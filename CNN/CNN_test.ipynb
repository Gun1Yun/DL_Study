{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"CNN_test.ipynb","provenance":[],"collapsed_sections":[],"authorship_tag":"ABX9TyOYKypnI5ibAOBq768kRHWh"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"markdown","metadata":{"id":"3hoxKS59I0lu"},"source":["# Convolutional Neural Network(CNN) 구현 & Time Series Data 학습\n","\n","## 1. GPU 사용 여부 설정\n","GPU 사용 시 런타임 유형 GPU러 살장\n","\n","- True : cupy 사용\n","- False : numpy 사용"]},{"cell_type":"code","metadata":{"id":"ulEpbdB354MP","executionInfo":{"status":"ok","timestamp":1621861758549,"user_tz":-540,"elapsed":268,"user":{"displayName":"윤건일","photoUrl":"","userId":"05157393038207945770"}}},"source":["# GPU \n","GPU = False\n","if GPU:\n","    import cupy as np\n","    np.cuda.set_allocator(np.cuda.MemoryPool().malloc)\n","else:\n","    import numpy as np"],"execution_count":1,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"Q9HqUj1PKlf_"},"source":["# 2. Optimizer 및 FC, Loss layer 구현\n","- optimizer : Adam\n","- FC : Fully Connected Layer\n","- Loss : Mean Squared Error(MSE)"]},{"cell_type":"code","metadata":{"id":"9IHafbLFXLoZ","executionInfo":{"status":"ok","timestamp":1621861760363,"user_tz":-540,"elapsed":413,"user":{"displayName":"윤건일","photoUrl":"","userId":"05157393038207945770"}}},"source":["# Optimizer Adam\n","class Adam:\n","    def __init__(self, lr=0.001, beta1=0.9, beta2=0.999):\n","        self.lr = lr\n","        self.beta1 = beta1\n","        self.beta2 = beta2\n","        self.iter = 0\n","        self.m = None\n","        self.v = None\n","        \n","    def update(self, params, grads):\n","        if self.m is None:\n","            self.m, self.v = [], []\n","            for param in params:\n","                self.m.append(np.zeros_like(param))\n","                self.v.append(np.zeros_like(param))\n","        \n","        self.iter += 1\n","        lr_t = self.lr * np.sqrt(1.0 - self.beta2**self.iter) / (1.0 - self.beta1**self.iter)\n","\n","        for i in range(len(params)):\n","            self.m[i] += (1 - self.beta1) * (grads[i] - self.m[i])\n","            self.v[i] += (1 - self.beta2) * (grads[i]**2 - self.v[i])\n","            \n","            params[i] -= lr_t * self.m[i] / (np.sqrt(self.v[i]) + 1e-7)"],"execution_count":2,"outputs":[]},{"cell_type":"code","metadata":{"id":"GPNkRgxU5689","executionInfo":{"status":"ok","timestamp":1621861762548,"user_tz":-540,"elapsed":280,"user":{"displayName":"윤건일","photoUrl":"","userId":"05157393038207945770"}}},"source":["# Fully Connected Layer\n","class FullyConnected:\n","    def __init__(self, W, b):\n","        self.params = [W, b]\n","        self.grads = [np.zeros_like(W), np.zeros_like(b)]\n","        self.x = None\n","\n","    def forward(self, x):\n","        W, b = self.params\n","        self.x_shape = x.shape\n","\n","        x = x.reshape(x.shape[0], -1)\n","        y = np.dot(x, W) + b        # y = X*W + b\n","        self.x = x\n","\n","        return y\n","\n","    def backward(self, dy):\n","        W, b = self.params\n","        x = self.x\n","\n","        db = np.sum(dy, axis=0)\n","        dW = np.dot(x.T, dy)\n","        dx = np.dot(dy, W.T)\n","\n","        self.grads[0][...] = dW\n","        self.grads[1][...] = db\n","        dx = dx.reshape(*self.x_shape)\n","\n","        return dx\n","\n","# activation function (ReLU)\n","class ReLU:\n","    def __init__(self):\n","        self.mask = None\n","\n","    def forward(self, x):\n","        self.mask = (x<=0)\n","        y = x.copy()\n","        y[self.mask] = 0\n","\n","        return y\n","    \n","    def backward(self, dy):\n","        dy[self.mask] = 0\n","        dx = dy\n","\n","        return dx\n","# MSE\n","def MSE(y, t):\n","    return 0.5*np.mean((y-t)**2)\n","\n","# ReLU with MSE\n","class ReluWithLoss:\n","    def __init__(self):\n","        self.params, self.grads = [], []\n","        self.activation = ReLU()\n","        self.cache = None\n","\n","    def forward(self, x, t):\n","        N, V = x.shape      # batch, ouput\n","\n","        x = x.reshape(N, V)\n","        t = t.reshape(N, V)\n","        x = self.activation.forward(x)\n","\n","        loss = MSE(x, t)\n","        self.cache = (t, x, (N, V))\n","        return loss\n","\n","    def backward(self, dy = 1):\n","        t, x, (N, V) = self.cache\n","        dx = dy*(x-t) / N\n","\n","        dx = self.activation.backward(dx)\n","        dx = dx.reshape(N, V)\n","\n","        return dx"],"execution_count":3,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"UD_pfz8pKFQb"},"source":["## 3. CNN Layer 구현\n","- im2col : image to column data\n","- col2im : column data to image\n","\n"]},{"cell_type":"code","metadata":{"id":"V3lfSywr9nTP","executionInfo":{"status":"ok","timestamp":1621861764722,"user_tz":-540,"elapsed":386,"user":{"displayName":"윤건일","photoUrl":"","userId":"05157393038207945770"}}},"source":["# CNN Layer (Conv, Pooling)\n","def im2col(data, filter_h, filter_w, stride = 1, padding = 0):\n","    # flatten data to 2D array\n","    N, C, H, W = data.shape\n","    \n","    out_h = (H + 2*padding - filter_h)//stride + 1\n","    out_w = (W + 2*padding - filter_w)//stride + 1\n","\n","    # padding for H, W\n","    img = np.pad(data, \n","                 [(0, 0), (0, 0), (padding, padding), (padding, padding)], \n","                 'constant')\n","    col = np.zeros((N, C, filter_h, filter_w, out_h, out_w))\n","    for y in range(filter_h):\n","        y_max = y + stride*out_h\n","        for x in range(filter_w):\n","            x_max = x + stride*out_w\n","            col[:, :, y, x, :, :] = img[:, :, y:y_max:stride, x:x_max:stride]\n","            \n","    col = col.transpose(0, 4, 5, 1, 2, 3).reshape(N*out_h*out_w, -1)\n","\n","    return col\n","\n","def col2im(col, shape, filter_h, filter_w, stride=1, padding=0):\n","    # 2D for img data\n","    # shape = original data shape\n","    N, C, H, W = shape\n","    out_h = (H + 2*padding - filter_h)//stride + 1\n","    out_w = (W + 2*padding - filter_w)//stride + 1\n","    col = col.reshape(N, out_h, out_w, C, filter_h, filter_w).transpose(0, 3, 4, 5, 1, 2)\n","\n","    img = np.zeros((N, C, H+2*padding + stride -1, W+2*padding+stride-1))\n","    \n","    for y in range(filter_h):\n","        y_max = y + stride*out_h\n","        for x in range(filter_w):\n","            x_max = x + stride*out_w\n","            img[:, :, y:y_max:stride, x:x_max:stride] =+ col[:, :, y, x, :, :]\n","\n","    return img[:, :, padding:H+padding, padding:W+padding]\n","\n","\n","class Convolution:\n","    def __init__(self, W, b, stride=1, padding=0):\n","        self.params = [W, b]\n","        self.grads = [np.zeros_like(W), np.zeros_like(b)]\n","        self.stride = stride\n","        self.padding = padding\n","        self.cache = None\n","\n","    def forward(self, x):\n","        weight, b = self.params\n","        FN, FC, FH, FW = weight.shape\n","        N, C, H, W = x.shape        # Samples, Channel, Time steps(24), Features\n","\n","        out_h = (H + 2*self.padding - FH)//self.stride + 1\n","        out_w = (W + 2*self.padding - FW)//self.stride + 1\n","\n","        col = im2col(x, FH, FW, self.stride, self.padding)\n","        col_W = weight.reshape(FN, -1).T\n","\n","        y = np.dot(col, col_W) + b\n","        y = y.reshape(N, out_h, out_w, -1).transpose(0, 3, 1, 2)\n","\n","        self.cache = (x, col, col_W)\n","\n","        return y\n","\n","    def backward(self, dy):\n","        W, b = self.params\n","        x, col, col_W = self.cache\n","        FN, C, FH, FW = W.shape\n","        \n","        dy = dy.transpose(0, 2, 3, 1).reshape(-1, FN)\n","\n","        db = np.sum(dy, axis=0)\n","        dW = np.dot(col.T, dy)\n","        dW = dW.transpose(1, 0).reshape(FN, C, FH, FW)\n","\n","        self.grads[0][...] = dW\n","        self.grads[1][...] = db\n","\n","        dx = np.dot(dy, col_W.T)\n","        dx = col2im(dx, x.shape, FH, FW, self.stride, self.padding)\n","\n","        return dx\n","\n","class Pooling:\n","    def __init__(self, pool_h, pool_w, stride=1, padding=0):\n","        self.pool_h = pool_h\n","        self.pool_w = pool_w\n","        self.stride = stride\n","        self.padding = padding\n","\n","    def forward(self, x):\n","        N, C, H, W = x.shape\n","        out_h = int(1 + (H - self.pool_h) / self.stride)\n","        out_w = int(1 + (W - self.pool_w) / self.stride)\n","\n","        col = im2col(x, self.pool_h, self.pool_w, self.stride, self.padding)\n","        col = col.reshape(-1, self.pool_h*self.pool_w)\n","\n","        arg_max = np.argmax(col, axis=1)\n","        y = np.max(col, axis=1)\n","        y = y.reshape(N, out_h, out_w, C).transpose(0, 3, 1, 2)\n","\n","        self.cache = (x, arg_max)\n","\n","        return y\n","\n","    def backward(self, dy):\n","        x, arg_max = self.cache\n","\n","        dy = dy.transpose(0, 2, 3, 1)      # N, C, H, W\n","        pool_size = self.pool_h*self.pool_w\n","\n","        dmax = np.zeros((dy.size, pool_size))\n","        dmax[np.arange(arg_max.size), arg_max.flatten()] = dy.flatten()\n","        dmax = dmax.reshape(dy.shape + (pool_size, ))\n","        dcol = dmax.reshape(dmax.shape[0]*dmax.shape[1]*dmax.shape[2], -1)\n","        dx = col2im(dcol, x.shape, \n","                    self.pool_h, \n","                    self.pool_w, \n","                    self.stride, \n","                    self.padding)\n","        \n","        return dx"],"execution_count":4,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"CGPPBXdiK8p2"},"source":["## 4. Model 설계\n","### Model Architecture\n","- conv -> relu -> pool -> fc -> relu -> fc -> relu"]},{"cell_type":"code","metadata":{"id":"qMHGE1QVy5Uv","executionInfo":{"status":"ok","timestamp":1621861766440,"user_tz":-540,"elapsed":577,"user":{"displayName":"윤건일","photoUrl":"","userId":"05157393038207945770"}}},"source":["# CNN Model\n","class Model:\n","    def __init__(self, input_dim = (1, 24, 8), \n","                 params={'filter_num':30, 'filter_size':5, \n","                         'padding':0, 'stride':1},\n","                 hidden_size=100, output_size=1):\n","        filter_num = params['filter_num']\n","        filter_size = params['filter_size']\n","        padding = params['padding']\n","        stride = params['stride']\n","\n","        # not square\n","        input_size = input_dim[1]\n","        input_size2 = input_dim[2]\n","        conv_output_size_h = (input_size - filter_size + 2*padding)/stride + 1\n","        conv_output_size_w = (input_size2 - filter_size + 2*padding)/stride + 1\n","        pool_output_size = int(filter_num*(conv_output_size_h/2)*(conv_output_size_w/2))\n","\n","        self.params = {}\n","        rand = np.random.randn\n","\n","        # He initialize\n","        self.params['cnn_W'] = rand(filter_num, input_dim[0], filter_size, filter_size) / np.sqrt(filter_num/2)\n","        self.params['cnn_b'] = np.zeros(filter_num)\n","        self.params['W1'] = rand(pool_output_size, hidden_size)/np.sqrt(pool_output_size/2)\n","        self.params['b1'] = np.zeros(hidden_size)\n","        self.params['W2'] = rand(hidden_size, output_size)/np.sqrt(hidden_size/2)\n","        self.params['b2'] = np.zeros(output_size)\n","\n","        self.layers=[\n","                     Convolution(self.params['cnn_W'], self.params['cnn_b'], stride, padding),\n","                     ReLU(),\n","                     Pooling(pool_h=2, pool_w=2, stride=2),\n","                     FullyConnected(self.params['W1'], self.params['b1']),\n","                     ReLU(),\n","                     FullyConnected(self.params['W2'], self.params['b2']),\n","        ]\n","        self.loss_layer = ReluWithLoss()\n","\n","        self.grads = []\n","        self.params = []\n","        for i in [0, 3, 5]:\n","            self.params += self.layers[i].params\n","            self.grads+=self.layers[i].grads\n","\n","\n","    def predict(self, x):\n","        x = np.array(x)\n","        for layer in self.layers:\n","            x = layer.forward(x)\n","        return x\n","\n","    def forward(self, x, t):\n","        x = np.array(x)\n","        t = np.array(t)\n","        x = self.predict(x)\n","        loss = self.loss_layer.forward(x, t)\n","        return loss\n","\n","    def backward(self, dy=1):\n","        dy = self.loss_layer.backward(dy)\n","\n","        for layer in reversed(self.layers):\n","            dy = layer.backward(dy)\n","        return dy\n","\n","    def fit(self, train_X=None, train_y=None, epochs=1, batch_size=1, verbose=0):\n","        \n","        optimizer = Adam(0.01)\n","\n","        data_size = train_X.shape[0]\n","        max_iters = data_size // batch_size\n","\n","        for epoch in range(1, epochs+1):\n","            # shuffle\n","            idx = np.random.permutation(np.arange(data_size))\n","            x_data = train_X[idx]\n","            y_data = train_y[idx]\n","\n","            epoch_loss = 0\n","            start_time = time.time()\n","\n","            for iter in range(max_iters):\n","                batch_x = x_data[iter*batch_size:(iter+1)*batch_size]\n","                batch_y = y_data[iter*batch_size:(iter+1)*batch_size]\n","\n","                loss = self.forward(batch_x, batch_y)\n","                self.backward()\n","                params, grads = self.params, self.grads\n","                optimizer.update(params, grads)\n","\n","                epoch_loss += loss\n","            avg_loss = epoch_loss / max_iters\n","\n","            if verbose:\n","                duration = time.time()-start_time\n","                print(f'epoch:{epoch}/{epochs}, 시간:{duration:.2f}[s], loss:{avg_loss:.5f}')"],"execution_count":5,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"K9niaCF6nt8y","executionInfo":{"status":"ok","timestamp":1621861768817,"user_tz":-540,"elapsed":892,"user":{"displayName":"윤건일","photoUrl":"","userId":"05157393038207945770"}},"outputId":"2a87c528-66f3-4be6-8431-5c52fde4bf6a"},"source":["import numpy as np\n","import pandas as pd\n","import time\n","\n","nRows = 365     #days\n","\n","df = pd.DataFrame(np.random.randint(0, 5, size=(nRows, 2)), columns=[\"X\", \"y\"], index = pd.date_range(\"20210101\", periods=nRows))\n","df.head()\n","\n","from sklearn.model_selection import TimeSeriesSplit\n","\n","n_splits = 3\n","\n","trainTestSplit = TimeSeriesSplit(n_splits+1).split(df)\n","next(trainTestSplit) #Skip the first fold\n","\n","for trainCvIndices, testIndices in trainTestSplit:\n","    # split Train, Cv, Test\n","    XTrainCv, yTrainCv = df.iloc[trainCvIndices, 0], df.iloc[trainCvIndices, 1]\n","    XTest, yTest = df.iloc[testIndices, 0], df.iloc[testIndices, 1]\n","\n","    test_length = len(XTest)\n","    trainCvSplit = [(list(range(trainCvIndices[0], trainCvIndices[-test_length])),\n","                     list(range(trainCvIndices[-test_length], trainCvIndices[-1]+1)))]\n","\n","    print(f'Training : {XTrainCv.index[0].date()} -- {XTrainCv.index[-test_length-1].date()}\\\n","          , Cv : {XTrainCv.index[-test_length].date()} -- {XTrainCv.index[-1].date()}\\\n","          , Test : {XTest.index[0].date()} -- {XTest.index[-1].date()}')"],"execution_count":6,"outputs":[{"output_type":"stream","text":["Training : 2021-01-01 -- 2021-03-14          , Cv : 2021-03-15 -- 2021-05-26          , Test : 2021-05-27 -- 2021-08-07\n","Training : 2021-01-01 -- 2021-05-26          , Cv : 2021-05-27 -- 2021-08-07          , Test : 2021-08-08 -- 2021-10-19\n","Training : 2021-01-01 -- 2021-08-07          , Cv : 2021-08-08 -- 2021-10-19          , Test : 2021-10-20 -- 2021-12-31\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":486},"id":"CwhI0OYlXGan","executionInfo":{"status":"error","timestamp":1621867055406,"user_tz":-540,"elapsed":672601,"user":{"displayName":"윤건일","photoUrl":"","userId":"05157393038207945770"}},"outputId":"17ed5616-980d-4623-ff1a-8a547643e0ab"},"source":["import pandas as pd\n","import time\n","def series_to_img(dataset, time_step=1):\n","    num = dataset.shape[1]      # features num\n","    df = pd.DataFrame(dataset)\n","    cols, names = list(), list()\n","    # sequence t-n to t-1\n","    for i in range(time_step, 0, -1):\n","        cols.append(df.shift(i))\n","        names += [('var%d(t-%d)' % (j+1, i)) for j in range(num)]\n","\n","    for i in range(0, 1):\n","        cols.append(df.shift(-i))\n","        if i == 0:\n","            names += [('var%d(t)' % (j+1)) for j in range(num)]\n","        else:\n","            names += [('var%d(t+%d)' % (j+1, i)) for j in range(num)]\n","\n","    agg = pd.concat(cols, axis=1)\n","    agg.columns = names\n","    agg.dropna(inplace=True)\n","    return agg\n","\n","def model_config():\n","    # config for CNN\n","    filter_num = [10, 30]\n","    filter_size = [5]\n","    epochs = [5]\n","    batch_size = [64]\n","    # create config\n","    config = []\n","    for i in filter_num:\n","        for j in filter_size:\n","            for k in epochs:\n","                for l in batch_size:\n","                    c = [i, j, k, l]\n","                    config.append(c)\n","    return config\n","\n","def fit_model(train_x, train_y, config):\n","    '''\n","    train : train data\n","    config : parameters\n","    '''\n","    # unpack config\n","    filter_num, filter_size, n_epochs, n_batch = config\n","\n","    params = {'filter_num':filter_num, 'filter_size':filter_size, 'padding':0, 'stride':1}\n","    model = Model(params=params)\n","    # train_X=None, train_y=None, epochs=1, batch_size=1, verbose=0\n","    model.fit(train_X=train_x, train_y=train_y, epochs=n_epochs, batch_size=n_batch, verbose=1)\n","    return model\n","\n","# use beijing air pollution data\n","from datetime import datetime\n","\n","df_parser = lambda x: datetime.strptime(x, '%Y %m %d %H')    # string to datetime\n","# data_url = 'https://archive.ics.uci.edu/ml/machine-learning-databases/00381/PRSA_data_2010.1.1-2014.12.31.csv'\n","data_url = 'https://raw.githubusercontent.com/jbrownlee/Datasets/master/pollution.csv'\n","df = pd.read_csv(data_url, sep=',', parse_dates=[['year', 'month', 'day', 'hour']], date_parser=df_parser, index_col=0)\n","\n","del df['No']\n","df.columns = ['pm2.5', 'dewp', 'temp', 'pres', 'cbwd','wind_speed', 'snow', 'rain']\n","df = df[24:]       # NaN values in first 24hours\n","\n","# sklearn library for time series split\n","from sklearn.model_selection import TimeSeriesSplit\n","from sklearn.preprocessing import LabelEncoder, MinMaxScaler\n","from sklearn.metrics import mean_squared_error\n","\n","dataset = df.values\n","label_encoder = LabelEncoder()\n","dataset[:, 4] = label_encoder.fit_transform(dataset[:, 4])  # for wind direction\n","\n","n_inputs = 24       # input time dim\n","n_features = 8      # input feature dim\n","del_idx = n_inputs * n_features + 1\n","del_cols = [i for i in range(del_idx, del_idx+n_features-1)]\n","new_df = series_to_img(dataset, n_inputs)\n","new_df.drop(new_df.columns[del_cols], axis=1, inplace=True)\n","\n","\n","n_splits = 3\n","\n","# Time split for nested cross validation\n","train_test_split = TimeSeriesSplit(n_splits=n_splits+1, gap=n_inputs).split(new_df)\n","next(train_test_split)\n","\n","for train_cv_indices, test_cv_indices in train_test_split:\n","    train_cv_X, train_cv_y = new_df.iloc[train_cv_indices, :-1].values, new_df.iloc[train_cv_indices,-1].values\n","    test_cv_X, test_cv_y = new_df.iloc[test_cv_indices, :-1].values, new_df.iloc[test_cv_indices, -1].values\n","\n","    test_length = len(test_cv_X)\n","    train_cv_split = [(list(range(train_cv_indices[0], train_cv_indices[-test_length])),\n","                       list(range(train_cv_indices[-test_length], train_cv_indices[-1]+1)))]\n","\n","    # scaling data\n","    scaler_x = MinMaxScaler()\n","    train_cv_X = scaler_x.fit_transform(train_cv_X)\n","    test_cv_X = scaler_x.transform(test_cv_X)\n","\n","    train_X, val_X = train_cv_X[:-test_length, :], train_cv_X[-test_length:, :]\n","    train_y, val_y = train_cv_y[:-test_length], train_cv_y[-test_length:]\n","\n","    #reshape\n","    # inner\n","    train_X = train_X.reshape(-1, 1, n_inputs, n_features)\n","    val_X = val_X.reshape(-1, 1, n_inputs, n_features)\n","\n","    # outter\n","    train_cv_X = train_cv_X.reshape(-1, 1, n_inputs, n_features)\n","    test_cv_X = test_cv_X.reshape(-1, 1, n_inputs, n_features)\n","\n","    # model fit\n","    configs = model_config()\n","    errors = []\n","    for idx, cfg in enumerate(configs):\n","        model = fit_model(train_X, train_y, cfg)\n","        predicted = model.predict(val_X)\n","        error = np.sqrt(mean_squared_error(predicted, val_y))   # rmse\n","        if errors:\n","            if error < min(errors):\n","                param = idx\n","        else:\n","            param = idx\n","        errors.append(error)\n","\n","    selected_model = fit_model(train_cv_X,train_cv_y, configs[param])\n","    predicted = selected_model.predict(test_cv_X)\n","    error = np.sqrt(mean_squared_error(predicted, test_cv_y))\n","\n","    # model eval\n","    # print(f'train : {train_cv.index[0].date()} -- {train_cv.index[-test_length-1].date()}, error : {error}, param:{param}')\n","\n"],"execution_count":19,"outputs":[{"output_type":"stream","text":["epoch:1/5, 시간:16.78[s], loss:9904.78673\n","epoch:2/5, 시간:16.84[s], loss:9908.93429\n","epoch:3/5, 시간:16.82[s], loss:9889.35964\n","epoch:4/5, 시간:16.73[s], loss:9893.54354\n","epoch:5/5, 시간:16.77[s], loss:9903.31223\n","epoch:1/5, 시간:37.93[s], loss:3468.09924\n","epoch:2/5, 시간:38.53[s], loss:1925.19312\n","epoch:3/5, 시간:38.67[s], loss:1405.35273\n","epoch:4/5, 시간:38.74[s], loss:1032.47665\n","epoch:5/5, 시간:38.92[s], loss:993.86983\n","epoch:1/5, 시간:77.90[s], loss:2647.39309\n","epoch:2/5, 시간:77.79[s], loss:1294.85724\n","epoch:3/5, 시간:78.42[s], loss:983.88978\n","epoch:4/5, 시간:78.61[s], loss:765.29004\n","epoch:5/5, 시간:77.65[s], loss:643.45741\n"],"name":"stdout"},{"output_type":"error","ename":"AttributeError","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)","\u001b[0;32m<ipython-input-19-83ff8277d925>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    131\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    132\u001b[0m     \u001b[0;31m# model eval\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 133\u001b[0;31m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf'train : {train_cv.index[0].date()} -- {train_cv.index[-test_length-1].date()}, error : {error}, param:{param}'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    134\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mAttributeError\u001b[0m: 'numpy.int64' object has no attribute 'date'"]}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Jc_lwP7h18-F","executionInfo":{"status":"ok","timestamp":1621861555100,"user_tz":-540,"elapsed":280,"user":{"displayName":"윤건일","photoUrl":"","userId":"05157393038207945770"}},"outputId":"d880915e-ffe4-47cd-c782-36db73e9012b"},"source":["import sklearn\n","print(sklearn.__version__)"],"execution_count":17,"outputs":[{"output_type":"stream","text":["0.22.2.post1\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":318},"id":"85El79Q_etE_","executionInfo":{"status":"ok","timestamp":1621861734174,"user_tz":-540,"elapsed":8223,"user":{"displayName":"윤건일","photoUrl":"","userId":"05157393038207945770"}},"outputId":"84ba4d04-cbb5-4c39-8bee-0e45c8caa20b"},"source":["!pip install scikit-learn==0.24.2"],"execution_count":21,"outputs":[{"output_type":"stream","text":["Collecting scikit-learn==0.24.2\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/a8/eb/a48f25c967526b66d5f1fa7a984594f0bf0a5afafa94a8c4dbc317744620/scikit_learn-0.24.2-cp37-cp37m-manylinux2010_x86_64.whl (22.3MB)\n","\u001b[K     |████████████████████████████████| 22.3MB 1.5MB/s \n","\u001b[?25hRequirement already satisfied: numpy>=1.13.3 in /usr/local/lib/python3.7/dist-packages (from scikit-learn==0.24.2) (1.19.5)\n","Requirement already satisfied: scipy>=0.19.1 in /usr/local/lib/python3.7/dist-packages (from scikit-learn==0.24.2) (1.4.1)\n","Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from scikit-learn==0.24.2) (2.1.0)\n","Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.7/dist-packages (from scikit-learn==0.24.2) (1.0.1)\n","Installing collected packages: scikit-learn\n","  Found existing installation: scikit-learn 0.24.0\n","    Uninstalling scikit-learn-0.24.0:\n","      Successfully uninstalled scikit-learn-0.24.0\n","Successfully installed scikit-learn-0.24.2\n"],"name":"stdout"},{"output_type":"display_data","data":{"application/vnd.colab-display-data+json":{"pip_warning":{"packages":["sklearn"]}}},"metadata":{"tags":[]}}]},{"cell_type":"code","metadata":{"id":"-KeWVNaJfTl4"},"source":[""],"execution_count":null,"outputs":[]}]}