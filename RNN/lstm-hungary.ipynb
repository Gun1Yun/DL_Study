{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"lstm-hungary.ipynb","provenance":[],"authorship_tag":"ABX9TyMrkzsDViv6ZLh29B1EK5O0"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU"},"cells":[{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"NfGPJXuRi7-3","executionInfo":{"status":"ok","timestamp":1623053881502,"user_tz":-540,"elapsed":16661,"user":{"displayName":"윤건일","photoUrl":"","userId":"05157393038207945770"}},"outputId":"06b32265-bc18-4ef0-914b-b2ee25bc78dc"},"source":["# google drive mount\n","from os.path import join\n","from google.colab import drive\n","\n","ROOT = '/content/drive'\n","drive.mount(ROOT)"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Mounted at /content/drive\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"ilDIefSTjHn9","executionInfo":{"status":"ok","timestamp":1623053886021,"user_tz":-540,"elapsed":264,"user":{"displayName":"윤건일","photoUrl":"","userId":"05157393038207945770"}},"outputId":"f3f84ba3-41e3-4165-f249-eb8071af8145"},"source":["import os\n","import sys\n","\n","DATA_PATH = '/content/drive/MyDrive/GitHub/DL_Study/datasets'\n","MODULE_PATH = '/content/drive/MyDrive/GitHub/DL_Study/Base'\n","\n","sys.path.insert(0, DATA_PATH)\n","sys.path.insert(0, MODULE_PATH)\n","sys.path"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["['/content/drive/MyDrive/GitHub/DL_Study/Base',\n"," '/content/drive/MyDrive/GitHub/DL_Study/datasets',\n"," '',\n"," '/content',\n"," '/env/python',\n"," '/usr/lib/python37.zip',\n"," '/usr/lib/python3.7',\n"," '/usr/lib/python3.7/lib-dynload',\n"," '/usr/local/lib/python3.7/dist-packages',\n"," '/usr/lib/python3/dist-packages',\n"," '/usr/local/lib/python3.7/dist-packages/IPython/extensions',\n"," '/root/.ipython']"]},"metadata":{"tags":[]},"execution_count":2}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"4mZRZny4jN8g","executionInfo":{"status":"ok","timestamp":1623053955955,"user_tz":-540,"elapsed":8637,"user":{"displayName":"윤건일","photoUrl":"","userId":"05157393038207945770"}},"outputId":"95205ec8-ae34-44b8-8bb1-d09521c1e125"},"source":["# import\n","from config import *\n","from layers import LSTM, TimeLSTM, FullyConnected\n","from optim import Adam\n","\n","# for time series split\n","!pip install scikit-learn==0.24.2"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Collecting scikit-learn==0.24.2\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/a8/eb/a48f25c967526b66d5f1fa7a984594f0bf0a5afafa94a8c4dbc317744620/scikit_learn-0.24.2-cp37-cp37m-manylinux2010_x86_64.whl (22.3MB)\n","\u001b[K     |████████████████████████████████| 22.3MB 1.6MB/s \n","\u001b[?25hRequirement already satisfied: scipy>=0.19.1 in /usr/local/lib/python3.7/dist-packages (from scikit-learn==0.24.2) (1.4.1)\n","Collecting threadpoolctl>=2.0.0\n","  Downloading https://files.pythonhosted.org/packages/f7/12/ec3f2e203afa394a149911729357aa48affc59c20e2c1c8297a60f33f133/threadpoolctl-2.1.0-py3-none-any.whl\n","Requirement already satisfied: numpy>=1.13.3 in /usr/local/lib/python3.7/dist-packages (from scikit-learn==0.24.2) (1.19.5)\n","Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.7/dist-packages (from scikit-learn==0.24.2) (1.0.1)\n","Installing collected packages: threadpoolctl, scikit-learn\n","  Found existing installation: scikit-learn 0.22.2.post1\n","    Uninstalling scikit-learn-0.22.2.post1:\n","      Successfully uninstalled scikit-learn-0.22.2.post1\n","Successfully installed scikit-learn-0.24.2 threadpoolctl-2.1.0\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"ScfFKtEBjc-W"},"source":["def MSE(y, t):\n","    return 0.5*np.mean((y-t)**2)\n","\n","class ReLU:\n","    def __init__(self):\n","        self.mask = None\n","\n","    def forward(self, x):\n","        self.mask = (x<=0)\n","        y = x.copy()\n","        y[self.mask] = 0\n","\n","        return y\n","    \n","    def backward(self, dy):\n","        dy[self.mask] = 0\n","        dx = dy\n","\n","        return dx\n","\n","\n","class TimeFC:\n","    def __init__(self, W, b):\n","        self.params = [W, b]\n","        self.grads = [np.zeros_like(W), np.zeros_like(b)]\n","        self.x = None\n","\n","    def forward(self, x):\n","        W, b = self.params\n","        N, D = x.shape\n","\n","        reshaped_x = x.reshape(N, -1)\n","        y = np.dot(reshaped_x, W) + b\n","        \n","        self.x = x\n","        y = y.reshape(N, -1)\n","        return y\n","\n","    def backward(self, dy):\n","        W, b = self.params\n","        x = self.x\n","        N, D = x.shape\n","\n","        dy = dy.reshape(N, -1)\n","        reshaped_x = x.reshape(N, -1)\n","\n","        db = np.sum(dy, axis=0)\n","        dx = np.matmul(dy, W.T)\n","        dW = np.matmul(reshaped_x.T, dy)\n","        \n","        dx = dx.reshape(*x.shape)\n","\n","        self.grads[0][...] = dW\n","        self.grads[1][...] = db\n","\n","        return dx\n","\n","class TimeMSE:\n","    def __init__(self):\n","        self.params, self.grads = [], []\n","        self.activation = ReLU()\n","        self.cache = None\n","\n","    def forward(self, xs, ts):\n","        N, V = xs.shape\n","        xs = xs.reshape(N, V)\n","        xs = self.activation.forward(xs)\n","        ts = ts.reshape(N, V)\n","\n","        loss = MSE(xs, ts)\n","        self.cache = (ts, xs, (N, V))\n","\n","        return loss\n","\n","    def backward(self, dy = 1):\n","\n","        ts, xs, (N,  V) = self.cache\n","        \n","        dx = dy * (xs - ts) / (N)\n","\n","        dx = self.activation.backward(dx)\n","        dx = dx.reshape(N , V)\n","        return dx"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"vCxWj9Q4jh0S"},"source":["class LstmModelReg:\n","    def __init__(self, time_size, hidden_size, feature_size):\n","        T, H, F = time_size, hidden_size, feature_size\n","        H2 = 64\n","        rand = np.random.randn\n","\n","        # weights (Xavier)\n","        lstm_Wx = (rand(F, 4*H)/ np.sqrt(F)).astype('f')\n","        lstm_Wh = (rand(H, 4*H)/ np.sqrt(H)).astype('f')\n","        lstm_b = np.zeros(4*H).astype('f')\n","\n","        # He initialize\n","        fc_W1 = (rand(H, H2)/ np.sqrt(H/2)).astype('f')\n","        fc_b1 = np.zeros(H2).astype('f')\n","\n","        fc_W2 = (rand(H2, 1)/ np.sqrt(H2/2)).astype('f')\n","        fc_b2 = np.zeros(1).astype('f')\n","\n","        # layer\n","        self.layers = [\n","            TimeLSTM(lstm_Wx, lstm_Wh, lstm_b, stateful=True),\n","            TimeFC(fc_W1, fc_b1),\n","            TimeFC(fc_W2, fc_b2)\n","        ]\n","        self.loss_layer = TimeMSE()\n","\n","        self.params, self.grads = [], []\n","\n","        for layer in self.layers:\n","            self.params += layer.params\n","            self.grads += layer.grads\n","\n","\n","    def predict(self, xs):\n","        xs = np.array(xs)\n","        for layer in self.layers:\n","            xs = layer.forward(xs)\n","        return xs\n","\n","    def forward(self, xs, ts):\n","        xs = np.array(xs)\n","        ts = np.array(ts)\n","        for layer in self.layers:\n","            xs = layer.forward(xs)\n","        loss = self.loss_layer.forward(xs, ts)\n","        return loss\n","\n","    def backward(self, dy = 1):\n","        dy = self.loss_layer.backward(dy)\n","        for layer in reversed(self.layers):\n","            dy = layer.backward(dy)\n","        return dy\n","\n","    def fit(self, train_X=None, train_y=None,learning_rate=0.01, epochs=10, batch_size=32, verbose=0):\n","        optimizer = Adam(learning_rate)\n","\n","        data_size = train_X.shape[0]\n","        max_iters = data_size//batch_size\n","\n","        for epoch in range(1, epochs+1):\n","            idx = numpy.random.permutation(numpy.arange(data_size))\n","            train_X = train_X[idx]\n","            train_y = train_y[idx]\n","\n","            epoch_loss = 0\n","            start_time=time.time()\n","            \n","            for iter in range(max_iters):\n","                batch_x = train_X[iter*batch_size:(iter+1)*batch_size]\n","                batch_y = train_y[iter*batch_size:(iter+1)*batch_size]\n","\n","                loss = self.forward(batch_x, batch_y)\n","                self.backward()\n","                params, grads = self.params, self.grads\n","                optimizer.update(params, grads)\n","\n","                epoch_loss += loss\n","            avg_loss = epoch_loss/max_iters\n","\n","            if verbose:\n","                duration = start_time-time.time()\n","                print(f'epoch:{epoch}/{epochs}, 시간:{duration:.2f}[s], loss:{avg_loss:.5f}')\n","\n","\n","    def reset_state(self):\n","        self.layers[0].reset_state()"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"UXQRWlwfjsxg"},"source":["# configuration setting\n","def model_config():\n","    # parameter for LSTM Model\n","    epochs = [30]\n","    batch_size = [8, 16]\n","    learning_rate = [0.01, 0.001]\n","    \n","    # create config data\n","    configs = []\n","    for i in epochs:\n","        for j in batch_size:\n","            for k in learning_rate:\n","                config = [i, j, k]\n","                configs.append(config)\n","    return configs\n","\n","# fucntion for fit cnn model using configs\n","def model_fit(train_X, train_y, config):\n","    # unpack config\n","    n_epochs, n_batch, learning_rate = config\n","    model = LstmModelReg(time_size=8, hidden_size=100, feature_size=20)\n","    # fit model and return\n","    model.fit(train_X=train_X, train_y=train_y, epochs=n_epochs, \n","              batch_size=n_batch, learning_rate=learning_rate)\n","    return model\n","\n","def MAE_metric(x, t):\n","    return np.mean(np.abs(x-t))\n","\n","def MSE_metric(x, t):\n","    return np.mean((x-t)**2)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":224},"id":"8IbkHp2Gj-UV","executionInfo":{"status":"ok","timestamp":1623054091105,"user_tz":-540,"elapsed":355,"user":{"displayName":"윤건일","photoUrl":"","userId":"05157393038207945770"}},"outputId":"7ac8738b-ae5b-44f4-bd0e-0b80d16960cd"},"source":["# datset\n","import pandas as pd\n","\n","df = pd.read_csv('/content/drive/MyDrive/GitHub/DL_Study/datasets/hungary_chickenpox/hungary_chickenpox.csv')\n","df.drop('Date', axis=1, inplace=True)       # drop Date column\n","df.head()"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>BUDAPEST</th>\n","      <th>BARANYA</th>\n","      <th>BACS</th>\n","      <th>BEKES</th>\n","      <th>BORSOD</th>\n","      <th>CSONGRAD</th>\n","      <th>FEJER</th>\n","      <th>GYOR</th>\n","      <th>HAJDU</th>\n","      <th>HEVES</th>\n","      <th>JASZ</th>\n","      <th>KOMAROM</th>\n","      <th>NOGRAD</th>\n","      <th>PEST</th>\n","      <th>SOMOGY</th>\n","      <th>SZABOLCS</th>\n","      <th>TOLNA</th>\n","      <th>VAS</th>\n","      <th>VESZPREM</th>\n","      <th>ZALA</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>168</td>\n","      <td>79</td>\n","      <td>30</td>\n","      <td>173</td>\n","      <td>169</td>\n","      <td>42</td>\n","      <td>136</td>\n","      <td>120</td>\n","      <td>162</td>\n","      <td>36</td>\n","      <td>130</td>\n","      <td>57</td>\n","      <td>2</td>\n","      <td>178</td>\n","      <td>66</td>\n","      <td>64</td>\n","      <td>11</td>\n","      <td>29</td>\n","      <td>87</td>\n","      <td>68</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>157</td>\n","      <td>60</td>\n","      <td>30</td>\n","      <td>92</td>\n","      <td>200</td>\n","      <td>53</td>\n","      <td>51</td>\n","      <td>70</td>\n","      <td>84</td>\n","      <td>28</td>\n","      <td>80</td>\n","      <td>50</td>\n","      <td>29</td>\n","      <td>141</td>\n","      <td>48</td>\n","      <td>29</td>\n","      <td>58</td>\n","      <td>53</td>\n","      <td>68</td>\n","      <td>26</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>96</td>\n","      <td>44</td>\n","      <td>31</td>\n","      <td>86</td>\n","      <td>93</td>\n","      <td>30</td>\n","      <td>93</td>\n","      <td>84</td>\n","      <td>191</td>\n","      <td>51</td>\n","      <td>64</td>\n","      <td>46</td>\n","      <td>4</td>\n","      <td>157</td>\n","      <td>33</td>\n","      <td>33</td>\n","      <td>24</td>\n","      <td>18</td>\n","      <td>62</td>\n","      <td>44</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>163</td>\n","      <td>49</td>\n","      <td>43</td>\n","      <td>126</td>\n","      <td>46</td>\n","      <td>39</td>\n","      <td>52</td>\n","      <td>114</td>\n","      <td>107</td>\n","      <td>42</td>\n","      <td>63</td>\n","      <td>54</td>\n","      <td>14</td>\n","      <td>107</td>\n","      <td>66</td>\n","      <td>50</td>\n","      <td>25</td>\n","      <td>21</td>\n","      <td>43</td>\n","      <td>31</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>122</td>\n","      <td>78</td>\n","      <td>53</td>\n","      <td>87</td>\n","      <td>103</td>\n","      <td>34</td>\n","      <td>95</td>\n","      <td>131</td>\n","      <td>172</td>\n","      <td>40</td>\n","      <td>61</td>\n","      <td>49</td>\n","      <td>11</td>\n","      <td>124</td>\n","      <td>63</td>\n","      <td>56</td>\n","      <td>7</td>\n","      <td>47</td>\n","      <td>85</td>\n","      <td>60</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["   BUDAPEST  BARANYA  BACS  BEKES  BORSOD  ...  SZABOLCS  TOLNA  VAS  VESZPREM  ZALA\n","0       168       79    30    173     169  ...        64     11   29        87    68\n","1       157       60    30     92     200  ...        29     58   53        68    26\n","2        96       44    31     86      93  ...        33     24   18        62    44\n","3       163       49    43    126      46  ...        50     25   21        43    31\n","4       122       78    53     87     103  ...        56      7   47        85    60\n","\n","[5 rows x 20 columns]"]},"metadata":{"tags":[]},"execution_count":6}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"iXOIDivmkACE","executionInfo":{"status":"ok","timestamp":1623054095218,"user_tz":-540,"elapsed":286,"user":{"displayName":"윤건일","photoUrl":"","userId":"05157393038207945770"}},"outputId":"48a371cc-8547-445a-9adb-619c9e79bce2"},"source":["df.isnull().sum()"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["BUDAPEST    0\n","BARANYA     0\n","BACS        0\n","BEKES       0\n","BORSOD      0\n","CSONGRAD    0\n","FEJER       0\n","GYOR        0\n","HAJDU       0\n","HEVES       0\n","JASZ        0\n","KOMAROM     0\n","NOGRAD      0\n","PEST        0\n","SOMOGY      0\n","SZABOLCS    0\n","TOLNA       0\n","VAS         0\n","VESZPREM    0\n","ZALA        0\n","dtype: int64"]},"metadata":{"tags":[]},"execution_count":7}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":270},"id":"yADVsNYZkBCq","executionInfo":{"status":"ok","timestamp":1623054107140,"user_tz":-540,"elapsed":254,"user":{"displayName":"윤건일","photoUrl":"","userId":"05157393038207945770"}},"outputId":"2adbf22e-b218-4a91-9479-f2cbd951f9e3"},"source":["# task : budapest\n","# series data to img function\n","def series_to_img(dataset, time_step=1):\n","    num = dataset.shape[1]      # features num\n","    df = pd.DataFrame(dataset)\n","    cols, names = list(), list()\n","    # sequence t-n to t-1\n","    for i in range(time_step, 0, -1):\n","        cols.append(df.shift(i))\n","        names += [('var%d(t-%d)' % (j+1, i)) for j in range(num)]\n","\n","    for i in range(0, 1):\n","        cols.append(df.shift(-i))\n","        if i == 0:\n","            names += [('var%d(t)' % (j+1)) for j in range(num)]\n","        else:\n","            names += [('var%d(t+%d)' % (j+1, i)) for j in range(num)]\n","\n","    agg = pd.concat(cols, axis=1)\n","    agg.columns = names\n","    agg.dropna(inplace=True)\n","    return agg\n","\n","dataset = df.values\n","dataset = dataset.astype('float')\n","\n","n_inputs = 8\n","n_features = 20\n","del_idx = n_inputs*n_features+1\n","del_cols = [i for i in range(del_idx, del_idx+n_features-1)]\n","new_df = series_to_img(dataset, n_inputs)\n","new_df.drop(new_df.columns[del_cols], axis=1, inplace=True)\n","new_df.head()"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>var1(t-8)</th>\n","      <th>var2(t-8)</th>\n","      <th>var3(t-8)</th>\n","      <th>var4(t-8)</th>\n","      <th>var5(t-8)</th>\n","      <th>var6(t-8)</th>\n","      <th>var7(t-8)</th>\n","      <th>var8(t-8)</th>\n","      <th>var9(t-8)</th>\n","      <th>var10(t-8)</th>\n","      <th>var11(t-8)</th>\n","      <th>var12(t-8)</th>\n","      <th>var13(t-8)</th>\n","      <th>var14(t-8)</th>\n","      <th>var15(t-8)</th>\n","      <th>var16(t-8)</th>\n","      <th>var17(t-8)</th>\n","      <th>var18(t-8)</th>\n","      <th>var19(t-8)</th>\n","      <th>var20(t-8)</th>\n","      <th>var1(t-7)</th>\n","      <th>var2(t-7)</th>\n","      <th>var3(t-7)</th>\n","      <th>var4(t-7)</th>\n","      <th>var5(t-7)</th>\n","      <th>var6(t-7)</th>\n","      <th>var7(t-7)</th>\n","      <th>var8(t-7)</th>\n","      <th>var9(t-7)</th>\n","      <th>var10(t-7)</th>\n","      <th>var11(t-7)</th>\n","      <th>var12(t-7)</th>\n","      <th>var13(t-7)</th>\n","      <th>var14(t-7)</th>\n","      <th>var15(t-7)</th>\n","      <th>var16(t-7)</th>\n","      <th>var17(t-7)</th>\n","      <th>var18(t-7)</th>\n","      <th>var19(t-7)</th>\n","      <th>var20(t-7)</th>\n","      <th>...</th>\n","      <th>var2(t-2)</th>\n","      <th>var3(t-2)</th>\n","      <th>var4(t-2)</th>\n","      <th>var5(t-2)</th>\n","      <th>var6(t-2)</th>\n","      <th>var7(t-2)</th>\n","      <th>var8(t-2)</th>\n","      <th>var9(t-2)</th>\n","      <th>var10(t-2)</th>\n","      <th>var11(t-2)</th>\n","      <th>var12(t-2)</th>\n","      <th>var13(t-2)</th>\n","      <th>var14(t-2)</th>\n","      <th>var15(t-2)</th>\n","      <th>var16(t-2)</th>\n","      <th>var17(t-2)</th>\n","      <th>var18(t-2)</th>\n","      <th>var19(t-2)</th>\n","      <th>var20(t-2)</th>\n","      <th>var1(t-1)</th>\n","      <th>var2(t-1)</th>\n","      <th>var3(t-1)</th>\n","      <th>var4(t-1)</th>\n","      <th>var5(t-1)</th>\n","      <th>var6(t-1)</th>\n","      <th>var7(t-1)</th>\n","      <th>var8(t-1)</th>\n","      <th>var9(t-1)</th>\n","      <th>var10(t-1)</th>\n","      <th>var11(t-1)</th>\n","      <th>var12(t-1)</th>\n","      <th>var13(t-1)</th>\n","      <th>var14(t-1)</th>\n","      <th>var15(t-1)</th>\n","      <th>var16(t-1)</th>\n","      <th>var17(t-1)</th>\n","      <th>var18(t-1)</th>\n","      <th>var19(t-1)</th>\n","      <th>var20(t-1)</th>\n","      <th>var1(t)</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>8</th>\n","      <td>168.0</td>\n","      <td>79.0</td>\n","      <td>30.0</td>\n","      <td>173.0</td>\n","      <td>169.0</td>\n","      <td>42.0</td>\n","      <td>136.0</td>\n","      <td>120.0</td>\n","      <td>162.0</td>\n","      <td>36.0</td>\n","      <td>130.0</td>\n","      <td>57.0</td>\n","      <td>2.0</td>\n","      <td>178.0</td>\n","      <td>66.0</td>\n","      <td>64.0</td>\n","      <td>11.0</td>\n","      <td>29.0</td>\n","      <td>87.0</td>\n","      <td>68.0</td>\n","      <td>157.0</td>\n","      <td>60.0</td>\n","      <td>30.0</td>\n","      <td>92.0</td>\n","      <td>200.0</td>\n","      <td>53.0</td>\n","      <td>51.0</td>\n","      <td>70.0</td>\n","      <td>84.0</td>\n","      <td>28.0</td>\n","      <td>80.0</td>\n","      <td>50.0</td>\n","      <td>29.0</td>\n","      <td>141.0</td>\n","      <td>48.0</td>\n","      <td>29.0</td>\n","      <td>58.0</td>\n","      <td>53.0</td>\n","      <td>68.0</td>\n","      <td>26.0</td>\n","      <td>...</td>\n","      <td>103.0</td>\n","      <td>54.0</td>\n","      <td>192.0</td>\n","      <td>148.0</td>\n","      <td>65.0</td>\n","      <td>100.0</td>\n","      <td>118.0</td>\n","      <td>129.0</td>\n","      <td>40.0</td>\n","      <td>88.0</td>\n","      <td>56.0</td>\n","      <td>10.0</td>\n","      <td>119.0</td>\n","      <td>104.0</td>\n","      <td>85.0</td>\n","      <td>20.0</td>\n","      <td>32.0</td>\n","      <td>153.0</td>\n","      <td>70.0</td>\n","      <td>115.0</td>\n","      <td>74.0</td>\n","      <td>64.0</td>\n","      <td>174.0</td>\n","      <td>140.0</td>\n","      <td>56.0</td>\n","      <td>111.0</td>\n","      <td>175.0</td>\n","      <td>138.0</td>\n","      <td>60.0</td>\n","      <td>112.0</td>\n","      <td>70.0</td>\n","      <td>21.0</td>\n","      <td>178.0</td>\n","      <td>70.0</td>\n","      <td>75.0</td>\n","      <td>5.0</td>\n","      <td>66.0</td>\n","      <td>149.0</td>\n","      <td>54.0</td>\n","      <td>119.0</td>\n","    </tr>\n","    <tr>\n","      <th>9</th>\n","      <td>157.0</td>\n","      <td>60.0</td>\n","      <td>30.0</td>\n","      <td>92.0</td>\n","      <td>200.0</td>\n","      <td>53.0</td>\n","      <td>51.0</td>\n","      <td>70.0</td>\n","      <td>84.0</td>\n","      <td>28.0</td>\n","      <td>80.0</td>\n","      <td>50.0</td>\n","      <td>29.0</td>\n","      <td>141.0</td>\n","      <td>48.0</td>\n","      <td>29.0</td>\n","      <td>58.0</td>\n","      <td>53.0</td>\n","      <td>68.0</td>\n","      <td>26.0</td>\n","      <td>96.0</td>\n","      <td>44.0</td>\n","      <td>31.0</td>\n","      <td>86.0</td>\n","      <td>93.0</td>\n","      <td>30.0</td>\n","      <td>93.0</td>\n","      <td>84.0</td>\n","      <td>191.0</td>\n","      <td>51.0</td>\n","      <td>64.0</td>\n","      <td>46.0</td>\n","      <td>4.0</td>\n","      <td>157.0</td>\n","      <td>33.0</td>\n","      <td>33.0</td>\n","      <td>24.0</td>\n","      <td>18.0</td>\n","      <td>62.0</td>\n","      <td>44.0</td>\n","      <td>...</td>\n","      <td>74.0</td>\n","      <td>64.0</td>\n","      <td>174.0</td>\n","      <td>140.0</td>\n","      <td>56.0</td>\n","      <td>111.0</td>\n","      <td>175.0</td>\n","      <td>138.0</td>\n","      <td>60.0</td>\n","      <td>112.0</td>\n","      <td>70.0</td>\n","      <td>21.0</td>\n","      <td>178.0</td>\n","      <td>70.0</td>\n","      <td>75.0</td>\n","      <td>5.0</td>\n","      <td>66.0</td>\n","      <td>149.0</td>\n","      <td>54.0</td>\n","      <td>119.0</td>\n","      <td>86.0</td>\n","      <td>57.0</td>\n","      <td>171.0</td>\n","      <td>90.0</td>\n","      <td>65.0</td>\n","      <td>118.0</td>\n","      <td>105.0</td>\n","      <td>194.0</td>\n","      <td>60.0</td>\n","      <td>67.0</td>\n","      <td>46.0</td>\n","      <td>12.0</td>\n","      <td>112.0</td>\n","      <td>116.0</td>\n","      <td>76.0</td>\n","      <td>22.0</td>\n","      <td>45.0</td>\n","      <td>102.0</td>\n","      <td>42.0</td>\n","      <td>114.0</td>\n","    </tr>\n","    <tr>\n","      <th>10</th>\n","      <td>96.0</td>\n","      <td>44.0</td>\n","      <td>31.0</td>\n","      <td>86.0</td>\n","      <td>93.0</td>\n","      <td>30.0</td>\n","      <td>93.0</td>\n","      <td>84.0</td>\n","      <td>191.0</td>\n","      <td>51.0</td>\n","      <td>64.0</td>\n","      <td>46.0</td>\n","      <td>4.0</td>\n","      <td>157.0</td>\n","      <td>33.0</td>\n","      <td>33.0</td>\n","      <td>24.0</td>\n","      <td>18.0</td>\n","      <td>62.0</td>\n","      <td>44.0</td>\n","      <td>163.0</td>\n","      <td>49.0</td>\n","      <td>43.0</td>\n","      <td>126.0</td>\n","      <td>46.0</td>\n","      <td>39.0</td>\n","      <td>52.0</td>\n","      <td>114.0</td>\n","      <td>107.0</td>\n","      <td>42.0</td>\n","      <td>63.0</td>\n","      <td>54.0</td>\n","      <td>14.0</td>\n","      <td>107.0</td>\n","      <td>66.0</td>\n","      <td>50.0</td>\n","      <td>25.0</td>\n","      <td>21.0</td>\n","      <td>43.0</td>\n","      <td>31.0</td>\n","      <td>...</td>\n","      <td>86.0</td>\n","      <td>57.0</td>\n","      <td>171.0</td>\n","      <td>90.0</td>\n","      <td>65.0</td>\n","      <td>118.0</td>\n","      <td>105.0</td>\n","      <td>194.0</td>\n","      <td>60.0</td>\n","      <td>67.0</td>\n","      <td>46.0</td>\n","      <td>12.0</td>\n","      <td>112.0</td>\n","      <td>116.0</td>\n","      <td>76.0</td>\n","      <td>22.0</td>\n","      <td>45.0</td>\n","      <td>102.0</td>\n","      <td>42.0</td>\n","      <td>114.0</td>\n","      <td>81.0</td>\n","      <td>129.0</td>\n","      <td>217.0</td>\n","      <td>167.0</td>\n","      <td>64.0</td>\n","      <td>93.0</td>\n","      <td>154.0</td>\n","      <td>119.0</td>\n","      <td>34.0</td>\n","      <td>118.0</td>\n","      <td>73.0</td>\n","      <td>6.0</td>\n","      <td>130.0</td>\n","      <td>68.0</td>\n","      <td>59.0</td>\n","      <td>31.0</td>\n","      <td>85.0</td>\n","      <td>96.0</td>\n","      <td>54.0</td>\n","      <td>127.0</td>\n","    </tr>\n","    <tr>\n","      <th>11</th>\n","      <td>163.0</td>\n","      <td>49.0</td>\n","      <td>43.0</td>\n","      <td>126.0</td>\n","      <td>46.0</td>\n","      <td>39.0</td>\n","      <td>52.0</td>\n","      <td>114.0</td>\n","      <td>107.0</td>\n","      <td>42.0</td>\n","      <td>63.0</td>\n","      <td>54.0</td>\n","      <td>14.0</td>\n","      <td>107.0</td>\n","      <td>66.0</td>\n","      <td>50.0</td>\n","      <td>25.0</td>\n","      <td>21.0</td>\n","      <td>43.0</td>\n","      <td>31.0</td>\n","      <td>122.0</td>\n","      <td>78.0</td>\n","      <td>53.0</td>\n","      <td>87.0</td>\n","      <td>103.0</td>\n","      <td>34.0</td>\n","      <td>95.0</td>\n","      <td>131.0</td>\n","      <td>172.0</td>\n","      <td>40.0</td>\n","      <td>61.0</td>\n","      <td>49.0</td>\n","      <td>11.0</td>\n","      <td>124.0</td>\n","      <td>63.0</td>\n","      <td>56.0</td>\n","      <td>7.0</td>\n","      <td>47.0</td>\n","      <td>85.0</td>\n","      <td>60.0</td>\n","      <td>...</td>\n","      <td>81.0</td>\n","      <td>129.0</td>\n","      <td>217.0</td>\n","      <td>167.0</td>\n","      <td>64.0</td>\n","      <td>93.0</td>\n","      <td>154.0</td>\n","      <td>119.0</td>\n","      <td>34.0</td>\n","      <td>118.0</td>\n","      <td>73.0</td>\n","      <td>6.0</td>\n","      <td>130.0</td>\n","      <td>68.0</td>\n","      <td>59.0</td>\n","      <td>31.0</td>\n","      <td>85.0</td>\n","      <td>96.0</td>\n","      <td>54.0</td>\n","      <td>127.0</td>\n","      <td>59.0</td>\n","      <td>81.0</td>\n","      <td>243.0</td>\n","      <td>99.0</td>\n","      <td>81.0</td>\n","      <td>72.0</td>\n","      <td>107.0</td>\n","      <td>117.0</td>\n","      <td>57.0</td>\n","      <td>72.0</td>\n","      <td>91.0</td>\n","      <td>9.0</td>\n","      <td>113.0</td>\n","      <td>62.0</td>\n","      <td>22.0</td>\n","      <td>26.0</td>\n","      <td>19.0</td>\n","      <td>118.0</td>\n","      <td>43.0</td>\n","      <td>135.0</td>\n","    </tr>\n","    <tr>\n","      <th>12</th>\n","      <td>122.0</td>\n","      <td>78.0</td>\n","      <td>53.0</td>\n","      <td>87.0</td>\n","      <td>103.0</td>\n","      <td>34.0</td>\n","      <td>95.0</td>\n","      <td>131.0</td>\n","      <td>172.0</td>\n","      <td>40.0</td>\n","      <td>61.0</td>\n","      <td>49.0</td>\n","      <td>11.0</td>\n","      <td>124.0</td>\n","      <td>63.0</td>\n","      <td>56.0</td>\n","      <td>7.0</td>\n","      <td>47.0</td>\n","      <td>85.0</td>\n","      <td>60.0</td>\n","      <td>174.0</td>\n","      <td>76.0</td>\n","      <td>77.0</td>\n","      <td>152.0</td>\n","      <td>189.0</td>\n","      <td>26.0</td>\n","      <td>74.0</td>\n","      <td>181.0</td>\n","      <td>157.0</td>\n","      <td>44.0</td>\n","      <td>95.0</td>\n","      <td>97.0</td>\n","      <td>26.0</td>\n","      <td>146.0</td>\n","      <td>59.0</td>\n","      <td>54.0</td>\n","      <td>27.0</td>\n","      <td>54.0</td>\n","      <td>48.0</td>\n","      <td>60.0</td>\n","      <td>...</td>\n","      <td>59.0</td>\n","      <td>81.0</td>\n","      <td>243.0</td>\n","      <td>99.0</td>\n","      <td>81.0</td>\n","      <td>72.0</td>\n","      <td>107.0</td>\n","      <td>117.0</td>\n","      <td>57.0</td>\n","      <td>72.0</td>\n","      <td>91.0</td>\n","      <td>9.0</td>\n","      <td>113.0</td>\n","      <td>62.0</td>\n","      <td>22.0</td>\n","      <td>26.0</td>\n","      <td>19.0</td>\n","      <td>118.0</td>\n","      <td>43.0</td>\n","      <td>135.0</td>\n","      <td>74.0</td>\n","      <td>51.0</td>\n","      <td>271.0</td>\n","      <td>215.0</td>\n","      <td>48.0</td>\n","      <td>115.0</td>\n","      <td>148.0</td>\n","      <td>171.0</td>\n","      <td>21.0</td>\n","      <td>114.0</td>\n","      <td>82.0</td>\n","      <td>10.0</td>\n","      <td>141.0</td>\n","      <td>55.0</td>\n","      <td>45.0</td>\n","      <td>23.0</td>\n","      <td>83.0</td>\n","      <td>127.0</td>\n","      <td>36.0</td>\n","      <td>116.0</td>\n","    </tr>\n","  </tbody>\n","</table>\n","<p>5 rows × 161 columns</p>\n","</div>"],"text/plain":["    var1(t-8)  var2(t-8)  var3(t-8)  ...  var19(t-1)  var20(t-1)  var1(t)\n","8       168.0       79.0       30.0  ...       149.0        54.0    119.0\n","9       157.0       60.0       30.0  ...       102.0        42.0    114.0\n","10       96.0       44.0       31.0  ...        96.0        54.0    127.0\n","11      163.0       49.0       43.0  ...       118.0        43.0    135.0\n","12      122.0       78.0       53.0  ...       127.0        36.0    116.0\n","\n","[5 rows x 161 columns]"]},"metadata":{"tags":[]},"execution_count":8}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"18-DKjahkD9h","executionInfo":{"status":"ok","timestamp":1623054856043,"user_tz":-540,"elapsed":434194,"user":{"displayName":"윤건일","photoUrl":"","userId":"05157393038207945770"}},"outputId":"6e72195b-af53-476f-87df-fe4f4c18af4f"},"source":["import numpy\n","import time\n","from sklearn.model_selection import TimeSeriesSplit\n","from sklearn.preprocessing import MinMaxScaler\n","\n","n_splits = 10\n","train_test_split = TimeSeriesSplit(n_splits=n_splits+1, gap=n_inputs).split(new_df)\n","next(train_test_split)\n","\n","configs = model_config()\n","history = []\n","best_error = []\n","i = 1\n","\n","print('config : epochs, batch_size, learning_rate')\n","\n","# neted cross validation\n","for train_cv_indices, test_cv_indices in train_test_split:\n","    print(f'fold : {i}/{n_splits}')\n","    i+=1\n","\n","    # split x, y data\n","    train_cv_X, train_cv_y = new_df.iloc[train_cv_indices, :-1].values, new_df.iloc[train_cv_indices,-1].values\n","    test_cv_X, test_cv_y = new_df.iloc[test_cv_indices, :-1].values, new_df.iloc[test_cv_indices, -1].values\n","\n","    # length for validation set\n","    test_length = len(test_cv_X)\n","\n","    # scaling data\n","    scaler_x = MinMaxScaler()\n","    train_cv_X = scaler_x.fit_transform(train_cv_X)\n","    test_cv_X = scaler_x.transform(test_cv_X)\n","\n","    train_X, val_X = train_cv_X[:-test_length, :], train_cv_X[-test_length:, :]\n","    train_y, val_y = train_cv_y[:-test_length], train_cv_y[-test_length:]\n","\n","    # reshape\n","    # inner loop\n","    train_X = train_X.reshape(-1,  n_inputs, n_features)\n","    val_X = val_X.reshape(-1, n_inputs, n_features)\n","    train_y = train_y.reshape(-1, 1)\n","    val_y = val_y.reshape(-1, 1)\n","\n","    # outer loop\n","    train_cv_X = train_cv_X.reshape(-1,  n_inputs, n_features)\n","    test_cv_X = test_cv_X.reshape(-1, n_inputs, n_features)\n","    train_cv_y = train_cv_y.reshape(-1, 1)\n","    test_cv_y = test_cv_y.reshape(-1, 1)\n","\n","    # model fit, inner\n","    errors = []\n","    for idx, cfg in enumerate(configs):\n","        print(f' == train {cfg} model == ', end=' ')\n","        model = model_fit(train_X, train_y, cfg)\n","        model.reset_state()\n","        predicted = model.predict(val_X)\n","        if GPU:\n","            predicted = np.asnumpy(predicted)\n","        error = np.sqrt(MSE_metric(predicted, val_y))   # rmse\n","        print(f' error(RMSE):{error}')\n","        if errors:\n","            if error < min(errors):\n","                param = idx\n","        else:\n","            param = idx\n","        errors.append(error)\n","\n","    history.append(errors)\n","\n","    selected_model = model_fit(train_cv_X,train_cv_y, configs[param])\n","    selected_model.reset_state()\n","    predicted = selected_model.predict(test_cv_X)\n","    if GPU:\n","        predicted = np.asnumpy(predicted)\n","    error = np.sqrt(MSE_metric(predicted, test_cv_y))\n","    best_error.append(error)\n","\n","    # model eval\n","    print(f'best_model => error(rmse) : {error}, param:{configs[param]}')"],"execution_count":null,"outputs":[{"output_type":"stream","text":["config : epochs, batch_size, learning_rate\n","fold : 1/10\n"," == train [30, 8, 0.01] model ==   error(RMSE):167.21779009537838\n"," == train [30, 8, 0.001] model ==   error(RMSE):102.7697439171926\n"," == train [30, 16, 0.01] model ==   error(RMSE):84.84705130577332\n"," == train [30, 16, 0.001] model ==   error(RMSE):112.46977758832696\n","best_model => error(rmse) : 65.83051872333382, param:2\n","fold : 2/10\n"," == train [30, 8, 0.01] model ==   error(RMSE):64.80174027209944\n"," == train [30, 8, 0.001] model ==   error(RMSE):62.39768961385993\n"," == train [30, 16, 0.01] model ==   error(RMSE):70.84605414762446\n"," == train [30, 16, 0.001] model ==   error(RMSE):87.41327511950276\n","best_model => error(rmse) : 74.48305595029728, param:1\n","fold : 3/10\n"," == train [30, 8, 0.01] model ==   error(RMSE):71.31769926115776\n"," == train [30, 8, 0.001] model ==   error(RMSE):75.45506887182951\n"," == train [30, 16, 0.01] model ==   error(RMSE):85.80418861232671\n"," == train [30, 16, 0.001] model ==   error(RMSE):68.46703751463416\n","best_model => error(rmse) : 54.89001018799462, param:3\n","fold : 4/10\n"," == train [30, 8, 0.01] model ==   error(RMSE):54.10983361507563\n"," == train [30, 8, 0.001] model ==   error(RMSE):59.99399454751467\n"," == train [30, 16, 0.01] model ==   error(RMSE):58.50927980024398\n"," == train [30, 16, 0.001] model ==   error(RMSE):56.52470009811789\n","best_model => error(rmse) : 35.47236730082703, param:0\n","fold : 5/10\n"," == train [30, 8, 0.01] model ==   error(RMSE):40.71672490015061\n"," == train [30, 8, 0.001] model ==   error(RMSE):38.291761100820636\n"," == train [30, 16, 0.01] model ==   error(RMSE):45.77453455850375\n"," == train [30, 16, 0.001] model ==   error(RMSE):34.66270472533154\n","best_model => error(rmse) : 47.624331145250466, param:3\n","fold : 6/10\n"," == train [30, 8, 0.01] model ==   error(RMSE):32.855485874605904\n"," == train [30, 8, 0.001] model ==   error(RMSE):30.675050331972326\n"," == train [30, 16, 0.01] model ==   error(RMSE):33.062862873760174\n"," == train [30, 16, 0.001] model ==   error(RMSE):27.26198300102524\n","best_model => error(rmse) : 51.126862818066556, param:3\n","fold : 7/10\n"," == train [30, 8, 0.01] model ==   error(RMSE):58.273351005206706\n"," == train [30, 8, 0.001] model ==   error(RMSE):68.7450711719471\n"," == train [30, 16, 0.01] model ==   error(RMSE):62.43081138057569\n"," == train [30, 16, 0.001] model ==   error(RMSE):59.350868835801904\n","best_model => error(rmse) : 58.900512746542596, param:0\n","fold : 8/10\n"," == train [30, 8, 0.01] model ==   error(RMSE):61.895905293576945\n"," == train [30, 8, 0.001] model ==   error(RMSE):55.091589882734176\n"," == train [30, 16, 0.01] model ==   error(RMSE):57.61584365984013\n"," == train [30, 16, 0.001] model ==   error(RMSE):67.95596105932945\n","best_model => error(rmse) : 48.447410289360064, param:1\n","fold : 9/10\n"," == train [30, 8, 0.01] model ==   error(RMSE):42.405626012562315\n"," == train [30, 8, 0.001] model ==   error(RMSE):57.71012580389002\n"," == train [30, 16, 0.01] model ==   error(RMSE):46.54893964876448\n"," == train [30, 16, 0.001] model ==   error(RMSE):47.39456688828445\n","best_model => error(rmse) : 31.580887828650933, param:0\n","fold : 10/10\n"," == train [30, 8, 0.01] model ==   error(RMSE):33.919440136888966\n"," == train [30, 8, 0.001] model ==   error(RMSE):31.937874516058592\n"," == train [30, 16, 0.01] model ==   error(RMSE):32.86617532088869\n"," == train [30, 16, 0.001] model ==   error(RMSE):33.3247284921953\n","best_model => error(rmse) : 70.46656351897981, param:1\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Jh6Or60Pk9Y2","executionInfo":{"status":"ok","timestamp":1623055022421,"user_tz":-540,"elapsed":273,"user":{"displayName":"윤건일","photoUrl":"","userId":"05157393038207945770"}},"outputId":"31d8d685-b53a-43f2-8915-dbfdd6875120"},"source":["model_evaluation = sum(best_error)\n","model_evaluation /= n_splits\n","print(f'evaluation [Mean RMSE] : {model_evaluation}')"],"execution_count":null,"outputs":[{"output_type":"stream","text":["evaluation [Mean RMSE] : 53.88225205093032\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"ebpNMccklcbf","executionInfo":{"status":"ok","timestamp":1623055107693,"user_tz":-540,"elapsed":260,"user":{"displayName":"윤건일","photoUrl":"","userId":"05157393038207945770"}},"outputId":"6c41a9fb-807e-46c5-bf3f-95a94e4da9d6"},"source":["selected_model.reset_state()\n","predicted = selected_model.predict(test_cv_X)\n","if GPU:\n","    predicted = np.asnumpy(predicted)\n","print(f'MSE : {MSE_metric(predicted, test_cv_y)}')\n","print(f'RMSE : {np.sqrt(MSE_metric(predicted, test_cv_y))}')\n","\n","def MAE_metric(x, t):\n","    return np.mean(numpy.abs(x-t))\n","print(f'MAE : {MAE_metric(predicted, test_cv_y)}')"],"execution_count":null,"outputs":[{"output_type":"stream","text":["MSE : 4965.536574174417\n","RMSE : 70.46656351897981\n","MAE : 39.21686846869333\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"mYa1PQqknlnc"},"source":[""],"execution_count":null,"outputs":[]}]}