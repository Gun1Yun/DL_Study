{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"ISE-CNN-ShuffleNet-Regression.ipynb","provenance":[],"collapsed_sections":[],"mount_file_id":"1_h0R5ooBVqhcsEwTe_wtCGFqp-0kceJN","authorship_tag":"ABX9TyMNCypqTYgZDVwojbwtxtIW"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU"},"cells":[{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"44on1Fhnj6DI","executionInfo":{"status":"ok","timestamp":1625386274775,"user_tz":-540,"elapsed":410,"user":{"displayName":"윤건일","photoUrl":"","userId":"05157393038207945770"}},"outputId":"dcf846af-3086-49d3-f231-1849fc403f0c"},"source":["# check GPU\n","!nvidia-smi"],"execution_count":1,"outputs":[{"output_type":"stream","text":["Sun Jul  4 08:11:14 2021       \n","+-----------------------------------------------------------------------------+\n","| NVIDIA-SMI 465.27       Driver Version: 460.32.03    CUDA Version: 11.2     |\n","|-------------------------------+----------------------+----------------------+\n","| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n","| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n","|                               |                      |               MIG M. |\n","|===============================+======================+======================|\n","|   0  Tesla T4            Off  | 00000000:00:04.0 Off |                    0 |\n","| N/A   60C    P8    10W /  70W |      0MiB / 15109MiB |      0%      Default |\n","|                               |                      |                  N/A |\n","+-------------------------------+----------------------+----------------------+\n","                                                                               \n","+-----------------------------------------------------------------------------+\n","| Processes:                                                                  |\n","|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n","|        ID   ID                                                   Usage      |\n","|=============================================================================|\n","|  No running processes found                                                 |\n","+-----------------------------------------------------------------------------+\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"6EiH7zxnH7bB","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1625386275163,"user_tz":-540,"elapsed":15,"user":{"displayName":"윤건일","photoUrl":"","userId":"05157393038207945770"}},"outputId":"523bada4-982f-4569-93e6-3591c0946187"},"source":["import os\n","import sys\n","\n","MODULE_PATH = '/content/drive/MyDrive/GitHub/DL_Study/CNN'\n","\n","sys.path.insert(0, MODULE_PATH)\n","sys.path"],"execution_count":2,"outputs":[{"output_type":"execute_result","data":{"text/plain":["['/content/drive/MyDrive/GitHub/DL_Study/CNN',\n"," '',\n"," '/content',\n"," '/env/python',\n"," '/usr/lib/python37.zip',\n"," '/usr/lib/python3.7',\n"," '/usr/lib/python3.7/lib-dynload',\n"," '/usr/local/lib/python3.7/dist-packages',\n"," '/usr/lib/python3/dist-packages',\n"," '/usr/local/lib/python3.7/dist-packages/IPython/extensions',\n"," '/root/.ipython']"]},"metadata":{"tags":[]},"execution_count":2}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"R10pml8lN3U4","executionInfo":{"status":"ok","timestamp":1625386277840,"user_tz":-540,"elapsed":2683,"user":{"displayName":"윤건일","photoUrl":"","userId":"05157393038207945770"}},"outputId":"ce36ded9-207e-4c1f-c79d-f39e460c72c6"},"source":["# import\n","import torch\n","import torch.nn as nn\n","import torch.nn.functional as F\n","import torch.optim as optim\n","import time\n","import numpy\n","\n","from ShuffleNet import *\n","\n","torch.manual_seed(42)\n","\n","# for time series split\n","!pip install scikit-learn==0.24.2"],"execution_count":3,"outputs":[{"output_type":"stream","text":["Requirement already satisfied: scikit-learn==0.24.2 in /usr/local/lib/python3.7/dist-packages (0.24.2)\n","Requirement already satisfied: numpy>=1.13.3 in /usr/local/lib/python3.7/dist-packages (from scikit-learn==0.24.2) (1.19.5)\n","Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from scikit-learn==0.24.2) (2.1.0)\n","Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.7/dist-packages (from scikit-learn==0.24.2) (1.0.1)\n","Requirement already satisfied: scipy>=0.19.1 in /usr/local/lib/python3.7/dist-packages (from scikit-learn==0.24.2) (1.4.1)\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"BdOo-pR5OLs0","executionInfo":{"status":"ok","timestamp":1625386277841,"user_tz":-540,"elapsed":10,"user":{"displayName":"윤건일","photoUrl":"","userId":"05157393038207945770"}}},"source":["def get_device():\n","    if torch.cuda.is_available():\n","        device = torch.device('cuda:0')\n","    else:\n","        device = torch.device('cpu')\n","    return device\n","\n","def df_to_tensor(df):\n","    device = get_device()\n","    return torch.from_numpy(df.values).float().to(device)\n","\n","def np_to_tensor(data):\n","    device = get_device()\n","    return torch.tensor(data).float().to(device)\n","\n","# configuration setting\n","def model_config():\n","    # parameter for CNN Model\n","    epochs = [30]\n","    batch_size = [32]\n","    learning_rate = [0.01, 0.001]\n","    \n","    # create config data\n","    configs = []\n","    for i in epochs:\n","        for j in batch_size:\n","            for k in learning_rate:\n","                config = [i, j, k]\n","                configs.append(config)\n","    return configs\n","\n","# fucntion for fit cnn model using configs\n","def model_fit(train_X, train_y, config, verbose=0):\n","\n","    # unpack config\n","    n_epochs, n_batch, learning_rate = config\n","    # use ShuffleNet for CNN\n","    model = ShuffleNet(groups=3, in_channels=1)\n","    if torch.cuda.is_available():\n","        model.cuda()\n","\n","    # define Loss and Optimizer\n","    criterion = nn.MSELoss()\n","    optimizer = optim.Adam(model.parameters(), lr=learning_rate)\n","\n","    data_size = train_X.size(0)\n","    max_iters = data_size//n_batch\n","\n","    for epoch in range(1, n_epochs+1):\n","        #shuffle data\n","        idx = numpy.random.permutation(numpy.arange(data_size))\n","        x_data = train_X[idx]\n","        y_data = train_y[idx]\n","\n","        epoch_loss = 0\n","        start_time = time.time()\n","        for it in range(max_iters):\n","            batch_x = x_data[it*n_batch:(it+1)*n_batch]\n","            batch_y = y_data[it*n_batch:(it+1)*n_batch]\n","\n","            optimizer.zero_grad()\n","            predict = model(batch_x)\n","            loss = criterion(predict, batch_y)\n","            loss.backward()\n","            optimizer.step()\n","\n","            epoch_loss+= loss.item()\n","        avg_loss = epoch_loss/max_iters\n","\n","        if verbose:\n","            duration = start_time-time.time()\n","            print(f'epoch:{epoch}/{epochs}, ì‹œê°„:{duration:.2f}[s], loss:{avg_loss:.5f}')\n","\n","\n","    return model\n","\n","def MAE_metric(x, t):\n","    t = np.array(t)\n","    return np.mean(numpy.abs(x-t))\n","\n","def MSE_metric(x, t):\n","    t = np.array(t)\n","    return np.mean((x-t)**2)"],"execution_count":4,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":223},"id":"T5VlnvXwOc9l","executionInfo":{"status":"ok","timestamp":1625386278295,"user_tz":-540,"elapsed":460,"user":{"displayName":"윤건일","photoUrl":"","userId":"05157393038207945770"}},"outputId":"fe6cad18-26b7-4703-86b1-d4f9c1b70896"},"source":["import pandas as pd\n","import numpy as np\n","import numpy\n","import time\n","from datetime import datetime\n","\n","np.random.seed(42)\n","numpy.random.seed(42)\n","\n","data_url = 'https://archive.ics.uci.edu/ml/machine-learning-databases/00247/'\n","data_name = 'data_akbilgic.xlsx'\n","df = pd.read_excel(data_url+data_name, header=1)\n","df.drop(columns=df.columns[[0]], axis=1, inplace=True)\n","df.head()"],"execution_count":5,"outputs":[{"output_type":"execute_result","data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>ISE</th>\n","      <th>ISE.1</th>\n","      <th>SP</th>\n","      <th>DAX</th>\n","      <th>FTSE</th>\n","      <th>NIKKEI</th>\n","      <th>BOVESPA</th>\n","      <th>EU</th>\n","      <th>EM</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>0.035754</td>\n","      <td>0.038376</td>\n","      <td>-0.004679</td>\n","      <td>0.002193</td>\n","      <td>0.003894</td>\n","      <td>0.000000</td>\n","      <td>0.031190</td>\n","      <td>0.012698</td>\n","      <td>0.028524</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>0.025426</td>\n","      <td>0.031813</td>\n","      <td>0.007787</td>\n","      <td>0.008455</td>\n","      <td>0.012866</td>\n","      <td>0.004162</td>\n","      <td>0.018920</td>\n","      <td>0.011341</td>\n","      <td>0.008773</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>-0.028862</td>\n","      <td>-0.026353</td>\n","      <td>-0.030469</td>\n","      <td>-0.017833</td>\n","      <td>-0.028735</td>\n","      <td>0.017293</td>\n","      <td>-0.035899</td>\n","      <td>-0.017073</td>\n","      <td>-0.020015</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>-0.062208</td>\n","      <td>-0.084716</td>\n","      <td>0.003391</td>\n","      <td>-0.011726</td>\n","      <td>-0.000466</td>\n","      <td>-0.040061</td>\n","      <td>0.028283</td>\n","      <td>-0.005561</td>\n","      <td>-0.019424</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>0.009860</td>\n","      <td>0.009658</td>\n","      <td>-0.021533</td>\n","      <td>-0.019873</td>\n","      <td>-0.012710</td>\n","      <td>-0.004474</td>\n","      <td>-0.009764</td>\n","      <td>-0.010989</td>\n","      <td>-0.007802</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["        ISE     ISE.1        SP  ...   BOVESPA        EU        EM\n","0  0.035754  0.038376 -0.004679  ...  0.031190  0.012698  0.028524\n","1  0.025426  0.031813  0.007787  ...  0.018920  0.011341  0.008773\n","2 -0.028862 -0.026353 -0.030469  ... -0.035899 -0.017073 -0.020015\n","3 -0.062208 -0.084716  0.003391  ...  0.028283 -0.005561 -0.019424\n","4  0.009860  0.009658 -0.021533  ... -0.009764 -0.010989 -0.007802\n","\n","[5 rows x 9 columns]"]},"metadata":{"tags":[]},"execution_count":5}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"k0aUQgIHL6Hg","executionInfo":{"status":"ok","timestamp":1625386278624,"user_tz":-540,"elapsed":332,"user":{"displayName":"윤건일","photoUrl":"","userId":"05157393038207945770"}},"outputId":"f6f907f1-4a15-46c2-e5ce-cc831e46bbed"},"source":["from scipy.stats import skew, kurtosis\n","from statsmodels.tsa.stattools import adfuller\n","\n","# jb = (n/6)*(skewness**2 + (kurtosis**2/4))\n","\n","def data_statistics(df):\n","    df = df.dropna()\n","    data = df.values\n","    num = len(df)\n","    skewness_ = skew(data)\n","    kurtosis_ = kurtosis(data)\n","    jarque_bera_ = (num/6)*(skewness_**2 + (kurtosis_**2/4))\n","    result = adfuller(data)\n","    adf_ = result[0]\n","    print(f'skewness : {skewness_}')\n","    print(f'kurtosis : {kurtosis_}')\n","    print(f'jarque bera : {jarque_bera_}')\n","    print(f'ADF : {adf_}')\n","\n","data_statistics(df['ISE'])"],"execution_count":6,"outputs":[{"output_type":"stream","text":["/usr/local/lib/python3.7/dist-packages/statsmodels/tools/_testing.py:19: FutureWarning: pandas.util.testing is deprecated. Use the functions in the public API at pandas.testing instead.\n","  import pandas.util.testing as tm\n"],"name":"stderr"},{"output_type":"stream","text":["skewness : -0.09471168518047181\n","kurtosis : 1.3911438852164864\n","jarque bera : 44.02262967171534\n","ADF : -22.746992812220288\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":315},"id":"mllFwsJ2L8Qk","executionInfo":{"status":"ok","timestamp":1625386278946,"user_tz":-540,"elapsed":325,"user":{"displayName":"윤건일","photoUrl":"","userId":"05157393038207945770"}},"outputId":"be2f3fd8-07e6-41c7-b8de-a827c36c1325"},"source":["df.describe()"],"execution_count":7,"outputs":[{"output_type":"execute_result","data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>ISE</th>\n","      <th>ISE.1</th>\n","      <th>SP</th>\n","      <th>DAX</th>\n","      <th>FTSE</th>\n","      <th>NIKKEI</th>\n","      <th>BOVESPA</th>\n","      <th>EU</th>\n","      <th>EM</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>count</th>\n","      <td>536.000000</td>\n","      <td>536.000000</td>\n","      <td>536.000000</td>\n","      <td>536.000000</td>\n","      <td>536.000000</td>\n","      <td>536.000000</td>\n","      <td>536.000000</td>\n","      <td>536.000000</td>\n","      <td>536.000000</td>\n","    </tr>\n","    <tr>\n","      <th>mean</th>\n","      <td>0.001629</td>\n","      <td>0.001552</td>\n","      <td>0.000643</td>\n","      <td>0.000721</td>\n","      <td>0.000510</td>\n","      <td>0.000308</td>\n","      <td>0.000935</td>\n","      <td>0.000471</td>\n","      <td>0.000936</td>\n","    </tr>\n","    <tr>\n","      <th>std</th>\n","      <td>0.016264</td>\n","      <td>0.021122</td>\n","      <td>0.014093</td>\n","      <td>0.014557</td>\n","      <td>0.012656</td>\n","      <td>0.014850</td>\n","      <td>0.015751</td>\n","      <td>0.012990</td>\n","      <td>0.010501</td>\n","    </tr>\n","    <tr>\n","      <th>min</th>\n","      <td>-0.062208</td>\n","      <td>-0.084716</td>\n","      <td>-0.054262</td>\n","      <td>-0.052331</td>\n","      <td>-0.054816</td>\n","      <td>-0.050448</td>\n","      <td>-0.053849</td>\n","      <td>-0.048817</td>\n","      <td>-0.038564</td>\n","    </tr>\n","    <tr>\n","      <th>25%</th>\n","      <td>-0.006669</td>\n","      <td>-0.009753</td>\n","      <td>-0.004675</td>\n","      <td>-0.006212</td>\n","      <td>-0.005808</td>\n","      <td>-0.007407</td>\n","      <td>-0.007215</td>\n","      <td>-0.005952</td>\n","      <td>-0.004911</td>\n","    </tr>\n","    <tr>\n","      <th>50%</th>\n","      <td>0.002189</td>\n","      <td>0.002643</td>\n","      <td>0.000876</td>\n","      <td>0.000887</td>\n","      <td>0.000409</td>\n","      <td>0.000000</td>\n","      <td>0.000279</td>\n","      <td>0.000196</td>\n","      <td>0.001077</td>\n","    </tr>\n","    <tr>\n","      <th>75%</th>\n","      <td>0.010584</td>\n","      <td>0.013809</td>\n","      <td>0.006706</td>\n","      <td>0.008224</td>\n","      <td>0.007428</td>\n","      <td>0.007882</td>\n","      <td>0.008881</td>\n","      <td>0.007792</td>\n","      <td>0.006423</td>\n","    </tr>\n","    <tr>\n","      <th>max</th>\n","      <td>0.068952</td>\n","      <td>0.100621</td>\n","      <td>0.068366</td>\n","      <td>0.058951</td>\n","      <td>0.050323</td>\n","      <td>0.061229</td>\n","      <td>0.063792</td>\n","      <td>0.067042</td>\n","      <td>0.047805</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["              ISE       ISE.1          SP  ...     BOVESPA          EU          EM\n","count  536.000000  536.000000  536.000000  ...  536.000000  536.000000  536.000000\n","mean     0.001629    0.001552    0.000643  ...    0.000935    0.000471    0.000936\n","std      0.016264    0.021122    0.014093  ...    0.015751    0.012990    0.010501\n","min     -0.062208   -0.084716   -0.054262  ...   -0.053849   -0.048817   -0.038564\n","25%     -0.006669   -0.009753   -0.004675  ...   -0.007215   -0.005952   -0.004911\n","50%      0.002189    0.002643    0.000876  ...    0.000279    0.000196    0.001077\n","75%      0.010584    0.013809    0.006706  ...    0.008881    0.007792    0.006423\n","max      0.068952    0.100621    0.068366  ...    0.063792    0.067042    0.047805\n","\n","[8 rows x 9 columns]"]},"metadata":{"tags":[]},"execution_count":7}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"_Jvj3zL5L-Wx","executionInfo":{"status":"ok","timestamp":1625386278949,"user_tz":-540,"elapsed":19,"user":{"displayName":"윤건일","photoUrl":"","userId":"05157393038207945770"}},"outputId":"02be5985-1b25-4101-d9b6-b8003e223fae"},"source":["df.isnull().sum()"],"execution_count":8,"outputs":[{"output_type":"execute_result","data":{"text/plain":["ISE        0\n","ISE.1      0\n","SP         0\n","DAX        0\n","FTSE       0\n","NIKKEI     0\n","BOVESPA    0\n","EU         0\n","EM         0\n","dtype: int64"]},"metadata":{"tags":[]},"execution_count":8}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":269},"id":"7MkZpWvbOwHS","executionInfo":{"status":"ok","timestamp":1625386279237,"user_tz":-540,"elapsed":296,"user":{"displayName":"윤건일","photoUrl":"","userId":"05157393038207945770"}},"outputId":"cd7dc386-2ab4-48a8-bafb-5c136027ea32"},"source":["# series data to img function\n","def series_to_img(dataset, time_step=1):\n","    num = dataset.shape[1]      # features num\n","    df = pd.DataFrame(dataset)\n","    cols, names = list(), list()\n","    # sequence t-n to t-1\n","    for i in range(time_step, 0, -1):\n","        cols.append(df.shift(i))\n","        names += [('var%d(t-%d)' % (j+1, i)) for j in range(num)]\n","\n","    for i in range(0, 1):\n","        cols.append(df.shift(-i))\n","        if i == 0:\n","            names += [('var%d(t)' % (j+1)) for j in range(num)]\n","        else:\n","            names += [('var%d(t+%d)' % (j+1, i)) for j in range(num)]\n","\n","    agg = pd.concat(cols, axis=1)\n","    agg.columns = names\n","    agg.dropna(inplace=True)\n","    return agg\n","\n","from sklearn.model_selection import TimeSeriesSplit\n","from sklearn.preprocessing import MinMaxScaler\n","\n","dataset = df.values\n","dataset = dataset.astype('float')\n","\n","n_inputs = 24\n","n_features = 9\n","del_idx = n_inputs * n_features + 1\n","del_cols = [i for i in range(del_idx, del_idx+n_features-1)]\n","new_df = series_to_img(dataset, n_inputs)\n","new_df.drop(new_df.columns[del_cols], axis=1, inplace=True)\n","new_df.head()"],"execution_count":9,"outputs":[{"output_type":"execute_result","data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>var1(t-24)</th>\n","      <th>var2(t-24)</th>\n","      <th>var3(t-24)</th>\n","      <th>var4(t-24)</th>\n","      <th>var5(t-24)</th>\n","      <th>var6(t-24)</th>\n","      <th>var7(t-24)</th>\n","      <th>var8(t-24)</th>\n","      <th>var9(t-24)</th>\n","      <th>var1(t-23)</th>\n","      <th>var2(t-23)</th>\n","      <th>var3(t-23)</th>\n","      <th>var4(t-23)</th>\n","      <th>var5(t-23)</th>\n","      <th>var6(t-23)</th>\n","      <th>var7(t-23)</th>\n","      <th>var8(t-23)</th>\n","      <th>var9(t-23)</th>\n","      <th>var1(t-22)</th>\n","      <th>var2(t-22)</th>\n","      <th>var3(t-22)</th>\n","      <th>var4(t-22)</th>\n","      <th>var5(t-22)</th>\n","      <th>var6(t-22)</th>\n","      <th>var7(t-22)</th>\n","      <th>var8(t-22)</th>\n","      <th>var9(t-22)</th>\n","      <th>var1(t-21)</th>\n","      <th>var2(t-21)</th>\n","      <th>var3(t-21)</th>\n","      <th>var4(t-21)</th>\n","      <th>var5(t-21)</th>\n","      <th>var6(t-21)</th>\n","      <th>var7(t-21)</th>\n","      <th>var8(t-21)</th>\n","      <th>var9(t-21)</th>\n","      <th>var1(t-20)</th>\n","      <th>var2(t-20)</th>\n","      <th>var3(t-20)</th>\n","      <th>var4(t-20)</th>\n","      <th>...</th>\n","      <th>var7(t-5)</th>\n","      <th>var8(t-5)</th>\n","      <th>var9(t-5)</th>\n","      <th>var1(t-4)</th>\n","      <th>var2(t-4)</th>\n","      <th>var3(t-4)</th>\n","      <th>var4(t-4)</th>\n","      <th>var5(t-4)</th>\n","      <th>var6(t-4)</th>\n","      <th>var7(t-4)</th>\n","      <th>var8(t-4)</th>\n","      <th>var9(t-4)</th>\n","      <th>var1(t-3)</th>\n","      <th>var2(t-3)</th>\n","      <th>var3(t-3)</th>\n","      <th>var4(t-3)</th>\n","      <th>var5(t-3)</th>\n","      <th>var6(t-3)</th>\n","      <th>var7(t-3)</th>\n","      <th>var8(t-3)</th>\n","      <th>var9(t-3)</th>\n","      <th>var1(t-2)</th>\n","      <th>var2(t-2)</th>\n","      <th>var3(t-2)</th>\n","      <th>var4(t-2)</th>\n","      <th>var5(t-2)</th>\n","      <th>var6(t-2)</th>\n","      <th>var7(t-2)</th>\n","      <th>var8(t-2)</th>\n","      <th>var9(t-2)</th>\n","      <th>var1(t-1)</th>\n","      <th>var2(t-1)</th>\n","      <th>var3(t-1)</th>\n","      <th>var4(t-1)</th>\n","      <th>var5(t-1)</th>\n","      <th>var6(t-1)</th>\n","      <th>var7(t-1)</th>\n","      <th>var8(t-1)</th>\n","      <th>var9(t-1)</th>\n","      <th>var1(t)</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>24</th>\n","      <td>0.035754</td>\n","      <td>0.038376</td>\n","      <td>-0.004679</td>\n","      <td>0.002193</td>\n","      <td>0.003894</td>\n","      <td>0.000000</td>\n","      <td>0.031190</td>\n","      <td>0.012698</td>\n","      <td>0.028524</td>\n","      <td>0.025426</td>\n","      <td>0.031813</td>\n","      <td>0.007787</td>\n","      <td>0.008455</td>\n","      <td>0.012866</td>\n","      <td>0.004162</td>\n","      <td>0.018920</td>\n","      <td>0.011341</td>\n","      <td>0.008773</td>\n","      <td>-0.028862</td>\n","      <td>-0.026353</td>\n","      <td>-0.030469</td>\n","      <td>-0.017833</td>\n","      <td>-0.028735</td>\n","      <td>0.017293</td>\n","      <td>-0.035899</td>\n","      <td>-0.017073</td>\n","      <td>-0.020015</td>\n","      <td>-0.062208</td>\n","      <td>-0.084716</td>\n","      <td>0.003391</td>\n","      <td>-0.011726</td>\n","      <td>-0.000466</td>\n","      <td>-0.040061</td>\n","      <td>0.028283</td>\n","      <td>-0.005561</td>\n","      <td>-0.019424</td>\n","      <td>0.009860</td>\n","      <td>0.009658</td>\n","      <td>-0.021533</td>\n","      <td>-0.019873</td>\n","      <td>...</td>\n","      <td>-0.008538</td>\n","      <td>-0.007201</td>\n","      <td>0.002243</td>\n","      <td>-0.025919</td>\n","      <td>-0.035607</td>\n","      <td>-0.000533</td>\n","      <td>-0.015637</td>\n","      <td>-0.017454</td>\n","      <td>-0.015134</td>\n","      <td>-0.016289</td>\n","      <td>-0.019739</td>\n","      <td>-0.019091</td>\n","      <td>0.015279</td>\n","      <td>0.022403</td>\n","      <td>0.015710</td>\n","      <td>0.024040</td>\n","      <td>0.021039</td>\n","      <td>-0.006175</td>\n","      <td>0.027574</td>\n","      <td>0.017862</td>\n","      <td>0.012719</td>\n","      <td>0.018578</td>\n","      <td>0.023231</td>\n","      <td>-0.007518</td>\n","      <td>0.026577</td>\n","      <td>0.015275</td>\n","      <td>0.026908</td>\n","      <td>0.009565</td>\n","      <td>0.018770</td>\n","      <td>0.015166</td>\n","      <td>-0.014133</td>\n","      <td>-0.014571</td>\n","      <td>0.016233</td>\n","      <td>0.003932</td>\n","      <td>0.000071</td>\n","      <td>-0.011169</td>\n","      <td>0.024128</td>\n","      <td>-0.004139</td>\n","      <td>0.002073</td>\n","      <td>0.036607</td>\n","    </tr>\n","    <tr>\n","      <th>25</th>\n","      <td>0.025426</td>\n","      <td>0.031813</td>\n","      <td>0.007787</td>\n","      <td>0.008455</td>\n","      <td>0.012866</td>\n","      <td>0.004162</td>\n","      <td>0.018920</td>\n","      <td>0.011341</td>\n","      <td>0.008773</td>\n","      <td>-0.028862</td>\n","      <td>-0.026353</td>\n","      <td>-0.030469</td>\n","      <td>-0.017833</td>\n","      <td>-0.028735</td>\n","      <td>0.017293</td>\n","      <td>-0.035899</td>\n","      <td>-0.017073</td>\n","      <td>-0.020015</td>\n","      <td>-0.062208</td>\n","      <td>-0.084716</td>\n","      <td>0.003391</td>\n","      <td>-0.011726</td>\n","      <td>-0.000466</td>\n","      <td>-0.040061</td>\n","      <td>0.028283</td>\n","      <td>-0.005561</td>\n","      <td>-0.019424</td>\n","      <td>0.009860</td>\n","      <td>0.009658</td>\n","      <td>-0.021533</td>\n","      <td>-0.019873</td>\n","      <td>-0.012710</td>\n","      <td>-0.004474</td>\n","      <td>-0.009764</td>\n","      <td>-0.010989</td>\n","      <td>-0.007802</td>\n","      <td>-0.029191</td>\n","      <td>-0.042361</td>\n","      <td>-0.022823</td>\n","      <td>-0.013526</td>\n","      <td>...</td>\n","      <td>-0.016289</td>\n","      <td>-0.019739</td>\n","      <td>-0.019091</td>\n","      <td>0.015279</td>\n","      <td>0.022403</td>\n","      <td>0.015710</td>\n","      <td>0.024040</td>\n","      <td>0.021039</td>\n","      <td>-0.006175</td>\n","      <td>0.027574</td>\n","      <td>0.017862</td>\n","      <td>0.012719</td>\n","      <td>0.018578</td>\n","      <td>0.023231</td>\n","      <td>-0.007518</td>\n","      <td>0.026577</td>\n","      <td>0.015275</td>\n","      <td>0.026908</td>\n","      <td>0.009565</td>\n","      <td>0.018770</td>\n","      <td>0.015166</td>\n","      <td>-0.014133</td>\n","      <td>-0.014571</td>\n","      <td>0.016233</td>\n","      <td>0.003932</td>\n","      <td>0.000071</td>\n","      <td>-0.011169</td>\n","      <td>0.024128</td>\n","      <td>-0.004139</td>\n","      <td>0.002073</td>\n","      <td>0.036607</td>\n","      <td>0.042759</td>\n","      <td>0.026541</td>\n","      <td>0.029306</td>\n","      <td>0.014788</td>\n","      <td>0.015846</td>\n","      <td>0.039282</td>\n","      <td>0.019127</td>\n","      <td>0.032338</td>\n","      <td>0.011353</td>\n","    </tr>\n","    <tr>\n","      <th>26</th>\n","      <td>-0.028862</td>\n","      <td>-0.026353</td>\n","      <td>-0.030469</td>\n","      <td>-0.017833</td>\n","      <td>-0.028735</td>\n","      <td>0.017293</td>\n","      <td>-0.035899</td>\n","      <td>-0.017073</td>\n","      <td>-0.020015</td>\n","      <td>-0.062208</td>\n","      <td>-0.084716</td>\n","      <td>0.003391</td>\n","      <td>-0.011726</td>\n","      <td>-0.000466</td>\n","      <td>-0.040061</td>\n","      <td>0.028283</td>\n","      <td>-0.005561</td>\n","      <td>-0.019424</td>\n","      <td>0.009860</td>\n","      <td>0.009658</td>\n","      <td>-0.021533</td>\n","      <td>-0.019873</td>\n","      <td>-0.012710</td>\n","      <td>-0.004474</td>\n","      <td>-0.009764</td>\n","      <td>-0.010989</td>\n","      <td>-0.007802</td>\n","      <td>-0.029191</td>\n","      <td>-0.042361</td>\n","      <td>-0.022823</td>\n","      <td>-0.013526</td>\n","      <td>-0.005026</td>\n","      <td>-0.049039</td>\n","      <td>-0.053849</td>\n","      <td>-0.012451</td>\n","      <td>-0.022630</td>\n","      <td>0.015445</td>\n","      <td>-0.000272</td>\n","      <td>0.001757</td>\n","      <td>-0.017674</td>\n","      <td>...</td>\n","      <td>0.027574</td>\n","      <td>0.017862</td>\n","      <td>0.012719</td>\n","      <td>0.018578</td>\n","      <td>0.023231</td>\n","      <td>-0.007518</td>\n","      <td>0.026577</td>\n","      <td>0.015275</td>\n","      <td>0.026908</td>\n","      <td>0.009565</td>\n","      <td>0.018770</td>\n","      <td>0.015166</td>\n","      <td>-0.014133</td>\n","      <td>-0.014571</td>\n","      <td>0.016233</td>\n","      <td>0.003932</td>\n","      <td>0.000071</td>\n","      <td>-0.011169</td>\n","      <td>0.024128</td>\n","      <td>-0.004139</td>\n","      <td>0.002073</td>\n","      <td>0.036607</td>\n","      <td>0.042759</td>\n","      <td>0.026541</td>\n","      <td>0.029306</td>\n","      <td>0.014788</td>\n","      <td>0.015846</td>\n","      <td>0.039282</td>\n","      <td>0.019127</td>\n","      <td>0.032338</td>\n","      <td>0.011353</td>\n","      <td>0.021468</td>\n","      <td>0.001484</td>\n","      <td>0.004766</td>\n","      <td>0.003651</td>\n","      <td>-0.013411</td>\n","      <td>-0.015462</td>\n","      <td>0.005627</td>\n","      <td>0.007895</td>\n","      <td>-0.040542</td>\n","    </tr>\n","    <tr>\n","      <th>27</th>\n","      <td>-0.062208</td>\n","      <td>-0.084716</td>\n","      <td>0.003391</td>\n","      <td>-0.011726</td>\n","      <td>-0.000466</td>\n","      <td>-0.040061</td>\n","      <td>0.028283</td>\n","      <td>-0.005561</td>\n","      <td>-0.019424</td>\n","      <td>0.009860</td>\n","      <td>0.009658</td>\n","      <td>-0.021533</td>\n","      <td>-0.019873</td>\n","      <td>-0.012710</td>\n","      <td>-0.004474</td>\n","      <td>-0.009764</td>\n","      <td>-0.010989</td>\n","      <td>-0.007802</td>\n","      <td>-0.029191</td>\n","      <td>-0.042361</td>\n","      <td>-0.022823</td>\n","      <td>-0.013526</td>\n","      <td>-0.005026</td>\n","      <td>-0.049039</td>\n","      <td>-0.053849</td>\n","      <td>-0.012451</td>\n","      <td>-0.022630</td>\n","      <td>0.015445</td>\n","      <td>-0.000272</td>\n","      <td>0.001757</td>\n","      <td>-0.017674</td>\n","      <td>-0.006141</td>\n","      <td>0.000000</td>\n","      <td>0.003572</td>\n","      <td>-0.012220</td>\n","      <td>-0.004827</td>\n","      <td>-0.041168</td>\n","      <td>-0.035552</td>\n","      <td>-0.034032</td>\n","      <td>-0.047383</td>\n","      <td>...</td>\n","      <td>0.009565</td>\n","      <td>0.018770</td>\n","      <td>0.015166</td>\n","      <td>-0.014133</td>\n","      <td>-0.014571</td>\n","      <td>0.016233</td>\n","      <td>0.003932</td>\n","      <td>0.000071</td>\n","      <td>-0.011169</td>\n","      <td>0.024128</td>\n","      <td>-0.004139</td>\n","      <td>0.002073</td>\n","      <td>0.036607</td>\n","      <td>0.042759</td>\n","      <td>0.026541</td>\n","      <td>0.029306</td>\n","      <td>0.014788</td>\n","      <td>0.015846</td>\n","      <td>0.039282</td>\n","      <td>0.019127</td>\n","      <td>0.032338</td>\n","      <td>0.011353</td>\n","      <td>0.021468</td>\n","      <td>0.001484</td>\n","      <td>0.004766</td>\n","      <td>0.003651</td>\n","      <td>-0.013411</td>\n","      <td>-0.015462</td>\n","      <td>0.005627</td>\n","      <td>0.007895</td>\n","      <td>-0.040542</td>\n","      <td>-0.043907</td>\n","      <td>-0.050369</td>\n","      <td>-0.035170</td>\n","      <td>-0.022182</td>\n","      <td>-0.002902</td>\n","      <td>-0.021440</td>\n","      <td>-0.024388</td>\n","      <td>-0.002139</td>\n","      <td>-0.022106</td>\n","    </tr>\n","    <tr>\n","      <th>28</th>\n","      <td>0.009860</td>\n","      <td>0.009658</td>\n","      <td>-0.021533</td>\n","      <td>-0.019873</td>\n","      <td>-0.012710</td>\n","      <td>-0.004474</td>\n","      <td>-0.009764</td>\n","      <td>-0.010989</td>\n","      <td>-0.007802</td>\n","      <td>-0.029191</td>\n","      <td>-0.042361</td>\n","      <td>-0.022823</td>\n","      <td>-0.013526</td>\n","      <td>-0.005026</td>\n","      <td>-0.049039</td>\n","      <td>-0.053849</td>\n","      <td>-0.012451</td>\n","      <td>-0.022630</td>\n","      <td>0.015445</td>\n","      <td>-0.000272</td>\n","      <td>0.001757</td>\n","      <td>-0.017674</td>\n","      <td>-0.006141</td>\n","      <td>0.000000</td>\n","      <td>0.003572</td>\n","      <td>-0.012220</td>\n","      <td>-0.004827</td>\n","      <td>-0.041168</td>\n","      <td>-0.035552</td>\n","      <td>-0.034032</td>\n","      <td>-0.047383</td>\n","      <td>-0.050945</td>\n","      <td>0.002912</td>\n","      <td>-0.040302</td>\n","      <td>-0.045220</td>\n","      <td>-0.008677</td>\n","      <td>0.000662</td>\n","      <td>-0.017268</td>\n","      <td>0.001328</td>\n","      <td>-0.019551</td>\n","      <td>...</td>\n","      <td>0.024128</td>\n","      <td>-0.004139</td>\n","      <td>0.002073</td>\n","      <td>0.036607</td>\n","      <td>0.042759</td>\n","      <td>0.026541</td>\n","      <td>0.029306</td>\n","      <td>0.014788</td>\n","      <td>0.015846</td>\n","      <td>0.039282</td>\n","      <td>0.019127</td>\n","      <td>0.032338</td>\n","      <td>0.011353</td>\n","      <td>0.021468</td>\n","      <td>0.001484</td>\n","      <td>0.004766</td>\n","      <td>0.003651</td>\n","      <td>-0.013411</td>\n","      <td>-0.015462</td>\n","      <td>0.005627</td>\n","      <td>0.007895</td>\n","      <td>-0.040542</td>\n","      <td>-0.043907</td>\n","      <td>-0.050369</td>\n","      <td>-0.035170</td>\n","      <td>-0.022182</td>\n","      <td>-0.002902</td>\n","      <td>-0.021440</td>\n","      <td>-0.024388</td>\n","      <td>-0.002139</td>\n","      <td>-0.022106</td>\n","      <td>-0.033893</td>\n","      <td>0.007923</td>\n","      <td>0.005434</td>\n","      <td>0.005019</td>\n","      <td>-0.030745</td>\n","      <td>-0.008799</td>\n","      <td>0.001097</td>\n","      <td>-0.007926</td>\n","      <td>-0.014888</td>\n","    </tr>\n","  </tbody>\n","</table>\n","<p>5 rows × 217 columns</p>\n","</div>"],"text/plain":["    var1(t-24)  var2(t-24)  var3(t-24)  ...  var8(t-1)  var9(t-1)   var1(t)\n","24    0.035754    0.038376   -0.004679  ...  -0.004139   0.002073  0.036607\n","25    0.025426    0.031813    0.007787  ...   0.019127   0.032338  0.011353\n","26   -0.028862   -0.026353   -0.030469  ...   0.005627   0.007895 -0.040542\n","27   -0.062208   -0.084716    0.003391  ...  -0.024388  -0.002139 -0.022106\n","28    0.009860    0.009658   -0.021533  ...   0.001097  -0.007926 -0.014888\n","\n","[5 rows x 217 columns]"]},"metadata":{"tags":[]},"execution_count":9}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"n_miO_GTPSuB","executionInfo":{"status":"ok","timestamp":1625386487062,"user_tz":-540,"elapsed":207833,"user":{"displayName":"윤건일","photoUrl":"","userId":"05157393038207945770"}},"outputId":"cdbec724-9aa4-417b-9de6-a7c08d7c9dac"},"source":["n_splits = 10\n","train_test_split = TimeSeriesSplit(n_splits=n_splits+1, gap=n_inputs).split(new_df)\n","next(train_test_split)\n","\n","configs = model_config()\n","history = []\n","\n","best_rmse, best_mse, best_mae = [], [], []\n","learning_time = []\n","\n","i = 1\n","\n","print('config : epochs, batch_size, learning_rate')\n","\n","# nested cross validation for time series model\n","for train_cv_indices, test_cv_indices in train_test_split:\n","    print(f'fold : {i}/{n_splits}')\n","    i+=1\n","\n","    # split x, y data\n","    train_cv_X, train_cv_y = new_df.iloc[train_cv_indices, :-1].values, new_df.iloc[train_cv_indices,-1].values\n","    test_cv_X, test_cv_y = new_df.iloc[test_cv_indices, :-1].values, new_df.iloc[test_cv_indices, -1].values\n","\n","    # length for validation set\n","    test_length = int(len(train_cv_X)*0.2)\n","\n","    # scaling data\n","    scaler_x = MinMaxScaler()\n","    train_cv_X = scaler_x.fit_transform(train_cv_X)\n","    test_cv_X = scaler_x.transform(test_cv_X)\n","\n","    train_X, val_X = train_cv_X[:-test_length, :], train_cv_X[-test_length:, :]\n","    train_y, val_y = train_cv_y[:-test_length], train_cv_y[-test_length:]\n","\n","    # reshape\n","    # inner loop\n","    train_X = train_X.reshape(-1, 1, n_inputs, n_features)\n","    val_X = val_X.reshape(-1, 1, n_inputs, n_features)\n","    train_y = train_y.reshape(-1, 1)\n","    val_y = val_y.reshape(-1, 1)\n","\n","    # outer loop\n","    train_cv_X = train_cv_X.reshape(-1, 1, n_inputs, n_features)\n","    test_cv_X = test_cv_X.reshape(-1, 1, n_inputs, n_features)\n","    train_cv_y = train_cv_y.reshape(-1, 1)\n","    test_cv_y = test_cv_y.reshape(-1, 1)\n","\n","    train_X = np_to_tensor(train_X)\n","    train_y = np_to_tensor(train_y)\n","    val_X = np_to_tensor(val_X)\n","    val_y = np_to_tensor(val_y)\n","    train_cv_X = np_to_tensor(train_cv_X)\n","    train_cv_y = np_to_tensor(train_cv_y)\n","    test_cv_X = np_to_tensor(test_cv_X)\n","    test_cv_y = np_to_tensor(test_cv_y)\n","\n","    # model fit, inner\n","    errors = []\n","    for idx, cfg in enumerate(configs):\n","        print(f' == train {cfg} model == ', end=' ')\n","        model = model_fit(train_X, train_y, cfg)\n","        predicted = model(val_X)\n","        error = F.mse_loss(predicted, val_y)   # rmse\n","        print(f'error(rmse):{error.item():.2f}')\n","        if errors:\n","            if error.item() < min(errors):\n","                param = idx\n","        else:\n","            param = idx\n","        errors.append(error.item())\n","\n","    history.append(errors)\n","\n","    # outer\n","    start_time = time.time()\n","    # model fitting\n","    selected_model = model_fit(train_cv_X,train_cv_y, configs[param])\n","    # check time\n","    duration = time.time() - start_time\n","    predicted = selected_model(test_cv_X)\n","    rmse = np.sqrt(F.mse_loss(predicted, test_cv_y).item())\n","    mse = F.mse_loss(predicted, test_cv_y)\n","    mae = F.l1_loss(predicted, test_cv_y)\n","    best_rmse.append(rmse)\n","    best_mse.append(mse.item())\n","    best_mae.append(mae.item())\n","    learning_time.append(duration)\n","\n","    # model eval\n","    print(f'train-size:{train_X.size(0)}, val-size:{val_X.size(0)}, test-size:{test_cv_X.size(0)}')\n","    print(f'best_model => error(rmse) : {rmse:.2f}, param:{configs[param]}, times: {duration:.3f}')\n","    print()"],"execution_count":10,"outputs":[{"output_type":"stream","text":["config : epochs, batch_size, learning_rate\n","fold : 1/10\n"," == train [30, 32, 0.01] model ==  "],"name":"stdout"},{"output_type":"stream","text":["/usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:718: UserWarning: Named tensors and all their associated APIs are an experimental feature and subject to change. Please do not use them for anything important until they are released as stable. (Triggered internally at  /pytorch/c10/core/TensorImpl.h:1156.)\n","  return torch.max_pool2d(input, kernel_size, stride, padding, dilation, ceil_mode)\n"],"name":"stderr"},{"output_type":"stream","text":["error(rmse):1.14\n"," == train [30, 32, 0.001] model ==  error(rmse):0.00\n","train-size:55, val-size:13, test-size:42\n","best_model => error(rmse) : 0.05, param:[30, 32, 0.001], times: 1.997\n","\n","fold : 2/10\n"," == train [30, 32, 0.01] model ==  error(rmse):0.00\n"," == train [30, 32, 0.001] model ==  error(rmse):0.00\n","train-size:88, val-size:22, test-size:42\n","best_model => error(rmse) : 0.02, param:[30, 32, 0.001], times: 3.056\n","\n","fold : 3/10\n"," == train [30, 32, 0.01] model ==  error(rmse):0.00\n"," == train [30, 32, 0.001] model ==  error(rmse):0.00\n","train-size:122, val-size:30, test-size:42\n","best_model => error(rmse) : 0.03, param:[30, 32, 0.001], times: 4.081\n","\n","fold : 4/10\n"," == train [30, 32, 0.01] model ==  error(rmse):0.00\n"," == train [30, 32, 0.001] model ==  error(rmse):0.00\n","train-size:156, val-size:38, test-size:42\n","best_model => error(rmse) : 0.03, param:[30, 32, 0.01], times: 6.017\n","\n","fold : 5/10\n"," == train [30, 32, 0.01] model ==  error(rmse):0.00\n"," == train [30, 32, 0.001] model ==  error(rmse):0.00\n","train-size:189, val-size:47, test-size:42\n","best_model => error(rmse) : 0.03, param:[30, 32, 0.01], times: 7.093\n","\n","fold : 6/10\n"," == train [30, 32, 0.01] model ==  error(rmse):0.00\n"," == train [30, 32, 0.001] model ==  error(rmse):0.00\n","train-size:223, val-size:55, test-size:42\n","best_model => error(rmse) : 0.02, param:[30, 32, 0.01], times: 8.015\n","\n","fold : 7/10\n"," == train [30, 32, 0.01] model ==  error(rmse):0.00\n"," == train [30, 32, 0.001] model ==  error(rmse):0.00\n","train-size:256, val-size:64, test-size:42\n","best_model => error(rmse) : 0.02, param:[30, 32, 0.001], times: 9.969\n","\n","fold : 8/10\n"," == train [30, 32, 0.01] model ==  error(rmse):0.00\n"," == train [30, 32, 0.001] model ==  error(rmse):0.00\n","train-size:290, val-size:72, test-size:42\n","best_model => error(rmse) : 0.02, param:[30, 32, 0.01], times: 11.033\n","\n","fold : 9/10\n"," == train [30, 32, 0.01] model ==  error(rmse):0.00\n"," == train [30, 32, 0.001] model ==  error(rmse):0.00\n","train-size:324, val-size:80, test-size:42\n","best_model => error(rmse) : 0.02, param:[30, 32, 0.001], times: 11.920\n","\n","fold : 10/10\n"," == train [30, 32, 0.01] model ==  error(rmse):0.00\n"," == train [30, 32, 0.001] model ==  error(rmse):0.00\n","train-size:357, val-size:89, test-size:42\n","best_model => error(rmse) : 0.02, param:[30, 32, 0.001], times: 13.056\n","\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"4bpP4O9tPo1d","executionInfo":{"status":"ok","timestamp":1625386487064,"user_tz":-540,"elapsed":18,"user":{"displayName":"윤건일","photoUrl":"","userId":"05157393038207945770"}},"outputId":"2cdcded0-b103-4e1c-dba2-d7ab89ecdea1"},"source":["predicted = selected_model(test_cv_X)\n","\n","def model_evaluation(mse, rmse, mae):\n","    mse = np.array(mse)\n","    rmse = np.array(rmse)\n","    mae = np.array(mae)\n","    print(f'MSE: mean={np.mean(mse)}, std={np.std(mse)}')\n","    print(f'RMSE: mean={np.mean(rmse)}, std={np.std(rmse)}')\n","    print(f'MAE: mean={np.mean(mae)}, std={np.std(mae)}')\n","\n","model_evaluation(best_mse, best_rmse, best_mae)\n","\n","# check time\n","print()\n","print('[training time]')\n","print(f'mean : {np.mean(np.array(learning_time))}, last:{learning_time[-1]}')"],"execution_count":11,"outputs":[{"output_type":"stream","text":["MSE: mean=0.0007644297060323879, std=0.0006739338074347463\n","RMSE: mean=0.02586333659639421, std=0.009773306816733215\n","MAE: mean=0.021324109472334384, std=0.00949006493493155\n","\n","[training time]\n","mean : 7.623658084869385, last:13.055800199508667\n"],"name":"stdout"}]}]}