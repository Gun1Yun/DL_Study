{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "cf997d24-f11a-4270-a854-97119610cc41",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "\n",
    "MODULE_PATH = 'C:\\Github\\DL_Study\\CNN'\n",
    "\n",
    "sys.path.insert(0, MODULE_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ae0264d9-5aac-4760-a7d1-4ce2763c8f55",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch._C.Generator at 0x262c67d9450>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# import\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import numpy\n",
    "import time\n",
    "\n",
    "from ShuffleNet import *\n",
    "\n",
    "# set random seed\n",
    "torch.manual_seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "84b27ec6-411a-4df8-8489-62ee43f73473",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_device():\n",
    "    if torch.cuda.is_available():\n",
    "        device = torch.device('cuda:0')\n",
    "    else:\n",
    "        device = torch.device('cpu')\n",
    "    return device\n",
    "\n",
    "def df_to_tensor(df):\n",
    "    device = get_device()\n",
    "    return torch.from_numpy(df.values).float().to(device)\n",
    "\n",
    "def np_to_tensor(data):\n",
    "    device = get_device()\n",
    "    return torch.tensor(data).float().to(device)\n",
    "\n",
    "# configuration setting\n",
    "def model_config():\n",
    "    # parameter for CNN Model\n",
    "    epochs = [30]\n",
    "    batch_size = [32]\n",
    "    learning_rate = [0.01, 0.001]\n",
    "    \n",
    "    # create config data\n",
    "    configs = []\n",
    "    for i in epochs:\n",
    "        for j in batch_size:\n",
    "            for k in learning_rate:\n",
    "                config = [i, j, k]\n",
    "                configs.append(config)\n",
    "    return configs\n",
    "\n",
    "# fucntion for fit cnn model using configs\n",
    "def model_fit(train_X, train_y, config, verbose=0):\n",
    "\n",
    "    # unpack config\n",
    "    n_epochs, n_batch, learning_rate = config\n",
    "    # use ShuffleNet for CNN\n",
    "    model = ShuffleNet(groups=3, in_channels=1)\n",
    "    if torch.cuda.is_available():\n",
    "        model.cuda()\n",
    "\n",
    "    # define Loss and Optimizer\n",
    "    criterion = nn.MSELoss()\n",
    "    optimizer = optim.Adam(model.parameters(), lr=learning_rate)\n",
    "\n",
    "    data_size = train_X.size(0)\n",
    "    max_iters = data_size//n_batch\n",
    "\n",
    "    for epoch in range(1, n_epochs+1):\n",
    "        #shuffle data\n",
    "        idx = numpy.random.permutation(numpy.arange(data_size))\n",
    "        x_data = train_X[idx]\n",
    "        y_data = train_y[idx]\n",
    "\n",
    "        epoch_loss = 0\n",
    "        start_time = time.time()\n",
    "        for it in range(max_iters):\n",
    "            batch_x = x_data[it*n_batch:(it+1)*n_batch]\n",
    "            batch_y = y_data[it*n_batch:(it+1)*n_batch]\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            predict = model(batch_x)\n",
    "            loss = criterion(predict, batch_y)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            epoch_loss+= loss.item()\n",
    "        avg_loss = epoch_loss/max_iters\n",
    "\n",
    "        if verbose:\n",
    "            duration = start_time-time.time()\n",
    "            print(f'epoch:{epoch}/{epochs}, ì‹œê°„:{duration:.2f}[s], loss:{avg_loss:.5f}')\n",
    "\n",
    "\n",
    "    return model\n",
    "\n",
    "def MAE_metric(x, t):\n",
    "    t = np.array(t)\n",
    "    return np.mean(numpy.abs(x-t))\n",
    "\n",
    "def MSE_metric(x, t):\n",
    "    t = np.array(t)\n",
    "    return np.mean((x-t)**2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3a72c1ab-0830-4628-a4e3-b274d4435435",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\lab\\AppData\\Local\\Temp/ipykernel_16808/1429609044.py:12: FutureWarning: Your version of xlrd is 1.2.0. In xlrd >= 2.0, only the xls format is supported. As a result, the openpyxl engine will be used if it is installed and the engine argument is not specified. Install openpyxl instead.\n",
      "  df = pd.read_excel(data_url+data_name, header=1)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ISE</th>\n",
       "      <th>ISE.1</th>\n",
       "      <th>SP</th>\n",
       "      <th>DAX</th>\n",
       "      <th>FTSE</th>\n",
       "      <th>NIKKEI</th>\n",
       "      <th>BOVESPA</th>\n",
       "      <th>EU</th>\n",
       "      <th>EM</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.035754</td>\n",
       "      <td>0.038376</td>\n",
       "      <td>-0.004679</td>\n",
       "      <td>0.002193</td>\n",
       "      <td>0.003894</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.031190</td>\n",
       "      <td>0.012698</td>\n",
       "      <td>0.028524</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.025426</td>\n",
       "      <td>0.031813</td>\n",
       "      <td>0.007787</td>\n",
       "      <td>0.008455</td>\n",
       "      <td>0.012866</td>\n",
       "      <td>0.004162</td>\n",
       "      <td>0.018920</td>\n",
       "      <td>0.011341</td>\n",
       "      <td>0.008773</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-0.028862</td>\n",
       "      <td>-0.026353</td>\n",
       "      <td>-0.030469</td>\n",
       "      <td>-0.017833</td>\n",
       "      <td>-0.028735</td>\n",
       "      <td>0.017293</td>\n",
       "      <td>-0.035899</td>\n",
       "      <td>-0.017073</td>\n",
       "      <td>-0.020015</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-0.062208</td>\n",
       "      <td>-0.084716</td>\n",
       "      <td>0.003391</td>\n",
       "      <td>-0.011726</td>\n",
       "      <td>-0.000466</td>\n",
       "      <td>-0.040061</td>\n",
       "      <td>0.028283</td>\n",
       "      <td>-0.005561</td>\n",
       "      <td>-0.019424</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.009860</td>\n",
       "      <td>0.009658</td>\n",
       "      <td>-0.021533</td>\n",
       "      <td>-0.019873</td>\n",
       "      <td>-0.012710</td>\n",
       "      <td>-0.004474</td>\n",
       "      <td>-0.009764</td>\n",
       "      <td>-0.010989</td>\n",
       "      <td>-0.007802</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        ISE     ISE.1        SP       DAX      FTSE    NIKKEI   BOVESPA  \\\n",
       "0  0.035754  0.038376 -0.004679  0.002193  0.003894  0.000000  0.031190   \n",
       "1  0.025426  0.031813  0.007787  0.008455  0.012866  0.004162  0.018920   \n",
       "2 -0.028862 -0.026353 -0.030469 -0.017833 -0.028735  0.017293 -0.035899   \n",
       "3 -0.062208 -0.084716  0.003391 -0.011726 -0.000466 -0.040061  0.028283   \n",
       "4  0.009860  0.009658 -0.021533 -0.019873 -0.012710 -0.004474 -0.009764   \n",
       "\n",
       "         EU        EM  \n",
       "0  0.012698  0.028524  \n",
       "1  0.011341  0.008773  \n",
       "2 -0.017073 -0.020015  \n",
       "3 -0.005561 -0.019424  \n",
       "4 -0.010989 -0.007802  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import numpy\n",
    "import time\n",
    "from datetime import datetime\n",
    "\n",
    "np.random.seed(42)\n",
    "numpy.random.seed(42)\n",
    "\n",
    "data_url = 'https://archive.ics.uci.edu/ml/machine-learning-databases/00247/'\n",
    "data_name = 'data_akbilgic.xlsx'\n",
    "df = pd.read_excel(data_url+data_name, header=1)\n",
    "df.drop(columns=df.columns[[0]], axis=1, inplace=True)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "dfed03ce-0add-4141-9e33-414470d6e8cb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>var1(t-24)</th>\n",
       "      <th>var2(t-24)</th>\n",
       "      <th>var3(t-24)</th>\n",
       "      <th>var4(t-24)</th>\n",
       "      <th>var5(t-24)</th>\n",
       "      <th>var6(t-24)</th>\n",
       "      <th>var7(t-24)</th>\n",
       "      <th>var8(t-24)</th>\n",
       "      <th>var9(t-24)</th>\n",
       "      <th>var1(t-23)</th>\n",
       "      <th>...</th>\n",
       "      <th>var1(t-1)</th>\n",
       "      <th>var2(t-1)</th>\n",
       "      <th>var3(t-1)</th>\n",
       "      <th>var4(t-1)</th>\n",
       "      <th>var5(t-1)</th>\n",
       "      <th>var6(t-1)</th>\n",
       "      <th>var7(t-1)</th>\n",
       "      <th>var8(t-1)</th>\n",
       "      <th>var9(t-1)</th>\n",
       "      <th>var1(t)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>0.035754</td>\n",
       "      <td>0.038376</td>\n",
       "      <td>-0.004679</td>\n",
       "      <td>0.002193</td>\n",
       "      <td>0.003894</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.031190</td>\n",
       "      <td>0.012698</td>\n",
       "      <td>0.028524</td>\n",
       "      <td>0.025426</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.014133</td>\n",
       "      <td>-0.014571</td>\n",
       "      <td>0.016233</td>\n",
       "      <td>0.003932</td>\n",
       "      <td>0.000071</td>\n",
       "      <td>-0.011169</td>\n",
       "      <td>0.024128</td>\n",
       "      <td>-0.004139</td>\n",
       "      <td>0.002073</td>\n",
       "      <td>0.036607</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>0.025426</td>\n",
       "      <td>0.031813</td>\n",
       "      <td>0.007787</td>\n",
       "      <td>0.008455</td>\n",
       "      <td>0.012866</td>\n",
       "      <td>0.004162</td>\n",
       "      <td>0.018920</td>\n",
       "      <td>0.011341</td>\n",
       "      <td>0.008773</td>\n",
       "      <td>-0.028862</td>\n",
       "      <td>...</td>\n",
       "      <td>0.036607</td>\n",
       "      <td>0.042759</td>\n",
       "      <td>0.026541</td>\n",
       "      <td>0.029306</td>\n",
       "      <td>0.014788</td>\n",
       "      <td>0.015846</td>\n",
       "      <td>0.039282</td>\n",
       "      <td>0.019127</td>\n",
       "      <td>0.032338</td>\n",
       "      <td>0.011353</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>-0.028862</td>\n",
       "      <td>-0.026353</td>\n",
       "      <td>-0.030469</td>\n",
       "      <td>-0.017833</td>\n",
       "      <td>-0.028735</td>\n",
       "      <td>0.017293</td>\n",
       "      <td>-0.035899</td>\n",
       "      <td>-0.017073</td>\n",
       "      <td>-0.020015</td>\n",
       "      <td>-0.062208</td>\n",
       "      <td>...</td>\n",
       "      <td>0.011353</td>\n",
       "      <td>0.021468</td>\n",
       "      <td>0.001484</td>\n",
       "      <td>0.004766</td>\n",
       "      <td>0.003651</td>\n",
       "      <td>-0.013411</td>\n",
       "      <td>-0.015462</td>\n",
       "      <td>0.005627</td>\n",
       "      <td>0.007895</td>\n",
       "      <td>-0.040542</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>-0.062208</td>\n",
       "      <td>-0.084716</td>\n",
       "      <td>0.003391</td>\n",
       "      <td>-0.011726</td>\n",
       "      <td>-0.000466</td>\n",
       "      <td>-0.040061</td>\n",
       "      <td>0.028283</td>\n",
       "      <td>-0.005561</td>\n",
       "      <td>-0.019424</td>\n",
       "      <td>0.009860</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.040542</td>\n",
       "      <td>-0.043907</td>\n",
       "      <td>-0.050369</td>\n",
       "      <td>-0.035170</td>\n",
       "      <td>-0.022182</td>\n",
       "      <td>-0.002902</td>\n",
       "      <td>-0.021440</td>\n",
       "      <td>-0.024388</td>\n",
       "      <td>-0.002139</td>\n",
       "      <td>-0.022106</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>0.009860</td>\n",
       "      <td>0.009658</td>\n",
       "      <td>-0.021533</td>\n",
       "      <td>-0.019873</td>\n",
       "      <td>-0.012710</td>\n",
       "      <td>-0.004474</td>\n",
       "      <td>-0.009764</td>\n",
       "      <td>-0.010989</td>\n",
       "      <td>-0.007802</td>\n",
       "      <td>-0.029191</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.022106</td>\n",
       "      <td>-0.033893</td>\n",
       "      <td>0.007923</td>\n",
       "      <td>0.005434</td>\n",
       "      <td>0.005019</td>\n",
       "      <td>-0.030745</td>\n",
       "      <td>-0.008799</td>\n",
       "      <td>0.001097</td>\n",
       "      <td>-0.007926</td>\n",
       "      <td>-0.014888</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 217 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    var1(t-24)  var2(t-24)  var3(t-24)  var4(t-24)  var5(t-24)  var6(t-24)  \\\n",
       "24    0.035754    0.038376   -0.004679    0.002193    0.003894    0.000000   \n",
       "25    0.025426    0.031813    0.007787    0.008455    0.012866    0.004162   \n",
       "26   -0.028862   -0.026353   -0.030469   -0.017833   -0.028735    0.017293   \n",
       "27   -0.062208   -0.084716    0.003391   -0.011726   -0.000466   -0.040061   \n",
       "28    0.009860    0.009658   -0.021533   -0.019873   -0.012710   -0.004474   \n",
       "\n",
       "    var7(t-24)  var8(t-24)  var9(t-24)  var1(t-23)  ...  var1(t-1)  var2(t-1)  \\\n",
       "24    0.031190    0.012698    0.028524    0.025426  ...  -0.014133  -0.014571   \n",
       "25    0.018920    0.011341    0.008773   -0.028862  ...   0.036607   0.042759   \n",
       "26   -0.035899   -0.017073   -0.020015   -0.062208  ...   0.011353   0.021468   \n",
       "27    0.028283   -0.005561   -0.019424    0.009860  ...  -0.040542  -0.043907   \n",
       "28   -0.009764   -0.010989   -0.007802   -0.029191  ...  -0.022106  -0.033893   \n",
       "\n",
       "    var3(t-1)  var4(t-1)  var5(t-1)  var6(t-1)  var7(t-1)  var8(t-1)  \\\n",
       "24   0.016233   0.003932   0.000071  -0.011169   0.024128  -0.004139   \n",
       "25   0.026541   0.029306   0.014788   0.015846   0.039282   0.019127   \n",
       "26   0.001484   0.004766   0.003651  -0.013411  -0.015462   0.005627   \n",
       "27  -0.050369  -0.035170  -0.022182  -0.002902  -0.021440  -0.024388   \n",
       "28   0.007923   0.005434   0.005019  -0.030745  -0.008799   0.001097   \n",
       "\n",
       "    var9(t-1)   var1(t)  \n",
       "24   0.002073  0.036607  \n",
       "25   0.032338  0.011353  \n",
       "26   0.007895 -0.040542  \n",
       "27  -0.002139 -0.022106  \n",
       "28  -0.007926 -0.014888  \n",
       "\n",
       "[5 rows x 217 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# series data to img function\n",
    "def series_to_img(dataset, time_step=1):\n",
    "    num = dataset.shape[1]      # features num\n",
    "    df = pd.DataFrame(dataset)\n",
    "    cols, names = list(), list()\n",
    "    # sequence t-n to t-1\n",
    "    for i in range(time_step, 0, -1):\n",
    "        cols.append(df.shift(i))\n",
    "        names += [('var%d(t-%d)' % (j+1, i)) for j in range(num)]\n",
    "\n",
    "    for i in range(0, 1):\n",
    "        cols.append(df.shift(-i))\n",
    "        if i == 0:\n",
    "            names += [('var%d(t)' % (j+1)) for j in range(num)]\n",
    "        else:\n",
    "            names += [('var%d(t+%d)' % (j+1, i)) for j in range(num)]\n",
    "\n",
    "    agg = pd.concat(cols, axis=1)\n",
    "    agg.columns = names\n",
    "    agg.dropna(inplace=True)\n",
    "    return agg\n",
    "\n",
    "from sklearn.model_selection import TimeSeriesSplit\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "dataset = df.values\n",
    "dataset = dataset.astype('float')\n",
    "\n",
    "n_inputs = 24\n",
    "n_features = 9\n",
    "del_idx = n_inputs * n_features + 1\n",
    "del_cols = [i for i in range(del_idx, del_idx+n_features-1)]\n",
    "new_df = series_to_img(dataset, n_inputs)\n",
    "new_df.drop(new_df.columns[del_cols], axis=1, inplace=True)\n",
    "new_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3ed16e6a-2634-47bf-b125-a27f9dfc34ba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "config : epochs, batch_size, learning_rate\n",
      "fold : 1/10\n",
      " == train [30, 32, 0.01] model ==  "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\lab\\anaconda3\\envs\\pytorch\\lib\\site-packages\\torch\\nn\\functional.py:718: UserWarning: Named tensors and all their associated APIs are an experimental feature and subject to change. Please do not use them for anything important until they are released as stable. (Triggered internally at  ..\\c10/core/TensorImpl.h:1156.)\n",
      "  return torch.max_pool2d(input, kernel_size, stride, padding, dilation, ceil_mode)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "error(rmse):0.81419\n",
      " == train [30, 32, 0.001] model ==  error(rmse):0.03815\n",
      "train-size:55, val-size:13, test-size:42\n",
      "best_model => error(rmse) : 0.04323, param:[30, 32, 0.001], times: 2.408\n",
      "\n",
      "fold : 2/10\n",
      " == train [30, 32, 0.01] model ==  error(rmse):0.05590\n",
      " == train [30, 32, 0.001] model ==  error(rmse):0.05171\n",
      "train-size:88, val-size:22, test-size:42\n",
      "best_model => error(rmse) : 0.03068, param:[30, 32, 0.001], times: 3.622\n",
      "\n",
      "fold : 3/10\n",
      " == train [30, 32, 0.01] model ==  error(rmse):0.05534\n",
      " == train [30, 32, 0.001] model ==  error(rmse):0.02272\n",
      "train-size:122, val-size:30, test-size:42\n",
      "best_model => error(rmse) : 0.02717, param:[30, 32, 0.001], times: 4.813\n",
      "\n",
      "fold : 4/10\n",
      " == train [30, 32, 0.01] model ==  error(rmse):0.02545\n",
      " == train [30, 32, 0.001] model ==  error(rmse):0.02820\n",
      "train-size:156, val-size:38, test-size:42\n",
      "best_model => error(rmse) : 0.03038, param:[30, 32, 0.01], times: 7.169\n",
      "\n",
      "fold : 5/10\n",
      " == train [30, 32, 0.01] model ==  error(rmse):0.01847\n",
      " == train [30, 32, 0.001] model ==  error(rmse):0.02758\n",
      "train-size:189, val-size:47, test-size:42\n",
      "best_model => error(rmse) : 0.03730, param:[30, 32, 0.01], times: 8.500\n",
      "\n",
      "fold : 6/10\n",
      " == train [30, 32, 0.01] model ==  error(rmse):0.02205\n",
      " == train [30, 32, 0.001] model ==  error(rmse):0.02567\n",
      "train-size:223, val-size:55, test-size:42\n",
      "best_model => error(rmse) : 0.02401, param:[30, 32, 0.01], times: 9.688\n",
      "\n",
      "fold : 7/10\n",
      " == train [30, 32, 0.01] model ==  error(rmse):0.03578\n",
      " == train [30, 32, 0.001] model ==  error(rmse):0.02345\n",
      "train-size:256, val-size:64, test-size:42\n",
      "best_model => error(rmse) : 0.02104, param:[30, 32, 0.001], times: 12.009\n",
      "\n",
      "fold : 8/10\n",
      " == train [30, 32, 0.01] model ==  error(rmse):0.02063\n",
      " == train [30, 32, 0.001] model ==  error(rmse):0.02704\n",
      "train-size:290, val-size:72, test-size:42\n",
      "best_model => error(rmse) : 0.03057, param:[30, 32, 0.01], times: 13.102\n",
      "\n",
      "fold : 9/10\n",
      " == train [30, 32, 0.01] model ==  error(rmse):0.01915\n",
      " == train [30, 32, 0.001] model ==  error(rmse):0.01762\n",
      "train-size:324, val-size:80, test-size:42\n",
      "best_model => error(rmse) : 0.02010, param:[30, 32, 0.001], times: 14.488\n",
      "\n",
      "fold : 10/10\n",
      " == train [30, 32, 0.01] model ==  error(rmse):0.01883\n",
      " == train [30, 32, 0.001] model ==  error(rmse):0.01744\n",
      "train-size:357, val-size:89, test-size:42\n",
      "best_model => error(rmse) : 0.01935, param:[30, 32, 0.001], times: 15.542\n",
      "\n"
     ]
    }
   ],
   "source": [
    "n_splits = 10\n",
    "train_test_split = TimeSeriesSplit(n_splits=n_splits+1, gap=n_inputs).split(new_df)\n",
    "next(train_test_split)\n",
    "\n",
    "configs = model_config()\n",
    "history = []\n",
    "\n",
    "best_rmse, best_mse, best_mae = [], [], []\n",
    "learning_time = []\n",
    "\n",
    "i = 1\n",
    "\n",
    "print('config : epochs, batch_size, learning_rate')\n",
    "\n",
    "# nested cross validation for time series model\n",
    "for train_cv_indices, test_cv_indices in train_test_split:\n",
    "    print(f'fold : {i}/{n_splits}')\n",
    "    i+=1\n",
    "\n",
    "    # split x, y data\n",
    "    train_cv_X, train_cv_y = new_df.iloc[train_cv_indices, :-1].values, new_df.iloc[train_cv_indices,-1].values\n",
    "    test_cv_X, test_cv_y = new_df.iloc[test_cv_indices, :-1].values, new_df.iloc[test_cv_indices, -1].values\n",
    "\n",
    "    # length for validation set\n",
    "    test_length = int(len(train_cv_X)*0.2)\n",
    "\n",
    "    # scaling data\n",
    "    scaler_x = MinMaxScaler()\n",
    "    train_cv_X = scaler_x.fit_transform(train_cv_X)\n",
    "    test_cv_X = scaler_x.transform(test_cv_X)\n",
    "\n",
    "    train_X, val_X = train_cv_X[:-test_length, :], train_cv_X[-test_length:, :]\n",
    "    train_y, val_y = train_cv_y[:-test_length], train_cv_y[-test_length:]\n",
    "\n",
    "    # reshape\n",
    "    # inner loop\n",
    "    train_X = train_X.reshape(-1, 1, n_inputs, n_features)\n",
    "    val_X = val_X.reshape(-1, 1, n_inputs, n_features)\n",
    "    train_y = train_y.reshape(-1, 1)\n",
    "    val_y = val_y.reshape(-1, 1)\n",
    "\n",
    "    # outer loop\n",
    "    train_cv_X = train_cv_X.reshape(-1, 1, n_inputs, n_features)\n",
    "    test_cv_X = test_cv_X.reshape(-1, 1, n_inputs, n_features)\n",
    "    train_cv_y = train_cv_y.reshape(-1, 1)\n",
    "    test_cv_y = test_cv_y.reshape(-1, 1)\n",
    "\n",
    "    train_X = np_to_tensor(train_X)\n",
    "    train_y = np_to_tensor(train_y)\n",
    "    val_X = np_to_tensor(val_X)\n",
    "\n",
    "    train_cv_X = np_to_tensor(train_cv_X)\n",
    "    train_cv_y = np_to_tensor(train_cv_y)\n",
    "    test_cv_X = np_to_tensor(test_cv_X)\n",
    "\n",
    "    # model fit, inner\n",
    "    errors = []\n",
    "    for idx, cfg in enumerate(configs):\n",
    "        print(f' == train {cfg} model == ', end=' ')\n",
    "        model = model_fit(train_X, train_y, cfg)\n",
    "        output = model(val_X)\n",
    "        # for prevent cuda memory out\n",
    "        predicted = output.data.cpu().numpy()\n",
    "        error = MSE_metric(predicted, val_y)   # mse\n",
    "        print(f'error(rmse):{np.sqrt(error):.5f}')\n",
    "        if errors:\n",
    "            if error < min(errors):\n",
    "                param = idx\n",
    "        else:\n",
    "            param = idx\n",
    "        errors.append(error)\n",
    "    history.append(errors)\n",
    "\n",
    "    # outer\n",
    "    start_time = time.time()\n",
    "    # model fitting\n",
    "    selected_model = model_fit(train_cv_X,train_cv_y, configs[param])\n",
    "    # check time\n",
    "    duration = time.time() - start_time\n",
    "    output = selected_model(test_cv_X)\n",
    "    predicted = output.data.cpu().numpy()\n",
    "    \n",
    "    rmse = np.sqrt(MSE_metric(predicted, test_cv_y))\n",
    "    mse = MSE_metric(predicted, test_cv_y)\n",
    "    mae = MAE_metric(predicted, test_cv_y)\n",
    "    best_rmse.append(rmse)\n",
    "    best_mse.append(mse)\n",
    "    best_mae.append(mae)\n",
    "    learning_time.append(duration)\n",
    "\n",
    "    # model eval\n",
    "    print(f'train-size:{train_X.size(0)}, val-size:{val_X.size(0)}, test-size:{test_cv_X.size(0)}')\n",
    "    print(f'best_model => error(rmse) : {rmse:.5f}, param:{configs[param]}, times: {duration:.3f}')\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "27338cc7-af36-4057-a1fe-d6b34e307dbe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE: mean=0.0008594823059136974, std=0.00045051550272705065\n",
      "RMSE: mean=0.02838323364338957, std=0.0073399151124829655\n",
      "MAE: mean=0.02292710859651202, std=0.006755458999701383\n",
      "\n",
      "[training time]\n",
      "mean : 9.133955121040344, last:15.54196810722351\n"
     ]
    }
   ],
   "source": [
    "def model_evaluation(mse, rmse, mae):\n",
    "    mse = np.array(mse)\n",
    "    rmse = np.array(rmse)\n",
    "    mae = np.array(mae)\n",
    "    print(f'MSE: mean={np.mean(mse)}, std={np.std(mse)}')\n",
    "    print(f'RMSE: mean={np.mean(rmse)}, std={np.std(rmse)}')\n",
    "    print(f'MAE: mean={np.mean(mae)}, std={np.std(mae)}')\n",
    "\n",
    "model_evaluation(best_mse, best_rmse, best_mae)\n",
    "\n",
    "# check time\n",
    "print()\n",
    "print('[training time]')\n",
    "print(f'mean : {np.mean(np.array(learning_time))}, last:{learning_time[-1]}')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch",
   "language": "python",
   "name": "pytorch"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
