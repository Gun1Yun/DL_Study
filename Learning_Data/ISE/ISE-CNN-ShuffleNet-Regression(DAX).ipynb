{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2fb2376e-dbc8-497d-83fa-b7956e724243",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "\n",
    "MODULE_PATH = 'C:\\Github\\DL_Study\\CNN'\n",
    "\n",
    "sys.path.insert(0, MODULE_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "52397efe-f192-455f-9e0b-0460aec4c18d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch._C.Generator at 0x1e5ff705410>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# import\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import numpy\n",
    "import time\n",
    "\n",
    "from ShuffleNet import *\n",
    "\n",
    "# set random seed\n",
    "torch.manual_seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a2f3b256-e4b8-4174-bd57-96a66602cd2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_device():\n",
    "    if torch.cuda.is_available():\n",
    "        device = torch.device('cuda:0')\n",
    "    else:\n",
    "        device = torch.device('cpu')\n",
    "    return device\n",
    "\n",
    "def df_to_tensor(df):\n",
    "    device = get_device()\n",
    "    return torch.from_numpy(df.values).float().to(device)\n",
    "\n",
    "def np_to_tensor(data):\n",
    "    device = get_device()\n",
    "    return torch.tensor(data).float().to(device)\n",
    "\n",
    "# configuration setting\n",
    "def model_config():\n",
    "    # parameter for CNN Model\n",
    "    epochs = [30]\n",
    "    batch_size = [32]\n",
    "    learning_rate = [0.01, 0.001]\n",
    "    \n",
    "    # create config data\n",
    "    configs = []\n",
    "    for i in epochs:\n",
    "        for j in batch_size:\n",
    "            for k in learning_rate:\n",
    "                config = [i, j, k]\n",
    "                configs.append(config)\n",
    "    return configs\n",
    "\n",
    "# fucntion for fit cnn model using configs\n",
    "def model_fit(train_X, train_y, config, verbose=0):\n",
    "\n",
    "    # unpack config\n",
    "    n_epochs, n_batch, learning_rate = config\n",
    "    # use ShuffleNet for CNN\n",
    "    model = ShuffleNet(groups=3, in_channels=1)\n",
    "    if torch.cuda.is_available():\n",
    "        model.cuda()\n",
    "\n",
    "    # define Loss and Optimizer\n",
    "    criterion = nn.MSELoss()\n",
    "    optimizer = optim.Adam(model.parameters(), lr=learning_rate)\n",
    "\n",
    "    data_size = train_X.size(0)\n",
    "    max_iters = data_size//n_batch\n",
    "\n",
    "    for epoch in range(1, n_epochs+1):\n",
    "        #shuffle data\n",
    "        idx = numpy.random.permutation(numpy.arange(data_size))\n",
    "        x_data = train_X[idx]\n",
    "        y_data = train_y[idx]\n",
    "\n",
    "        epoch_loss = 0\n",
    "        start_time = time.time()\n",
    "        for it in range(max_iters):\n",
    "            batch_x = x_data[it*n_batch:(it+1)*n_batch]\n",
    "            batch_y = y_data[it*n_batch:(it+1)*n_batch]\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            predict = model(batch_x)\n",
    "            loss = criterion(predict, batch_y)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            epoch_loss+= loss.item()\n",
    "        avg_loss = epoch_loss/max_iters\n",
    "\n",
    "        if verbose:\n",
    "            duration = start_time-time.time()\n",
    "            print(f'epoch:{epoch}/{epochs}, ì‹œê°„:{duration:.2f}[s], loss:{avg_loss:.5f}')\n",
    "\n",
    "\n",
    "    return model\n",
    "\n",
    "def MAE_metric(x, t):\n",
    "    t = np.array(t)\n",
    "    return np.mean(numpy.abs(x-t))\n",
    "\n",
    "def MSE_metric(x, t):\n",
    "    t = np.array(t)\n",
    "    return np.mean((x-t)**2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "716b3ea5-54ec-4e71-bcdb-09301e072b54",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\lab\\AppData\\Local\\Temp/ipykernel_16224/4288721627.py:12: FutureWarning: Your version of xlrd is 1.2.0. In xlrd >= 2.0, only the xls format is supported. As a result, the openpyxl engine will be used if it is installed and the engine argument is not specified. Install openpyxl instead.\n",
      "  df = pd.read_excel(data_url+data_name, header=1)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>DAX</th>\n",
       "      <th>FTSE</th>\n",
       "      <th>NIKKEI</th>\n",
       "      <th>BOVESPA</th>\n",
       "      <th>EU</th>\n",
       "      <th>EM</th>\n",
       "      <th>ISE</th>\n",
       "      <th>ISE.1</th>\n",
       "      <th>SP</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.002193</td>\n",
       "      <td>0.003894</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.031190</td>\n",
       "      <td>0.012698</td>\n",
       "      <td>0.028524</td>\n",
       "      <td>0.035754</td>\n",
       "      <td>0.038376</td>\n",
       "      <td>-0.004679</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.008455</td>\n",
       "      <td>0.012866</td>\n",
       "      <td>0.004162</td>\n",
       "      <td>0.018920</td>\n",
       "      <td>0.011341</td>\n",
       "      <td>0.008773</td>\n",
       "      <td>0.025426</td>\n",
       "      <td>0.031813</td>\n",
       "      <td>0.007787</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-0.017833</td>\n",
       "      <td>-0.028735</td>\n",
       "      <td>0.017293</td>\n",
       "      <td>-0.035899</td>\n",
       "      <td>-0.017073</td>\n",
       "      <td>-0.020015</td>\n",
       "      <td>-0.028862</td>\n",
       "      <td>-0.026353</td>\n",
       "      <td>-0.030469</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-0.011726</td>\n",
       "      <td>-0.000466</td>\n",
       "      <td>-0.040061</td>\n",
       "      <td>0.028283</td>\n",
       "      <td>-0.005561</td>\n",
       "      <td>-0.019424</td>\n",
       "      <td>-0.062208</td>\n",
       "      <td>-0.084716</td>\n",
       "      <td>0.003391</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-0.019873</td>\n",
       "      <td>-0.012710</td>\n",
       "      <td>-0.004474</td>\n",
       "      <td>-0.009764</td>\n",
       "      <td>-0.010989</td>\n",
       "      <td>-0.007802</td>\n",
       "      <td>0.009860</td>\n",
       "      <td>0.009658</td>\n",
       "      <td>-0.021533</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        DAX      FTSE    NIKKEI   BOVESPA        EU        EM       ISE  \\\n",
       "0  0.002193  0.003894  0.000000  0.031190  0.012698  0.028524  0.035754   \n",
       "1  0.008455  0.012866  0.004162  0.018920  0.011341  0.008773  0.025426   \n",
       "2 -0.017833 -0.028735  0.017293 -0.035899 -0.017073 -0.020015 -0.028862   \n",
       "3 -0.011726 -0.000466 -0.040061  0.028283 -0.005561 -0.019424 -0.062208   \n",
       "4 -0.019873 -0.012710 -0.004474 -0.009764 -0.010989 -0.007802  0.009860   \n",
       "\n",
       "      ISE.1        SP  \n",
       "0  0.038376 -0.004679  \n",
       "1  0.031813  0.007787  \n",
       "2 -0.026353 -0.030469  \n",
       "3 -0.084716  0.003391  \n",
       "4  0.009658 -0.021533  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import numpy\n",
    "import time\n",
    "from datetime import datetime\n",
    "\n",
    "np.random.seed(42)\n",
    "numpy.random.seed(42)\n",
    "\n",
    "data_url = 'https://archive.ics.uci.edu/ml/machine-learning-databases/00247/'\n",
    "data_name = 'data_akbilgic.xlsx'\n",
    "df = pd.read_excel(data_url+data_name, header=1)\n",
    "df.drop(columns=df.columns[[0]], axis=1, inplace=True)\n",
    "cols = df.columns.tolist()\n",
    "cols = cols[3:]+cols[:3]\n",
    "df = df[cols]\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "cdb478be-ed18-448b-b4d9-004d5121c7a5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>var1(t-24)</th>\n",
       "      <th>var2(t-24)</th>\n",
       "      <th>var3(t-24)</th>\n",
       "      <th>var4(t-24)</th>\n",
       "      <th>var5(t-24)</th>\n",
       "      <th>var6(t-24)</th>\n",
       "      <th>var7(t-24)</th>\n",
       "      <th>var8(t-24)</th>\n",
       "      <th>var9(t-24)</th>\n",
       "      <th>var1(t-23)</th>\n",
       "      <th>...</th>\n",
       "      <th>var1(t-1)</th>\n",
       "      <th>var2(t-1)</th>\n",
       "      <th>var3(t-1)</th>\n",
       "      <th>var4(t-1)</th>\n",
       "      <th>var5(t-1)</th>\n",
       "      <th>var6(t-1)</th>\n",
       "      <th>var7(t-1)</th>\n",
       "      <th>var8(t-1)</th>\n",
       "      <th>var9(t-1)</th>\n",
       "      <th>var1(t)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>0.002193</td>\n",
       "      <td>0.003894</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.031190</td>\n",
       "      <td>0.012698</td>\n",
       "      <td>0.028524</td>\n",
       "      <td>0.035754</td>\n",
       "      <td>0.038376</td>\n",
       "      <td>-0.004679</td>\n",
       "      <td>0.008455</td>\n",
       "      <td>...</td>\n",
       "      <td>0.003932</td>\n",
       "      <td>0.000071</td>\n",
       "      <td>-0.011169</td>\n",
       "      <td>0.024128</td>\n",
       "      <td>-0.004139</td>\n",
       "      <td>0.002073</td>\n",
       "      <td>-0.014133</td>\n",
       "      <td>-0.014571</td>\n",
       "      <td>0.016233</td>\n",
       "      <td>0.029306</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>0.008455</td>\n",
       "      <td>0.012866</td>\n",
       "      <td>0.004162</td>\n",
       "      <td>0.018920</td>\n",
       "      <td>0.011341</td>\n",
       "      <td>0.008773</td>\n",
       "      <td>0.025426</td>\n",
       "      <td>0.031813</td>\n",
       "      <td>0.007787</td>\n",
       "      <td>-0.017833</td>\n",
       "      <td>...</td>\n",
       "      <td>0.029306</td>\n",
       "      <td>0.014788</td>\n",
       "      <td>0.015846</td>\n",
       "      <td>0.039282</td>\n",
       "      <td>0.019127</td>\n",
       "      <td>0.032338</td>\n",
       "      <td>0.036607</td>\n",
       "      <td>0.042759</td>\n",
       "      <td>0.026541</td>\n",
       "      <td>0.004766</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>-0.017833</td>\n",
       "      <td>-0.028735</td>\n",
       "      <td>0.017293</td>\n",
       "      <td>-0.035899</td>\n",
       "      <td>-0.017073</td>\n",
       "      <td>-0.020015</td>\n",
       "      <td>-0.028862</td>\n",
       "      <td>-0.026353</td>\n",
       "      <td>-0.030469</td>\n",
       "      <td>-0.011726</td>\n",
       "      <td>...</td>\n",
       "      <td>0.004766</td>\n",
       "      <td>0.003651</td>\n",
       "      <td>-0.013411</td>\n",
       "      <td>-0.015462</td>\n",
       "      <td>0.005627</td>\n",
       "      <td>0.007895</td>\n",
       "      <td>0.011353</td>\n",
       "      <td>0.021468</td>\n",
       "      <td>0.001484</td>\n",
       "      <td>-0.035170</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>-0.011726</td>\n",
       "      <td>-0.000466</td>\n",
       "      <td>-0.040061</td>\n",
       "      <td>0.028283</td>\n",
       "      <td>-0.005561</td>\n",
       "      <td>-0.019424</td>\n",
       "      <td>-0.062208</td>\n",
       "      <td>-0.084716</td>\n",
       "      <td>0.003391</td>\n",
       "      <td>-0.019873</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.035170</td>\n",
       "      <td>-0.022182</td>\n",
       "      <td>-0.002902</td>\n",
       "      <td>-0.021440</td>\n",
       "      <td>-0.024388</td>\n",
       "      <td>-0.002139</td>\n",
       "      <td>-0.040542</td>\n",
       "      <td>-0.043907</td>\n",
       "      <td>-0.050369</td>\n",
       "      <td>0.005434</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>-0.019873</td>\n",
       "      <td>-0.012710</td>\n",
       "      <td>-0.004474</td>\n",
       "      <td>-0.009764</td>\n",
       "      <td>-0.010989</td>\n",
       "      <td>-0.007802</td>\n",
       "      <td>0.009860</td>\n",
       "      <td>0.009658</td>\n",
       "      <td>-0.021533</td>\n",
       "      <td>-0.013526</td>\n",
       "      <td>...</td>\n",
       "      <td>0.005434</td>\n",
       "      <td>0.005019</td>\n",
       "      <td>-0.030745</td>\n",
       "      <td>-0.008799</td>\n",
       "      <td>0.001097</td>\n",
       "      <td>-0.007926</td>\n",
       "      <td>-0.022106</td>\n",
       "      <td>-0.033893</td>\n",
       "      <td>0.007923</td>\n",
       "      <td>-0.027421</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 217 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    var1(t-24)  var2(t-24)  var3(t-24)  var4(t-24)  var5(t-24)  var6(t-24)  \\\n",
       "24    0.002193    0.003894    0.000000    0.031190    0.012698    0.028524   \n",
       "25    0.008455    0.012866    0.004162    0.018920    0.011341    0.008773   \n",
       "26   -0.017833   -0.028735    0.017293   -0.035899   -0.017073   -0.020015   \n",
       "27   -0.011726   -0.000466   -0.040061    0.028283   -0.005561   -0.019424   \n",
       "28   -0.019873   -0.012710   -0.004474   -0.009764   -0.010989   -0.007802   \n",
       "\n",
       "    var7(t-24)  var8(t-24)  var9(t-24)  var1(t-23)  ...  var1(t-1)  var2(t-1)  \\\n",
       "24    0.035754    0.038376   -0.004679    0.008455  ...   0.003932   0.000071   \n",
       "25    0.025426    0.031813    0.007787   -0.017833  ...   0.029306   0.014788   \n",
       "26   -0.028862   -0.026353   -0.030469   -0.011726  ...   0.004766   0.003651   \n",
       "27   -0.062208   -0.084716    0.003391   -0.019873  ...  -0.035170  -0.022182   \n",
       "28    0.009860    0.009658   -0.021533   -0.013526  ...   0.005434   0.005019   \n",
       "\n",
       "    var3(t-1)  var4(t-1)  var5(t-1)  var6(t-1)  var7(t-1)  var8(t-1)  \\\n",
       "24  -0.011169   0.024128  -0.004139   0.002073  -0.014133  -0.014571   \n",
       "25   0.015846   0.039282   0.019127   0.032338   0.036607   0.042759   \n",
       "26  -0.013411  -0.015462   0.005627   0.007895   0.011353   0.021468   \n",
       "27  -0.002902  -0.021440  -0.024388  -0.002139  -0.040542  -0.043907   \n",
       "28  -0.030745  -0.008799   0.001097  -0.007926  -0.022106  -0.033893   \n",
       "\n",
       "    var9(t-1)   var1(t)  \n",
       "24   0.016233  0.029306  \n",
       "25   0.026541  0.004766  \n",
       "26   0.001484 -0.035170  \n",
       "27  -0.050369  0.005434  \n",
       "28   0.007923 -0.027421  \n",
       "\n",
       "[5 rows x 217 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# series data to img function\n",
    "def series_to_img(dataset, time_step=1):\n",
    "    num = dataset.shape[1]      # features num\n",
    "    df = pd.DataFrame(dataset)\n",
    "    cols, names = list(), list()\n",
    "    # sequence t-n to t-1\n",
    "    for i in range(time_step, 0, -1):\n",
    "        cols.append(df.shift(i))\n",
    "        names += [('var%d(t-%d)' % (j+1, i)) for j in range(num)]\n",
    "\n",
    "    for i in range(0, 1):\n",
    "        cols.append(df.shift(-i))\n",
    "        if i == 0:\n",
    "            names += [('var%d(t)' % (j+1)) for j in range(num)]\n",
    "        else:\n",
    "            names += [('var%d(t+%d)' % (j+1, i)) for j in range(num)]\n",
    "\n",
    "    agg = pd.concat(cols, axis=1)\n",
    "    agg.columns = names\n",
    "    agg.dropna(inplace=True)\n",
    "    return agg\n",
    "\n",
    "from sklearn.model_selection import TimeSeriesSplit\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "dataset = df.values\n",
    "dataset = dataset.astype('float')\n",
    "\n",
    "n_inputs = 24\n",
    "n_features = 9\n",
    "del_idx = n_inputs * n_features + 1\n",
    "del_cols = [i for i in range(del_idx, del_idx+n_features-1)]\n",
    "new_df = series_to_img(dataset, n_inputs)\n",
    "new_df.drop(new_df.columns[del_cols], axis=1, inplace=True)\n",
    "new_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1f0d4f37-2331-4ce4-8a8d-d5117a33543a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "config : epochs, batch_size, learning_rate\n",
      "fold : 1/10\n",
      " == train [30, 32, 0.01] model ==  "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\lab\\anaconda3\\envs\\pytorch\\lib\\site-packages\\torch\\nn\\functional.py:718: UserWarning: Named tensors and all their associated APIs are an experimental feature and subject to change. Please do not use them for anything important until they are released as stable. (Triggered internally at  ..\\c10/core/TensorImpl.h:1156.)\n",
      "  return torch.max_pool2d(input, kernel_size, stride, padding, dilation, ceil_mode)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "error(rmse):0.15007\n",
      " == train [30, 32, 0.001] model ==  error(rmse):0.03251\n",
      "train-size:55, val-size:13, test-size:42\n",
      "best_model => error(rmse) : 0.04779, param:[30, 32, 0.001], times: 2.442\n",
      "\n",
      "fold : 2/10\n",
      " == train [30, 32, 0.01] model ==  error(rmse):0.09673\n",
      " == train [30, 32, 0.001] model ==  error(rmse):0.03864\n",
      "train-size:88, val-size:22, test-size:42\n",
      "best_model => error(rmse) : 0.02961, param:[30, 32, 0.001], times: 3.666\n",
      "\n",
      "fold : 3/10\n",
      " == train [30, 32, 0.01] model ==  error(rmse):0.02295\n",
      " == train [30, 32, 0.001] model ==  error(rmse):0.02551\n",
      "train-size:122, val-size:30, test-size:42\n",
      "best_model => error(rmse) : 0.02831, param:[30, 32, 0.01], times: 4.880\n",
      "\n",
      "fold : 4/10\n",
      " == train [30, 32, 0.01] model ==  error(rmse):0.03927\n",
      " == train [30, 32, 0.001] model ==  error(rmse):0.01931\n",
      "train-size:156, val-size:38, test-size:42\n",
      "best_model => error(rmse) : 0.01722, param:[30, 32, 0.001], times: 7.361\n",
      "\n",
      "fold : 5/10\n",
      " == train [30, 32, 0.01] model ==  error(rmse):0.01902\n",
      " == train [30, 32, 0.001] model ==  error(rmse):0.02166\n",
      "train-size:189, val-size:47, test-size:42\n",
      "best_model => error(rmse) : 0.02959, param:[30, 32, 0.01], times: 8.568\n",
      "\n",
      "fold : 6/10\n",
      " == train [30, 32, 0.01] model ==  error(rmse):0.01929\n",
      " == train [30, 32, 0.001] model ==  error(rmse):0.02042\n",
      "train-size:223, val-size:55, test-size:42\n",
      "best_model => error(rmse) : 0.02257, param:[30, 32, 0.01], times: 9.742\n",
      "\n",
      "fold : 7/10\n",
      " == train [30, 32, 0.01] model ==  error(rmse):0.02385\n",
      " == train [30, 32, 0.001] model ==  error(rmse):0.01988\n",
      "train-size:256, val-size:64, test-size:42\n",
      "best_model => error(rmse) : 0.01791, param:[30, 32, 0.001], times: 12.183\n",
      "\n",
      "fold : 8/10\n",
      " == train [30, 32, 0.01] model ==  error(rmse):0.01936\n",
      " == train [30, 32, 0.001] model ==  error(rmse):0.01909\n",
      "train-size:290, val-size:72, test-size:42\n",
      "best_model => error(rmse) : 0.01559, param:[30, 32, 0.001], times: 13.447\n",
      "\n",
      "fold : 9/10\n",
      " == train [30, 32, 0.01] model ==  error(rmse):0.01447\n",
      " == train [30, 32, 0.001] model ==  error(rmse):0.01619\n",
      "train-size:324, val-size:80, test-size:42\n",
      "best_model => error(rmse) : 0.02566, param:[30, 32, 0.01], times: 14.455\n",
      "\n",
      "fold : 10/10\n",
      " == train [30, 32, 0.01] model ==  error(rmse):0.01933\n",
      " == train [30, 32, 0.001] model ==  error(rmse):0.01605\n",
      "train-size:357, val-size:89, test-size:42\n",
      "best_model => error(rmse) : 0.01350, param:[30, 32, 0.001], times: 15.974\n",
      "\n"
     ]
    }
   ],
   "source": [
    "n_splits = 10\n",
    "train_test_split = TimeSeriesSplit(n_splits=n_splits+1, gap=n_inputs).split(new_df)\n",
    "next(train_test_split)\n",
    "\n",
    "configs = model_config()\n",
    "history = []\n",
    "\n",
    "best_rmse, best_mse, best_mae = [], [], []\n",
    "learning_time = []\n",
    "\n",
    "i = 1\n",
    "\n",
    "print('config : epochs, batch_size, learning_rate')\n",
    "\n",
    "# nested cross validation for time series model\n",
    "for train_cv_indices, test_cv_indices in train_test_split:\n",
    "    print(f'fold : {i}/{n_splits}')\n",
    "    i+=1\n",
    "\n",
    "    # split x, y data\n",
    "    train_cv_X, train_cv_y = new_df.iloc[train_cv_indices, :-1].values, new_df.iloc[train_cv_indices,-1].values\n",
    "    test_cv_X, test_cv_y = new_df.iloc[test_cv_indices, :-1].values, new_df.iloc[test_cv_indices, -1].values\n",
    "\n",
    "    # length for validation set\n",
    "    test_length = int(len(train_cv_X)*0.2)\n",
    "\n",
    "    # scaling data\n",
    "    scaler_x = MinMaxScaler()\n",
    "    train_cv_X = scaler_x.fit_transform(train_cv_X)\n",
    "    test_cv_X = scaler_x.transform(test_cv_X)\n",
    "\n",
    "    train_X, val_X = train_cv_X[:-test_length, :], train_cv_X[-test_length:, :]\n",
    "    train_y, val_y = train_cv_y[:-test_length], train_cv_y[-test_length:]\n",
    "\n",
    "    # reshape\n",
    "    # inner loop\n",
    "    train_X = train_X.reshape(-1, 1, n_inputs, n_features)\n",
    "    val_X = val_X.reshape(-1, 1, n_inputs, n_features)\n",
    "    train_y = train_y.reshape(-1, 1)\n",
    "    val_y = val_y.reshape(-1, 1)\n",
    "\n",
    "    # outer loop\n",
    "    train_cv_X = train_cv_X.reshape(-1, 1, n_inputs, n_features)\n",
    "    test_cv_X = test_cv_X.reshape(-1, 1, n_inputs, n_features)\n",
    "    train_cv_y = train_cv_y.reshape(-1, 1)\n",
    "    test_cv_y = test_cv_y.reshape(-1, 1)\n",
    "\n",
    "    train_X = np_to_tensor(train_X)\n",
    "    train_y = np_to_tensor(train_y)\n",
    "    val_X = np_to_tensor(val_X)\n",
    "\n",
    "    train_cv_X = np_to_tensor(train_cv_X)\n",
    "    train_cv_y = np_to_tensor(train_cv_y)\n",
    "    test_cv_X = np_to_tensor(test_cv_X)\n",
    "\n",
    "    # model fit, inner\n",
    "    errors = []\n",
    "    for idx, cfg in enumerate(configs):\n",
    "        print(f' == train {cfg} model == ', end=' ')\n",
    "        model = model_fit(train_X, train_y, cfg)\n",
    "        output = model(val_X)\n",
    "        # for prevent cuda memory out\n",
    "        predicted = output.data.cpu().numpy()\n",
    "        error = MSE_metric(predicted, val_y)   # mse\n",
    "        print(f'error(rmse):{np.sqrt(error):.5f}')\n",
    "        if errors:\n",
    "            if error < min(errors):\n",
    "                param = idx\n",
    "        else:\n",
    "            param = idx\n",
    "        errors.append(error)\n",
    "    history.append(errors)\n",
    "\n",
    "    # outer\n",
    "    start_time = time.time()\n",
    "    # model fitting\n",
    "    selected_model = model_fit(train_cv_X,train_cv_y, configs[param])\n",
    "    # check time\n",
    "    duration = time.time() - start_time\n",
    "    output = selected_model(test_cv_X)\n",
    "    predicted = output.data.cpu().numpy()\n",
    "    \n",
    "    rmse = np.sqrt(MSE_metric(predicted, test_cv_y))\n",
    "    mse = MSE_metric(predicted, test_cv_y)\n",
    "    mae = MAE_metric(predicted, test_cv_y)\n",
    "    best_rmse.append(rmse)\n",
    "    best_mse.append(mse)\n",
    "    best_mae.append(mae)\n",
    "    learning_time.append(duration)\n",
    "\n",
    "    # model eval\n",
    "    print(f'train-size:{train_X.size(0)}, val-size:{val_X.size(0)}, test-size:{test_cv_X.size(0)}')\n",
    "    print(f'best_model => error(rmse) : {rmse:.5f}, param:{configs[param]}, times: {duration:.3f}')\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "34ea666f-d1e2-42ba-93b2-af6c748c5545",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE: mean=0.0007047551140983898, std=0.0005832339272529215\n",
      "RMSE: mean=0.024773951310683426, std=0.009539730109089916\n",
      "MAE: mean=0.019606560952633682, std=0.0077329030447378655\n",
      "\n",
      "[training time]\n",
      "mean : 9.271704697608948, last:15.973591327667236\n"
     ]
    }
   ],
   "source": [
    "def model_evaluation(mse, rmse, mae):\n",
    "    mse = np.array(mse)\n",
    "    rmse = np.array(rmse)\n",
    "    mae = np.array(mae)\n",
    "    print(f'MSE: mean={np.mean(mse)}, std={np.std(mse)}')\n",
    "    print(f'RMSE: mean={np.mean(rmse)}, std={np.std(rmse)}')\n",
    "    print(f'MAE: mean={np.mean(mae)}, std={np.std(mae)}')\n",
    "\n",
    "model_evaluation(best_mse, best_rmse, best_mae)\n",
    "\n",
    "# check time\n",
    "print()\n",
    "print('[training time]')\n",
    "print(f'mean : {np.mean(np.array(learning_time))}, last:{learning_time[-1]}')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch",
   "language": "python",
   "name": "pytorch"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
