{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3123df65-0150-48d5-bb3e-a0292a93dfe5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "\n",
    "MODULE_PATH = 'C:\\Github\\DL_Study\\Base'\n",
    "\n",
    "sys.path.insert(0, MODULE_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e4bf2078-2ef5-4b71-8731-0190210426c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import\n",
    "import numpy\n",
    "from config import *\n",
    "from optim import Adam\n",
    "from models import LstmModelReg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "55ffa317-25c2-4855-8a39-341979da5906",
   "metadata": {},
   "outputs": [],
   "source": [
    "# configuration setting\n",
    "def model_config():\n",
    "    # parameter for LSTM Model\n",
    "    epochs = [30]\n",
    "    batch_size = [32]\n",
    "    learning_rate = [0.01, 0.001]\n",
    "    \n",
    "    # create config data\n",
    "    configs = []\n",
    "    for i in epochs:\n",
    "        for j in batch_size:\n",
    "            for k in learning_rate:\n",
    "                config = [i, j, k]\n",
    "                configs.append(config)\n",
    "    return configs\n",
    "\n",
    "# fucntion for fit cnn model using configs\n",
    "def model_fit(train_X, train_y, config):\n",
    "    # unpack config\n",
    "    n_epochs, n_batch, learning_rate = config\n",
    "    model = LstmModelReg(time_size=24, hidden_size=64, feature_size=9)\n",
    "    # fit model and return\n",
    "    model.fit(train_X=train_X, train_y=train_y, epochs=n_epochs, \n",
    "              batch_size=n_batch, learning_rate=learning_rate)\n",
    "    return model\n",
    "\n",
    "def MAE_metric(x, t):\n",
    "    return np.mean(numpy.abs(x-t))\n",
    "\n",
    "def MSE_metric(x, t):\n",
    "    return np.mean((x-t)**2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b69ffc4e-f95d-4109-9d29-d14c9f7ea336",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\lab\\AppData\\Local\\Temp/ipykernel_11676/1179529721.py:11: FutureWarning: Your version of xlrd is 1.2.0. In xlrd >= 2.0, only the xls format is supported. As a result, the openpyxl engine will be used if it is installed and the engine argument is not specified. Install openpyxl instead.\n",
      "  df = pd.read_excel(data_url+data_name, header=1)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ISE</th>\n",
       "      <th>ISE.1</th>\n",
       "      <th>SP</th>\n",
       "      <th>DAX</th>\n",
       "      <th>FTSE</th>\n",
       "      <th>NIKKEI</th>\n",
       "      <th>BOVESPA</th>\n",
       "      <th>EU</th>\n",
       "      <th>EM</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.035754</td>\n",
       "      <td>0.038376</td>\n",
       "      <td>-0.004679</td>\n",
       "      <td>0.002193</td>\n",
       "      <td>0.003894</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.031190</td>\n",
       "      <td>0.012698</td>\n",
       "      <td>0.028524</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.025426</td>\n",
       "      <td>0.031813</td>\n",
       "      <td>0.007787</td>\n",
       "      <td>0.008455</td>\n",
       "      <td>0.012866</td>\n",
       "      <td>0.004162</td>\n",
       "      <td>0.018920</td>\n",
       "      <td>0.011341</td>\n",
       "      <td>0.008773</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-0.028862</td>\n",
       "      <td>-0.026353</td>\n",
       "      <td>-0.030469</td>\n",
       "      <td>-0.017833</td>\n",
       "      <td>-0.028735</td>\n",
       "      <td>0.017293</td>\n",
       "      <td>-0.035899</td>\n",
       "      <td>-0.017073</td>\n",
       "      <td>-0.020015</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-0.062208</td>\n",
       "      <td>-0.084716</td>\n",
       "      <td>0.003391</td>\n",
       "      <td>-0.011726</td>\n",
       "      <td>-0.000466</td>\n",
       "      <td>-0.040061</td>\n",
       "      <td>0.028283</td>\n",
       "      <td>-0.005561</td>\n",
       "      <td>-0.019424</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.009860</td>\n",
       "      <td>0.009658</td>\n",
       "      <td>-0.021533</td>\n",
       "      <td>-0.019873</td>\n",
       "      <td>-0.012710</td>\n",
       "      <td>-0.004474</td>\n",
       "      <td>-0.009764</td>\n",
       "      <td>-0.010989</td>\n",
       "      <td>-0.007802</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        ISE     ISE.1        SP       DAX      FTSE    NIKKEI   BOVESPA  \\\n",
       "0  0.035754  0.038376 -0.004679  0.002193  0.003894  0.000000  0.031190   \n",
       "1  0.025426  0.031813  0.007787  0.008455  0.012866  0.004162  0.018920   \n",
       "2 -0.028862 -0.026353 -0.030469 -0.017833 -0.028735  0.017293 -0.035899   \n",
       "3 -0.062208 -0.084716  0.003391 -0.011726 -0.000466 -0.040061  0.028283   \n",
       "4  0.009860  0.009658 -0.021533 -0.019873 -0.012710 -0.004474 -0.009764   \n",
       "\n",
       "         EU        EM  \n",
       "0  0.012698  0.028524  \n",
       "1  0.011341  0.008773  \n",
       "2 -0.017073 -0.020015  \n",
       "3 -0.005561 -0.019424  \n",
       "4 -0.010989 -0.007802  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy\n",
    "import time\n",
    "from datetime import datetime\n",
    "\n",
    "np.random.seed(42)\n",
    "numpy.random.seed(42)\n",
    "\n",
    "data_url = 'https://archive.ics.uci.edu/ml/machine-learning-databases/00247/'\n",
    "data_name = 'data_akbilgic.xlsx'\n",
    "df = pd.read_excel(data_url+data_name, header=1)\n",
    "df.drop(columns=df.columns[[0]], axis=1, inplace=True)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4b3b9893-6b3e-4df5-a94b-b089d6a9aa4e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>var1(t-24)</th>\n",
       "      <th>var2(t-24)</th>\n",
       "      <th>var3(t-24)</th>\n",
       "      <th>var4(t-24)</th>\n",
       "      <th>var5(t-24)</th>\n",
       "      <th>var6(t-24)</th>\n",
       "      <th>var7(t-24)</th>\n",
       "      <th>var8(t-24)</th>\n",
       "      <th>var9(t-24)</th>\n",
       "      <th>var1(t-23)</th>\n",
       "      <th>...</th>\n",
       "      <th>var1(t-1)</th>\n",
       "      <th>var2(t-1)</th>\n",
       "      <th>var3(t-1)</th>\n",
       "      <th>var4(t-1)</th>\n",
       "      <th>var5(t-1)</th>\n",
       "      <th>var6(t-1)</th>\n",
       "      <th>var7(t-1)</th>\n",
       "      <th>var8(t-1)</th>\n",
       "      <th>var9(t-1)</th>\n",
       "      <th>var1(t)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>0.035754</td>\n",
       "      <td>0.038376</td>\n",
       "      <td>-0.004679</td>\n",
       "      <td>0.002193</td>\n",
       "      <td>0.003894</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.031190</td>\n",
       "      <td>0.012698</td>\n",
       "      <td>0.028524</td>\n",
       "      <td>0.025426</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.014133</td>\n",
       "      <td>-0.014571</td>\n",
       "      <td>0.016233</td>\n",
       "      <td>0.003932</td>\n",
       "      <td>0.000071</td>\n",
       "      <td>-0.011169</td>\n",
       "      <td>0.024128</td>\n",
       "      <td>-0.004139</td>\n",
       "      <td>0.002073</td>\n",
       "      <td>0.036607</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>0.025426</td>\n",
       "      <td>0.031813</td>\n",
       "      <td>0.007787</td>\n",
       "      <td>0.008455</td>\n",
       "      <td>0.012866</td>\n",
       "      <td>0.004162</td>\n",
       "      <td>0.018920</td>\n",
       "      <td>0.011341</td>\n",
       "      <td>0.008773</td>\n",
       "      <td>-0.028862</td>\n",
       "      <td>...</td>\n",
       "      <td>0.036607</td>\n",
       "      <td>0.042759</td>\n",
       "      <td>0.026541</td>\n",
       "      <td>0.029306</td>\n",
       "      <td>0.014788</td>\n",
       "      <td>0.015846</td>\n",
       "      <td>0.039282</td>\n",
       "      <td>0.019127</td>\n",
       "      <td>0.032338</td>\n",
       "      <td>0.011353</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>-0.028862</td>\n",
       "      <td>-0.026353</td>\n",
       "      <td>-0.030469</td>\n",
       "      <td>-0.017833</td>\n",
       "      <td>-0.028735</td>\n",
       "      <td>0.017293</td>\n",
       "      <td>-0.035899</td>\n",
       "      <td>-0.017073</td>\n",
       "      <td>-0.020015</td>\n",
       "      <td>-0.062208</td>\n",
       "      <td>...</td>\n",
       "      <td>0.011353</td>\n",
       "      <td>0.021468</td>\n",
       "      <td>0.001484</td>\n",
       "      <td>0.004766</td>\n",
       "      <td>0.003651</td>\n",
       "      <td>-0.013411</td>\n",
       "      <td>-0.015462</td>\n",
       "      <td>0.005627</td>\n",
       "      <td>0.007895</td>\n",
       "      <td>-0.040542</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>-0.062208</td>\n",
       "      <td>-0.084716</td>\n",
       "      <td>0.003391</td>\n",
       "      <td>-0.011726</td>\n",
       "      <td>-0.000466</td>\n",
       "      <td>-0.040061</td>\n",
       "      <td>0.028283</td>\n",
       "      <td>-0.005561</td>\n",
       "      <td>-0.019424</td>\n",
       "      <td>0.009860</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.040542</td>\n",
       "      <td>-0.043907</td>\n",
       "      <td>-0.050369</td>\n",
       "      <td>-0.035170</td>\n",
       "      <td>-0.022182</td>\n",
       "      <td>-0.002902</td>\n",
       "      <td>-0.021440</td>\n",
       "      <td>-0.024388</td>\n",
       "      <td>-0.002139</td>\n",
       "      <td>-0.022106</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>0.009860</td>\n",
       "      <td>0.009658</td>\n",
       "      <td>-0.021533</td>\n",
       "      <td>-0.019873</td>\n",
       "      <td>-0.012710</td>\n",
       "      <td>-0.004474</td>\n",
       "      <td>-0.009764</td>\n",
       "      <td>-0.010989</td>\n",
       "      <td>-0.007802</td>\n",
       "      <td>-0.029191</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.022106</td>\n",
       "      <td>-0.033893</td>\n",
       "      <td>0.007923</td>\n",
       "      <td>0.005434</td>\n",
       "      <td>0.005019</td>\n",
       "      <td>-0.030745</td>\n",
       "      <td>-0.008799</td>\n",
       "      <td>0.001097</td>\n",
       "      <td>-0.007926</td>\n",
       "      <td>-0.014888</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 217 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    var1(t-24)  var2(t-24)  var3(t-24)  var4(t-24)  var5(t-24)  var6(t-24)  \\\n",
       "24    0.035754    0.038376   -0.004679    0.002193    0.003894    0.000000   \n",
       "25    0.025426    0.031813    0.007787    0.008455    0.012866    0.004162   \n",
       "26   -0.028862   -0.026353   -0.030469   -0.017833   -0.028735    0.017293   \n",
       "27   -0.062208   -0.084716    0.003391   -0.011726   -0.000466   -0.040061   \n",
       "28    0.009860    0.009658   -0.021533   -0.019873   -0.012710   -0.004474   \n",
       "\n",
       "    var7(t-24)  var8(t-24)  var9(t-24)  var1(t-23)  ...  var1(t-1)  var2(t-1)  \\\n",
       "24    0.031190    0.012698    0.028524    0.025426  ...  -0.014133  -0.014571   \n",
       "25    0.018920    0.011341    0.008773   -0.028862  ...   0.036607   0.042759   \n",
       "26   -0.035899   -0.017073   -0.020015   -0.062208  ...   0.011353   0.021468   \n",
       "27    0.028283   -0.005561   -0.019424    0.009860  ...  -0.040542  -0.043907   \n",
       "28   -0.009764   -0.010989   -0.007802   -0.029191  ...  -0.022106  -0.033893   \n",
       "\n",
       "    var3(t-1)  var4(t-1)  var5(t-1)  var6(t-1)  var7(t-1)  var8(t-1)  \\\n",
       "24   0.016233   0.003932   0.000071  -0.011169   0.024128  -0.004139   \n",
       "25   0.026541   0.029306   0.014788   0.015846   0.039282   0.019127   \n",
       "26   0.001484   0.004766   0.003651  -0.013411  -0.015462   0.005627   \n",
       "27  -0.050369  -0.035170  -0.022182  -0.002902  -0.021440  -0.024388   \n",
       "28   0.007923   0.005434   0.005019  -0.030745  -0.008799   0.001097   \n",
       "\n",
       "    var9(t-1)   var1(t)  \n",
       "24   0.002073  0.036607  \n",
       "25   0.032338  0.011353  \n",
       "26   0.007895 -0.040542  \n",
       "27  -0.002139 -0.022106  \n",
       "28  -0.007926 -0.014888  \n",
       "\n",
       "[5 rows x 217 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# series data to img function\n",
    "def series_to_img(dataset, time_step=1):\n",
    "    num = dataset.shape[1]      # features num\n",
    "    df = pd.DataFrame(dataset)\n",
    "    cols, names = list(), list()\n",
    "    # sequence t-n to t-1\n",
    "    for i in range(time_step, 0, -1):\n",
    "        cols.append(df.shift(i))\n",
    "        names += [('var%d(t-%d)' % (j+1, i)) for j in range(num)]\n",
    "\n",
    "    for i in range(0, 1):\n",
    "        cols.append(df.shift(-i))\n",
    "        if i == 0:\n",
    "            names += [('var%d(t)' % (j+1)) for j in range(num)]\n",
    "        else:\n",
    "            names += [('var%d(t+%d)' % (j+1, i)) for j in range(num)]\n",
    "\n",
    "    agg = pd.concat(cols, axis=1)\n",
    "    agg.columns = names\n",
    "    agg.dropna(inplace=True)\n",
    "    return agg\n",
    "\n",
    "from sklearn.model_selection import TimeSeriesSplit\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "dataset = df.values\n",
    "dataset = dataset.astype('float')\n",
    "\n",
    "n_inputs = 24\n",
    "n_features = 9\n",
    "del_idx = n_inputs * n_features + 1\n",
    "del_cols = [i for i in range(del_idx, del_idx+n_features-1)]\n",
    "new_df = series_to_img(dataset, n_inputs)\n",
    "new_df.drop(new_df.columns[del_cols], axis=1, inplace=True)\n",
    "new_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8e7a9ce0-17d0-4d17-8b3b-65d679ba2942",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "config : epochs, batch_size, learning_rate\n",
      "fold : 1/10\n",
      " == train [30, 32, 0.01] model ==   error(RMSE):17.26692322378628\n",
      " == train [30, 32, 0.001] model ==   error(RMSE):1.16650650587821\n",
      "train-size:55, val-size:13, test-size:42\n",
      "best_model => error(rmse) : 1.24, param:[30, 32, 0.001], times : 3.428\n",
      "\n",
      "fold : 2/10\n",
      " == train [30, 32, 0.01] model ==   error(RMSE):16.832330157692542\n",
      " == train [30, 32, 0.001] model ==   error(RMSE):0.17543737240713814\n",
      "train-size:88, val-size:22, test-size:42\n",
      "best_model => error(rmse) : 1.22, param:[30, 32, 0.001], times : 4.947\n",
      "\n",
      "fold : 3/10\n",
      " == train [30, 32, 0.01] model ==   error(RMSE):0.20210691041403409\n",
      " == train [30, 32, 0.001] model ==   error(RMSE):0.5620672378011192\n",
      "train-size:122, val-size:30, test-size:42\n",
      "best_model => error(rmse) : 16.39, param:[30, 32, 0.01], times : 6.090\n",
      "\n",
      "fold : 4/10\n",
      " == train [30, 32, 0.01] model ==   error(RMSE):19.852013530119493\n",
      " == train [30, 32, 0.001] model ==   error(RMSE):1.3898215560650853\n",
      "train-size:156, val-size:38, test-size:42\n",
      "best_model => error(rmse) : 1.63, param:[30, 32, 0.001], times : 9.602\n",
      "\n",
      "fold : 5/10\n",
      " == train [30, 32, 0.01] model ==   error(RMSE):0.20550469140162544\n",
      " == train [30, 32, 0.001] model ==   error(RMSE):1.6645918086441074\n",
      "train-size:189, val-size:47, test-size:42\n",
      "best_model => error(rmse) : 15.64, param:[30, 32, 0.01], times : 11.070\n",
      "\n",
      "fold : 6/10\n",
      " == train [30, 32, 0.01] model ==   error(RMSE):19.474042328726448\n",
      " == train [30, 32, 0.001] model ==   error(RMSE):1.0618280588108293\n",
      "train-size:223, val-size:55, test-size:42\n",
      "best_model => error(rmse) : 0.14, param:[30, 32, 0.001], times : 12.376\n",
      "\n",
      "fold : 7/10\n",
      " == train [30, 32, 0.01] model ==   error(RMSE):0.45146969033914525\n",
      " == train [30, 32, 0.001] model ==   error(RMSE):0.501471802142903\n",
      "train-size:256, val-size:64, test-size:42\n",
      "best_model => error(rmse) : 11.45, param:[30, 32, 0.01], times : 17.369\n",
      "\n",
      "fold : 8/10\n",
      " == train [30, 32, 0.01] model ==   error(RMSE):11.42611093247279\n",
      " == train [30, 32, 0.001] model ==   error(RMSE):0.6642369432021606\n",
      "train-size:290, val-size:72, test-size:42\n",
      "best_model => error(rmse) : 1.47, param:[30, 32, 0.001], times : 16.919\n",
      "\n",
      "fold : 9/10\n",
      " == train [30, 32, 0.01] model ==   error(RMSE):0.832135729233332\n",
      " == train [30, 32, 0.001] model ==   error(RMSE):1.5901683878848694\n",
      "train-size:324, val-size:80, test-size:42\n",
      "best_model => error(rmse) : 11.69, param:[30, 32, 0.01], times : 19.092\n",
      "\n",
      "fold : 10/10\n",
      " == train [30, 32, 0.01] model ==   error(RMSE):18.17718079200713\n",
      " == train [30, 32, 0.001] model ==   error(RMSE):2.004438931759682\n",
      "train-size:357, val-size:89, test-size:42\n",
      "best_model => error(rmse) : 1.48, param:[30, 32, 0.001], times : 20.272\n",
      "\n"
     ]
    }
   ],
   "source": [
    "n_splits = 10\n",
    "train_test_split = TimeSeriesSplit(n_splits=n_splits+1, gap=n_inputs).split(new_df)\n",
    "next(train_test_split)\n",
    "\n",
    "configs = model_config()\n",
    "history = []\n",
    "\n",
    "best_rmse, best_mse, best_mae = [], [], []\n",
    "learning_time = []\n",
    "i = 1\n",
    "\n",
    "print('config : epochs, batch_size, learning_rate')\n",
    "\n",
    "# neted cross validation\n",
    "for train_cv_indices, test_cv_indices in train_test_split:\n",
    "    print(f'fold : {i}/{n_splits}')\n",
    "    i+=1\n",
    "\n",
    "    # split x, y data\n",
    "    train_cv_X, train_cv_y = new_df.iloc[train_cv_indices, :-1].values, new_df.iloc[train_cv_indices,-1].values\n",
    "    test_cv_X, test_cv_y = new_df.iloc[test_cv_indices, :-1].values, new_df.iloc[test_cv_indices, -1].values\n",
    "\n",
    "    # length for validation set\n",
    "    test_length = int(len(train_cv_X)*0.2)\n",
    "\n",
    "    # scaling data\n",
    "    scaler_x = MinMaxScaler()\n",
    "    train_cv_X = scaler_x.fit_transform(train_cv_X)\n",
    "    test_cv_X = scaler_x.transform(test_cv_X)\n",
    "\n",
    "    train_X, val_X = train_cv_X[:-test_length, :], train_cv_X[-test_length:, :]\n",
    "    train_y, val_y = train_cv_y[:-test_length], train_cv_y[-test_length:]\n",
    "\n",
    "    # reshape\n",
    "    # inner loop\n",
    "    train_X = train_X.reshape(-1,  n_inputs, n_features)\n",
    "    val_X = val_X.reshape(-1, n_inputs, n_features)\n",
    "    train_y = train_y.reshape(-1, 1)\n",
    "    val_y = val_y.reshape(-1, 1)\n",
    "\n",
    "    # outer loop\n",
    "    train_cv_X = train_cv_X.reshape(-1,  n_inputs, n_features)\n",
    "    test_cv_X = test_cv_X.reshape(-1, n_inputs, n_features)\n",
    "    train_cv_y = train_cv_y.reshape(-1, 1)\n",
    "    test_cv_y = test_cv_y.reshape(-1, 1)\n",
    "\n",
    "    # model fit, inner\n",
    "    errors = []\n",
    "    for idx, cfg in enumerate(configs):\n",
    "        print(f' == train {cfg} model == ', end=' ')\n",
    "        model = model_fit(train_X, train_y, cfg)\n",
    "        model.reset_state()\n",
    "        predicted = model.predict(val_X)\n",
    "        if GPU:\n",
    "            predicted = np.asnumpy(predicted)\n",
    "        error = np.sqrt(MSE_metric(predicted, val_y))   # rmse\n",
    "        print(f' error(RMSE):{error}')\n",
    "        if errors:\n",
    "            if error < min(errors):\n",
    "                param = idx\n",
    "        else:\n",
    "            param = idx\n",
    "        errors.append(error)\n",
    "\n",
    "    history.append(errors)\n",
    "    \n",
    "    # check start time\n",
    "    start_time = time.time()\n",
    "    # model fitting\n",
    "    selected_model = model_fit(train_cv_X,train_cv_y, configs[param])\n",
    "    # check duration\n",
    "    duration = time.time()-start_time\n",
    "    selected_model.reset_state()\n",
    "    predicted = selected_model.predict(test_cv_X)\n",
    "    if GPU:\n",
    "        predicted = np.asnumpy(predicted)\n",
    "\n",
    "    rmse = np.sqrt(MSE_metric(predicted, test_cv_y))\n",
    "    mse = MSE_metric(predicted, test_cv_y)\n",
    "    mae = MAE_metric(predicted, test_cv_y)\n",
    "    best_rmse.append(rmse)\n",
    "    best_mse.append(mse)\n",
    "    best_mae.append(mae)\n",
    "    learning_time.append(duration)\n",
    "\n",
    "    # model eval\n",
    "    print(f'train-size:{train_X.shape[0]}, val-size:{val_X.shape[0]}, test-size:{test_cv_X.shape[0]}')\n",
    "    print(f'best_model => error(rmse) : {rmse.item():.2f}, param:{configs[param]}, times : {duration:.3f}')\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "9a301bb4-5a87-4e01-bf7e-ffe081d5dd81",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE: mean=79.12675036825463, std=102.65345474115449\n",
      "RMSE: mean=6.235813038382236, std=6.343609864942574\n",
      "MAE: mean=6.233683277464621, std=6.344387170597406\n",
      "\n",
      "[training time]\n",
      "mean : 12.116526651382447, last:20.27159333229065\n"
     ]
    }
   ],
   "source": [
    "def model_evaluation(mse, rmse, mae):\n",
    "    mse = np.array(mse)\n",
    "    rmse = np.array(rmse)\n",
    "    mae = np.array(mae)\n",
    "    print(f'MSE: mean={np.mean(mse)}, std={np.std(mse)}')\n",
    "    print(f'RMSE: mean={np.mean(rmse)}, std={np.std(rmse)}')\n",
    "    print(f'MAE: mean={np.mean(mae)}, std={np.std(mae)}')\n",
    "\n",
    "model_evaluation(best_mse, best_rmse, best_mae)\n",
    "\n",
    "# check time\n",
    "print()\n",
    "print('[training time]')\n",
    "print(f'mean : {np.mean(np.array(learning_time))}, last:{learning_time[-1]}')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch",
   "language": "python",
   "name": "pytorch"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
