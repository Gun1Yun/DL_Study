{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4093eb72-7bcc-4fad-a1ee-2468222ea54a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "\n",
    "MODULE_PATH = 'C:\\Github\\DL_Study\\CNN'\n",
    "\n",
    "sys.path.insert(0, MODULE_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3dfc306d-9bd5-499b-89f7-3a4e94add68e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch._C.Generator at 0x159422b4430>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# import\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import numpy\n",
    "import time\n",
    "\n",
    "from ShuffleNet import *\n",
    "\n",
    "# set random seed\n",
    "torch.manual_seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "70e62e75-7274-4648-a76e-8f17502b48ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_device():\n",
    "    if torch.cuda.is_available():\n",
    "        device = torch.device('cuda:0')\n",
    "    else:\n",
    "        device = torch.device('cpu')\n",
    "    return device\n",
    "\n",
    "def df_to_tensor(df):\n",
    "    device = get_device()\n",
    "    return torch.from_numpy(df.values).float().to(device)\n",
    "\n",
    "def np_to_tensor(data):\n",
    "    device = get_device()\n",
    "    return torch.tensor(data).float().to(device)\n",
    "\n",
    "# configuration setting\n",
    "def model_config():\n",
    "    # parameter for CNN Model\n",
    "    epochs = [30]\n",
    "    batch_size = [64]\n",
    "    learning_rate = [0.01, 0.001]\n",
    "    \n",
    "    # create config data\n",
    "    configs = []\n",
    "    for i in epochs:\n",
    "        for j in batch_size:\n",
    "            for k in learning_rate:\n",
    "                config = [i, j, k]\n",
    "                configs.append(config)\n",
    "    return configs\n",
    "\n",
    "# fucntion for fit cnn model using configs\n",
    "def model_fit(train_X, train_y, config, verbose=0):\n",
    "\n",
    "    # unpack config\n",
    "    n_epochs, n_batch, learning_rate = config\n",
    "    # use ShuffleNet for CNN\n",
    "    model = ShuffleNet(groups=3, in_channels=1)\n",
    "    if torch.cuda.is_available():\n",
    "        model.cuda()\n",
    "\n",
    "    # define Loss and Optimizer\n",
    "    criterion = nn.MSELoss()\n",
    "    optimizer = optim.Adam(model.parameters(), lr=learning_rate)\n",
    "\n",
    "    data_size = train_X.size(0)\n",
    "    max_iters = data_size//n_batch\n",
    "\n",
    "    for epoch in range(1, n_epochs+1):\n",
    "        #shuffle data\n",
    "        idx = numpy.random.permutation(numpy.arange(data_size))\n",
    "        x_data = train_X[idx]\n",
    "        y_data = train_y[idx]\n",
    "\n",
    "        epoch_loss = 0\n",
    "        start_time = time.time()\n",
    "        for it in range(max_iters):\n",
    "            batch_x = x_data[it*n_batch:(it+1)*n_batch]\n",
    "            batch_y = y_data[it*n_batch:(it+1)*n_batch]\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            predict = model(batch_x)\n",
    "            loss = criterion(predict, batch_y)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            epoch_loss+= loss.item()\n",
    "        avg_loss = epoch_loss/max_iters\n",
    "\n",
    "        if verbose:\n",
    "            duration = start_time-time.time()\n",
    "            print(f'epoch:{epoch}/{epochs}, ì‹œê°„:{duration:.2f}[s], loss:{avg_loss:.5f}')\n",
    "\n",
    "\n",
    "    return model\n",
    "\n",
    "def MAE_metric(x, t):\n",
    "    t = np.array(t)\n",
    "    return np.mean(numpy.abs(x-t))\n",
    "\n",
    "def MSE_metric(x, t):\n",
    "    t = np.array(t)\n",
    "    return np.mean((x-t)**2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "bb92ba63-bf38-41b6-a7f3-5f83a0a9787c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>pm2.5</th>\n",
       "      <th>DEWP</th>\n",
       "      <th>TEMP</th>\n",
       "      <th>PRES</th>\n",
       "      <th>cbwd</th>\n",
       "      <th>Iws</th>\n",
       "      <th>Is</th>\n",
       "      <th>Ir</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>year_month_day_hour</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2010-01-02 00:00:00</th>\n",
       "      <td>129.0</td>\n",
       "      <td>-16</td>\n",
       "      <td>-4.0</td>\n",
       "      <td>1020.0</td>\n",
       "      <td>SE</td>\n",
       "      <td>1.79</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2010-01-02 01:00:00</th>\n",
       "      <td>148.0</td>\n",
       "      <td>-15</td>\n",
       "      <td>-4.0</td>\n",
       "      <td>1020.0</td>\n",
       "      <td>SE</td>\n",
       "      <td>2.68</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2010-01-02 02:00:00</th>\n",
       "      <td>159.0</td>\n",
       "      <td>-11</td>\n",
       "      <td>-5.0</td>\n",
       "      <td>1021.0</td>\n",
       "      <td>SE</td>\n",
       "      <td>3.57</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2010-01-02 03:00:00</th>\n",
       "      <td>181.0</td>\n",
       "      <td>-7</td>\n",
       "      <td>-5.0</td>\n",
       "      <td>1022.0</td>\n",
       "      <td>SE</td>\n",
       "      <td>5.36</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2010-01-02 04:00:00</th>\n",
       "      <td>138.0</td>\n",
       "      <td>-7</td>\n",
       "      <td>-5.0</td>\n",
       "      <td>1022.0</td>\n",
       "      <td>SE</td>\n",
       "      <td>6.25</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                     pm2.5  DEWP  TEMP    PRES cbwd   Iws  Is  Ir\n",
       "year_month_day_hour                                              \n",
       "2010-01-02 00:00:00  129.0   -16  -4.0  1020.0   SE  1.79   0   0\n",
       "2010-01-02 01:00:00  148.0   -15  -4.0  1020.0   SE  2.68   0   0\n",
       "2010-01-02 02:00:00  159.0   -11  -5.0  1021.0   SE  3.57   0   0\n",
       "2010-01-02 03:00:00  181.0    -7  -5.0  1022.0   SE  5.36   1   0\n",
       "2010-01-02 04:00:00  138.0    -7  -5.0  1022.0   SE  6.25   2   0"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy\n",
    "import numpy as np\n",
    "import time\n",
    "from datetime import datetime\n",
    "\n",
    "np.random.seed(42)\n",
    "numpy.random.seed(42)\n",
    "\n",
    "df_parser = lambda x: datetime.strptime(x, '%Y %m %d %H')\n",
    "\n",
    "data_url = 'https://archive.ics.uci.edu/ml/machine-learning-databases/00381/'\n",
    "data_name = 'PRSA_data_2010.1.1-2014.12.31.csv'\n",
    "df = pd.read_csv(data_url+data_name, sep=',', parse_dates=[['year', 'month', 'day', 'hour']], date_parser=df_parser, index_col=0)\n",
    "del df['No']\n",
    "df = df[24:]\n",
    "df = df[:10000]\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c6e3399a-cfec-45f2-a922-42c22883080c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>var1(t-24)</th>\n",
       "      <th>var2(t-24)</th>\n",
       "      <th>var3(t-24)</th>\n",
       "      <th>var4(t-24)</th>\n",
       "      <th>var5(t-24)</th>\n",
       "      <th>var6(t-24)</th>\n",
       "      <th>var7(t-24)</th>\n",
       "      <th>var8(t-24)</th>\n",
       "      <th>var1(t-23)</th>\n",
       "      <th>var2(t-23)</th>\n",
       "      <th>...</th>\n",
       "      <th>var8(t-2)</th>\n",
       "      <th>var1(t-1)</th>\n",
       "      <th>var2(t-1)</th>\n",
       "      <th>var3(t-1)</th>\n",
       "      <th>var4(t-1)</th>\n",
       "      <th>var5(t-1)</th>\n",
       "      <th>var6(t-1)</th>\n",
       "      <th>var7(t-1)</th>\n",
       "      <th>var8(t-1)</th>\n",
       "      <th>var1(t)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>129.0</td>\n",
       "      <td>-16.0</td>\n",
       "      <td>-4.0</td>\n",
       "      <td>1020.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.79</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>148.0</td>\n",
       "      <td>-15.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>126.0</td>\n",
       "      <td>-8.0</td>\n",
       "      <td>-6.0</td>\n",
       "      <td>1027.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>55.43</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>90.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>148.0</td>\n",
       "      <td>-15.0</td>\n",
       "      <td>-4.0</td>\n",
       "      <td>1020.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.68</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>159.0</td>\n",
       "      <td>-11.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>90.0</td>\n",
       "      <td>-7.0</td>\n",
       "      <td>-6.0</td>\n",
       "      <td>1027.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>58.56</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>63.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>159.0</td>\n",
       "      <td>-11.0</td>\n",
       "      <td>-5.0</td>\n",
       "      <td>1021.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.57</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>181.0</td>\n",
       "      <td>-7.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>63.0</td>\n",
       "      <td>-8.0</td>\n",
       "      <td>-6.0</td>\n",
       "      <td>1026.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>61.69</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>65.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>181.0</td>\n",
       "      <td>-7.0</td>\n",
       "      <td>-5.0</td>\n",
       "      <td>1022.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>5.36</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>138.0</td>\n",
       "      <td>-7.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>65.0</td>\n",
       "      <td>-8.0</td>\n",
       "      <td>-7.0</td>\n",
       "      <td>1026.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>65.71</td>\n",
       "      <td>6.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>55.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>138.0</td>\n",
       "      <td>-7.0</td>\n",
       "      <td>-5.0</td>\n",
       "      <td>1022.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>6.25</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>109.0</td>\n",
       "      <td>-7.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>55.0</td>\n",
       "      <td>-8.0</td>\n",
       "      <td>-7.0</td>\n",
       "      <td>1025.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>68.84</td>\n",
       "      <td>7.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>65.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 193 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    var1(t-24)  var2(t-24)  var3(t-24)  var4(t-24)  var5(t-24)  var6(t-24)  \\\n",
       "24       129.0       -16.0        -4.0      1020.0         2.0        1.79   \n",
       "25       148.0       -15.0        -4.0      1020.0         2.0        2.68   \n",
       "26       159.0       -11.0        -5.0      1021.0         2.0        3.57   \n",
       "27       181.0        -7.0        -5.0      1022.0         2.0        5.36   \n",
       "28       138.0        -7.0        -5.0      1022.0         2.0        6.25   \n",
       "\n",
       "    var7(t-24)  var8(t-24)  var1(t-23)  var2(t-23)  ...  var8(t-2)  var1(t-1)  \\\n",
       "24         0.0         0.0       148.0       -15.0  ...        0.0      126.0   \n",
       "25         0.0         0.0       159.0       -11.0  ...        0.0       90.0   \n",
       "26         0.0         0.0       181.0        -7.0  ...        0.0       63.0   \n",
       "27         1.0         0.0       138.0        -7.0  ...        0.0       65.0   \n",
       "28         2.0         0.0       109.0        -7.0  ...        0.0       55.0   \n",
       "\n",
       "    var2(t-1)  var3(t-1)  var4(t-1)  var5(t-1)  var6(t-1)  var7(t-1)  \\\n",
       "24       -8.0       -6.0     1027.0        2.0      55.43        3.0   \n",
       "25       -7.0       -6.0     1027.0        2.0      58.56        4.0   \n",
       "26       -8.0       -6.0     1026.0        2.0      61.69        5.0   \n",
       "27       -8.0       -7.0     1026.0        2.0      65.71        6.0   \n",
       "28       -8.0       -7.0     1025.0        2.0      68.84        7.0   \n",
       "\n",
       "    var8(t-1)  var1(t)  \n",
       "24        0.0     90.0  \n",
       "25        0.0     63.0  \n",
       "26        0.0     65.0  \n",
       "27        0.0     55.0  \n",
       "28        0.0     65.0  \n",
       "\n",
       "[5 rows x 193 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# series data to img function\n",
    "def series_to_img(dataset, time_step=1):\n",
    "    num = dataset.shape[1]      # features num\n",
    "    df = pd.DataFrame(dataset)\n",
    "    cols, names = list(), list()\n",
    "    # sequence t-n to t-1\n",
    "    for i in range(time_step, 0, -1):\n",
    "        cols.append(df.shift(i))\n",
    "        names += [('var%d(t-%d)' % (j+1, i)) for j in range(num)]\n",
    "\n",
    "    for i in range(0, 1):\n",
    "        cols.append(df.shift(-i))\n",
    "        if i == 0:\n",
    "            names += [('var%d(t)' % (j+1)) for j in range(num)]\n",
    "        else:\n",
    "            names += [('var%d(t+%d)' % (j+1, i)) for j in range(num)]\n",
    "\n",
    "    agg = pd.concat(cols, axis=1)\n",
    "    agg.columns = names\n",
    "    agg.dropna(inplace=True)\n",
    "    return agg\n",
    "\n",
    "from sklearn.model_selection import TimeSeriesSplit\n",
    "from sklearn.preprocessing import LabelEncoder, MinMaxScaler\n",
    "\n",
    "# Last observation carried forward (LOCF)\n",
    "df.fillna(method='ffill', inplace=True)\n",
    "\n",
    "dataset = df.values\n",
    "label_encoder = LabelEncoder()\n",
    "dataset[:, 4] = label_encoder.fit_transform(dataset[:, 4])  # for wind direction\n",
    "dataset = dataset.astype('float')\n",
    "\n",
    "n_inputs = 24\n",
    "n_features = 8\n",
    "del_idx = n_inputs * n_features + 1\n",
    "del_cols = [i for i in range(del_idx, del_idx+n_features-1)]\n",
    "new_df = series_to_img(dataset, n_inputs)\n",
    "new_df.drop(new_df.columns[del_cols], axis=1, inplace=True)\n",
    "new_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2e8df4dd-35f6-44c2-b975-14614290c801",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "config : epochs, batch_size, learning_rate\n",
      "fold : 1/10\n",
      " == train [30, 64, 0.01] model ==  "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\lab\\anaconda3\\envs\\pytorch\\lib\\site-packages\\torch\\nn\\functional.py:718: UserWarning: Named tensors and all their associated APIs are an experimental feature and subject to change. Please do not use them for anything important until they are released as stable. (Triggered internally at  ..\\c10/core/TensorImpl.h:1156.)\n",
      "  return torch.max_pool2d(input, kernel_size, stride, padding, dilation, ceil_mode)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "error(rmse):52.6097\n",
      " == train [30, 64, 0.001] model ==  error(rmse):76.4353\n",
      "train-size:1314, val-size:328, test-size:831\n",
      "best_model => error(rmse) : 62.56, param:[30, 64, 0.01], times: 29.827\n",
      "\n",
      "fold : 2/10\n",
      " == train [30, 64, 0.01] model ==  error(rmse):42.0659\n",
      " == train [30, 64, 0.001] model ==  error(rmse):63.0303\n",
      "train-size:1979, val-size:494, test-size:831\n",
      "best_model => error(rmse) : 44.67, param:[30, 64, 0.01], times: 45.211\n",
      "\n",
      "fold : 3/10\n",
      " == train [30, 64, 0.01] model ==  error(rmse):48.7150\n",
      " == train [30, 64, 0.001] model ==  error(rmse):56.8376\n",
      "train-size:2644, val-size:660, test-size:831\n",
      "best_model => error(rmse) : 57.71, param:[30, 64, 0.01], times: 60.542\n",
      "\n",
      "fold : 4/10\n",
      " == train [30, 64, 0.01] model ==  error(rmse):46.4451\n",
      " == train [30, 64, 0.001] model ==  error(rmse):65.8012\n",
      "train-size:3308, val-size:827, test-size:831\n",
      "best_model => error(rmse) : 46.30, param:[30, 64, 0.01], times: 75.911\n",
      "\n",
      "fold : 5/10\n",
      " == train [30, 64, 0.01] model ==  error(rmse):41.1377\n",
      " == train [30, 64, 0.001] model ==  error(rmse):51.8009\n",
      "train-size:3973, val-size:993, test-size:831\n",
      "best_model => error(rmse) : 29.68, param:[30, 64, 0.01], times: 91.497\n",
      "\n",
      "fold : 6/10\n",
      " == train [30, 64, 0.01] model ==  error(rmse):37.2363\n",
      " == train [30, 64, 0.001] model ==  error(rmse):52.9894\n",
      "train-size:4638, val-size:1159, test-size:831\n",
      "best_model => error(rmse) : 32.94, param:[30, 64, 0.01], times: 106.901\n",
      "\n",
      "fold : 7/10\n",
      " == train [30, 64, 0.01] model ==  error(rmse):28.7152\n",
      " == train [30, 64, 0.001] model ==  error(rmse):40.0234\n",
      "train-size:5303, val-size:1325, test-size:831\n",
      "best_model => error(rmse) : 60.80, param:[30, 64, 0.01], times: 122.532\n",
      "\n",
      "fold : 8/10\n",
      " == train [30, 64, 0.01] model ==  error(rmse):45.5574\n",
      " == train [30, 64, 0.001] model ==  error(rmse):52.6185\n",
      "train-size:5968, val-size:1491, test-size:831\n",
      "best_model => error(rmse) : 62.64, param:[30, 64, 0.01], times: 138.231\n",
      "\n",
      "fold : 9/10\n",
      " == train [30, 64, 0.01] model ==  error(rmse):66.6543\n",
      " == train [30, 64, 0.001] model ==  error(rmse):71.9005\n",
      "train-size:6632, val-size:1658, test-size:831\n",
      "best_model => error(rmse) : 38.02, param:[30, 64, 0.01], times: 154.066\n",
      "\n",
      "fold : 10/10\n",
      " == train [30, 64, 0.01] model ==  error(rmse):36.9898\n",
      " == train [30, 64, 0.001] model ==  error(rmse):56.0492\n",
      "train-size:7297, val-size:1824, test-size:831\n",
      "best_model => error(rmse) : 48.37, param:[30, 64, 0.01], times: 169.599\n",
      "\n"
     ]
    }
   ],
   "source": [
    "n_splits = 10\n",
    "train_test_split = TimeSeriesSplit(n_splits=n_splits+1, gap=n_inputs).split(new_df)\n",
    "next(train_test_split)\n",
    "\n",
    "configs = model_config()\n",
    "history = []\n",
    "\n",
    "best_rmse, best_mse, best_mae = [], [], []\n",
    "learning_time = []\n",
    "\n",
    "i = 1\n",
    "\n",
    "print('config : epochs, batch_size, learning_rate')\n",
    "\n",
    "# nested cross validation for time series model\n",
    "for train_cv_indices, test_cv_indices in train_test_split:\n",
    "    print(f'fold : {i}/{n_splits}')\n",
    "    i+=1\n",
    "\n",
    "    # split x, y data\n",
    "    train_cv_X, train_cv_y = new_df.iloc[train_cv_indices, :-1].values, new_df.iloc[train_cv_indices,-1].values\n",
    "    test_cv_X, test_cv_y = new_df.iloc[test_cv_indices, :-1].values, new_df.iloc[test_cv_indices, -1].values\n",
    "\n",
    "    # length for validation set\n",
    "    test_length = int(len(train_cv_X)*0.2)\n",
    "\n",
    "    # scaling data\n",
    "    scaler_x = MinMaxScaler()\n",
    "    train_cv_X = scaler_x.fit_transform(train_cv_X)\n",
    "    test_cv_X = scaler_x.transform(test_cv_X)\n",
    "\n",
    "    train_X, val_X = train_cv_X[:-test_length, :], train_cv_X[-test_length:, :]\n",
    "    train_y, val_y = train_cv_y[:-test_length], train_cv_y[-test_length:]\n",
    "\n",
    "    # reshape\n",
    "    # inner loop\n",
    "    train_X = train_X.reshape(-1, 1, n_inputs, n_features)\n",
    "    val_X = val_X.reshape(-1, 1, n_inputs, n_features)\n",
    "    train_y = train_y.reshape(-1, 1)\n",
    "    val_y = val_y.reshape(-1, 1)\n",
    "\n",
    "    # outer loop\n",
    "    train_cv_X = train_cv_X.reshape(-1, 1, n_inputs, n_features)\n",
    "    test_cv_X = test_cv_X.reshape(-1, 1, n_inputs, n_features)\n",
    "    train_cv_y = train_cv_y.reshape(-1, 1)\n",
    "    test_cv_y = test_cv_y.reshape(-1, 1)\n",
    "\n",
    "    train_X = np_to_tensor(train_X)\n",
    "    train_y = np_to_tensor(train_y)\n",
    "    val_X = np_to_tensor(val_X)\n",
    "    val_y = np_to_tensor(val_y)\n",
    "    train_cv_X = np_to_tensor(train_cv_X)\n",
    "    train_cv_y = np_to_tensor(train_cv_y)\n",
    "    test_cv_X = np_to_tensor(test_cv_X)\n",
    "    test_cv_y = np_to_tensor(test_cv_y)\n",
    "\n",
    "    # model fit, inner\n",
    "    errors = []\n",
    "    for idx, cfg in enumerate(configs):\n",
    "        print(f' == train {cfg} model == ', end=' ')\n",
    "        model = model_fit(train_X, train_y, cfg)\n",
    "        predicted = model(val_X)\n",
    "        error = F.mse_loss(predicted, val_y)   # mse\n",
    "        print(f'error(rmse):{np.sqrt(error.item()):.4f}')\n",
    "        if errors:\n",
    "            if error.item() < min(errors):\n",
    "                param = idx\n",
    "        else:\n",
    "            param = idx\n",
    "        errors.append(error.item())\n",
    "\n",
    "    history.append(errors)\n",
    "\n",
    "    # outer\n",
    "    start_time = time.time()\n",
    "    # model fitting\n",
    "    selected_model = model_fit(train_cv_X,train_cv_y, configs[param])\n",
    "    # check time\n",
    "    duration = time.time() - start_time\n",
    "    predicted = selected_model(test_cv_X)\n",
    "    rmse = np.sqrt(F.mse_loss(predicted, test_cv_y).item())\n",
    "    mse = F.mse_loss(predicted, test_cv_y)\n",
    "    mae = F.l1_loss(predicted, test_cv_y)\n",
    "    best_rmse.append(rmse)\n",
    "    best_mse.append(mse.item())\n",
    "    best_mae.append(mae.item())\n",
    "    learning_time.append(duration)\n",
    "\n",
    "    # model eval\n",
    "    print(f'train-size:{train_X.size(0)}, val-size:{val_X.size(0)}, test-size:{test_cv_X.size(0)}')\n",
    "    print(f'best_model => error(rmse) : {rmse:.2f}, param:{configs[param]}, times: {duration:.3f}')\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5eca16dd-2339-47ea-8d2d-7520ba1000e2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE: mean=2475.5290405273436, std=1108.4068347474893\n",
      "RMSE: mean=48.36936864020113, std=11.659040178148054\n",
      "MAE: mean=31.581441497802736, std=5.8800121606562525\n",
      "\n",
      "[training time]\n",
      "mean : 99.43167414665223, last:169.59912753105164\n"
     ]
    }
   ],
   "source": [
    "def model_evaluation(mse, rmse, mae):\n",
    "    mse = np.array(mse)\n",
    "    rmse = np.array(rmse)\n",
    "    mae = np.array(mae)\n",
    "    print(f'MSE: mean={np.mean(mse)}, std={np.std(mse)}')\n",
    "    print(f'RMSE: mean={np.mean(rmse)}, std={np.std(rmse)}')\n",
    "    print(f'MAE: mean={np.mean(mae)}, std={np.std(mae)}')\n",
    "\n",
    "model_evaluation(best_mse, best_rmse, best_mae)\n",
    "\n",
    "# check time\n",
    "print()\n",
    "print('[training time]')\n",
    "print(f'mean : {np.mean(np.array(learning_time))}, last:{learning_time[-1]}')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch",
   "language": "python",
   "name": "pytorch"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
