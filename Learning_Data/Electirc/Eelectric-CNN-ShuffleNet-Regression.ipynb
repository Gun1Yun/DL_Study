{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "569769b5-1a38-4860-b4a5-cbf38e6912f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "\n",
    "MODULE_PATH = 'C:\\Github\\DL_Study\\CNN'\n",
    "\n",
    "sys.path.insert(0, MODULE_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ab541283-1401-4135-afd8-c2ca5159a2cc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch._C.Generator at 0x1afee068410>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# import\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import numpy\n",
    "import time\n",
    "\n",
    "from ShuffleNet import *\n",
    "\n",
    "# set random seed\n",
    "torch.manual_seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7827e864-46aa-49b2-bdbd-1a377f43c8c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_device():\n",
    "    if torch.cuda.is_available():\n",
    "        device = torch.device('cuda:0')\n",
    "    else:\n",
    "        device = torch.device('cpu')\n",
    "    return device\n",
    "\n",
    "def df_to_tensor(df):\n",
    "    device = get_device()\n",
    "    return torch.from_numpy(df.values).float().to(device)\n",
    "\n",
    "def np_to_tensor(data):\n",
    "    device = get_device()\n",
    "    return torch.tensor(data).float().to(device)\n",
    "\n",
    "# configuration setting\n",
    "def model_config():\n",
    "    # parameter for CNN Model\n",
    "    epochs = [30]\n",
    "    batch_size = [64]\n",
    "    learning_rate = [0.01, 0.001]\n",
    "    \n",
    "    # create config data\n",
    "    configs = []\n",
    "    for i in epochs:\n",
    "        for j in batch_size:\n",
    "            for k in learning_rate:\n",
    "                config = [i, j, k]\n",
    "                configs.append(config)\n",
    "    return configs\n",
    "\n",
    "# fucntion for fit cnn model using configs\n",
    "def model_fit(train_X, train_y, config, verbose=0):\n",
    "\n",
    "    # unpack config\n",
    "    n_epochs, n_batch, learning_rate = config\n",
    "    # use ShuffleNet for CNN\n",
    "    model = ShuffleNet(groups=3, in_channels=1)\n",
    "    if torch.cuda.is_available():\n",
    "        model.cuda()\n",
    "\n",
    "    # define Loss and Optimizer\n",
    "    criterion = nn.MSELoss()\n",
    "    optimizer = optim.Adam(model.parameters(), lr=learning_rate)\n",
    "\n",
    "    data_size = train_X.size(0)\n",
    "    max_iters = data_size//n_batch\n",
    "\n",
    "    for epoch in range(1, n_epochs+1):\n",
    "        #shuffle data\n",
    "        idx = numpy.random.permutation(numpy.arange(data_size))\n",
    "        x_data = train_X[idx]\n",
    "        y_data = train_y[idx]\n",
    "\n",
    "        epoch_loss = 0\n",
    "        start_time = time.time()\n",
    "        for it in range(max_iters):\n",
    "            batch_x = x_data[it*n_batch:(it+1)*n_batch]\n",
    "            batch_y = y_data[it*n_batch:(it+1)*n_batch]\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            predict = model(batch_x)\n",
    "            loss = criterion(predict, batch_y)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            epoch_loss+= loss.item()\n",
    "        avg_loss = epoch_loss/max_iters\n",
    "\n",
    "        if verbose:\n",
    "            duration = start_time-time.time()\n",
    "            print(f'epoch:{epoch}/{epochs}, ì‹œê°„:{duration:.2f}[s], loss:{avg_loss:.5f}')\n",
    "\n",
    "\n",
    "    return model\n",
    "\n",
    "def MAE_metric(x, t):\n",
    "    t = np.array(t)\n",
    "    return np.mean(numpy.abs(x-t))\n",
    "\n",
    "def MSE_metric(x, t):\n",
    "    t = np.array(t)\n",
    "    return np.mean((x-t)**2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3d5650be-d6d4-4704-9f05-4c3b1cd4000a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\lab\\anaconda3\\envs\\pytorch\\lib\\site-packages\\IPython\\core\\interactiveshell.py:3169: DtypeWarning: Columns (2,3,4,5,6,7) have mixed types.Specify dtype option on import or set low_memory=False.\n",
      "  has_raised = await self.run_ast_nodes(code_ast.body, cell_name,\n",
      "C:\\Users\\lab\\AppData\\Local\\Temp/ipykernel_8032/1157829677.py:15: FutureWarning: Indexing a DataFrame with a datetimelike index using a single string to slice the rows, like `frame[string]`, is deprecated and will be removed in a future version. Use `frame.loc[string]` instead.\n",
      "  df = df['2007']\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Global_active_power</th>\n",
       "      <th>Global_reactive_power</th>\n",
       "      <th>Voltage</th>\n",
       "      <th>Global_intensity</th>\n",
       "      <th>Sub_metering_1</th>\n",
       "      <th>Sub_metering_2</th>\n",
       "      <th>Sub_metering_3</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Date_Time</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2007-01-01 00:00:00</th>\n",
       "      <td>2.580</td>\n",
       "      <td>0.136</td>\n",
       "      <td>241.97</td>\n",
       "      <td>10.6</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2007-01-01 00:01:00</th>\n",
       "      <td>2.552</td>\n",
       "      <td>0.100</td>\n",
       "      <td>241.75</td>\n",
       "      <td>10.4</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2007-01-01 00:02:00</th>\n",
       "      <td>2.550</td>\n",
       "      <td>0.100</td>\n",
       "      <td>241.64</td>\n",
       "      <td>10.4</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2007-01-01 00:03:00</th>\n",
       "      <td>2.550</td>\n",
       "      <td>0.100</td>\n",
       "      <td>241.71</td>\n",
       "      <td>10.4</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2007-01-01 00:04:00</th>\n",
       "      <td>2.554</td>\n",
       "      <td>0.100</td>\n",
       "      <td>241.98</td>\n",
       "      <td>10.4</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                     Global_active_power  Global_reactive_power  Voltage  \\\n",
       "Date_Time                                                                  \n",
       "2007-01-01 00:00:00                2.580                  0.136   241.97   \n",
       "2007-01-01 00:01:00                2.552                  0.100   241.75   \n",
       "2007-01-01 00:02:00                2.550                  0.100   241.64   \n",
       "2007-01-01 00:03:00                2.550                  0.100   241.71   \n",
       "2007-01-01 00:04:00                2.554                  0.100   241.98   \n",
       "\n",
       "                     Global_intensity  Sub_metering_1  Sub_metering_2  \\\n",
       "Date_Time                                                               \n",
       "2007-01-01 00:00:00              10.6             0.0             0.0   \n",
       "2007-01-01 00:01:00              10.4             0.0             0.0   \n",
       "2007-01-01 00:02:00              10.4             0.0             0.0   \n",
       "2007-01-01 00:03:00              10.4             0.0             0.0   \n",
       "2007-01-01 00:04:00              10.4             0.0             0.0   \n",
       "\n",
       "                     Sub_metering_3  \n",
       "Date_Time                            \n",
       "2007-01-01 00:00:00             0.0  \n",
       "2007-01-01 00:01:00             0.0  \n",
       "2007-01-01 00:02:00             0.0  \n",
       "2007-01-01 00:03:00             0.0  \n",
       "2007-01-01 00:04:00             0.0  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# testcell\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import numpy\n",
    "import time\n",
    "from datetime import datetime\n",
    "\n",
    "np.random.seed(42)\n",
    "numpy.random.seed(42)\n",
    "\n",
    "data_url = 'https://archive.ics.uci.edu/ml/machine-learning-databases/00235/household_power_consumption.zip'\n",
    "df_parser = lambda x: datetime.strptime(x, '%d/%m/%Y %H:%M:%S')\n",
    "df = pd.read_csv(data_url, compression='zip', sep=';', parse_dates=[['Date', 'Time']], date_parser=df_parser, index_col=0)\n",
    "df.replace('?', numpy.nan, inplace=True)    # nan data\n",
    "df = df['2007']\n",
    "df = df[:10000]\n",
    "df = df.astype(float)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2c15519a-b69d-4b97-b598-c16d2e55ce13",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>var1(t-24)</th>\n",
       "      <th>var2(t-24)</th>\n",
       "      <th>var3(t-24)</th>\n",
       "      <th>var4(t-24)</th>\n",
       "      <th>var5(t-24)</th>\n",
       "      <th>var6(t-24)</th>\n",
       "      <th>var7(t-24)</th>\n",
       "      <th>var1(t-23)</th>\n",
       "      <th>var2(t-23)</th>\n",
       "      <th>var3(t-23)</th>\n",
       "      <th>...</th>\n",
       "      <th>var6(t-2)</th>\n",
       "      <th>var7(t-2)</th>\n",
       "      <th>var1(t-1)</th>\n",
       "      <th>var2(t-1)</th>\n",
       "      <th>var3(t-1)</th>\n",
       "      <th>var4(t-1)</th>\n",
       "      <th>var5(t-1)</th>\n",
       "      <th>var6(t-1)</th>\n",
       "      <th>var7(t-1)</th>\n",
       "      <th>var1(t)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>2.580</td>\n",
       "      <td>0.136</td>\n",
       "      <td>241.97</td>\n",
       "      <td>10.6</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.552</td>\n",
       "      <td>0.1</td>\n",
       "      <td>241.75</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.650</td>\n",
       "      <td>0.218</td>\n",
       "      <td>241.67</td>\n",
       "      <td>11.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.682</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>2.552</td>\n",
       "      <td>0.100</td>\n",
       "      <td>241.75</td>\n",
       "      <td>10.4</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.550</td>\n",
       "      <td>0.1</td>\n",
       "      <td>241.64</td>\n",
       "      <td>...</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.682</td>\n",
       "      <td>0.258</td>\n",
       "      <td>242.45</td>\n",
       "      <td>11.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.660</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>2.550</td>\n",
       "      <td>0.100</td>\n",
       "      <td>241.64</td>\n",
       "      <td>10.4</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.550</td>\n",
       "      <td>0.1</td>\n",
       "      <td>241.71</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.660</td>\n",
       "      <td>0.252</td>\n",
       "      <td>241.60</td>\n",
       "      <td>11.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.650</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>2.550</td>\n",
       "      <td>0.100</td>\n",
       "      <td>241.71</td>\n",
       "      <td>10.4</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.554</td>\n",
       "      <td>0.1</td>\n",
       "      <td>241.98</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.650</td>\n",
       "      <td>0.250</td>\n",
       "      <td>241.14</td>\n",
       "      <td>11.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.654</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>2.554</td>\n",
       "      <td>0.100</td>\n",
       "      <td>241.98</td>\n",
       "      <td>10.4</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.550</td>\n",
       "      <td>0.1</td>\n",
       "      <td>241.83</td>\n",
       "      <td>...</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.654</td>\n",
       "      <td>0.250</td>\n",
       "      <td>241.38</td>\n",
       "      <td>11.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.642</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 169 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    var1(t-24)  var2(t-24)  var3(t-24)  var4(t-24)  var5(t-24)  var6(t-24)  \\\n",
       "24       2.580       0.136      241.97        10.6         0.0         0.0   \n",
       "25       2.552       0.100      241.75        10.4         0.0         0.0   \n",
       "26       2.550       0.100      241.64        10.4         0.0         0.0   \n",
       "27       2.550       0.100      241.71        10.4         0.0         0.0   \n",
       "28       2.554       0.100      241.98        10.4         0.0         0.0   \n",
       "\n",
       "    var7(t-24)  var1(t-23)  var2(t-23)  var3(t-23)  ...  var6(t-2)  var7(t-2)  \\\n",
       "24         0.0       2.552         0.1      241.75  ...        1.0        0.0   \n",
       "25         0.0       2.550         0.1      241.64  ...        2.0        0.0   \n",
       "26         0.0       2.550         0.1      241.71  ...        1.0        0.0   \n",
       "27         0.0       2.554         0.1      241.98  ...        1.0        0.0   \n",
       "28         0.0       2.550         0.1      241.83  ...        2.0        0.0   \n",
       "\n",
       "    var1(t-1)  var2(t-1)  var3(t-1)  var4(t-1)  var5(t-1)  var6(t-1)  \\\n",
       "24      2.650      0.218     241.67       11.0        0.0        2.0   \n",
       "25      2.682      0.258     242.45       11.0        0.0        1.0   \n",
       "26      2.660      0.252     241.60       11.0        0.0        1.0   \n",
       "27      2.650      0.250     241.14       11.0        0.0        2.0   \n",
       "28      2.654      0.250     241.38       11.0        0.0        1.0   \n",
       "\n",
       "    var7(t-1)  var1(t)  \n",
       "24        0.0    2.682  \n",
       "25        0.0    2.660  \n",
       "26        0.0    2.650  \n",
       "27        0.0    2.654  \n",
       "28        0.0    2.642  \n",
       "\n",
       "[5 rows x 169 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# series data to img function\n",
    "def series_to_img(dataset, time_step=1):\n",
    "    num = dataset.shape[1]      # features num\n",
    "    df = pd.DataFrame(dataset)\n",
    "    cols, names = list(), list()\n",
    "    # sequence t-n to t-1\n",
    "    for i in range(time_step, 0, -1):\n",
    "        cols.append(df.shift(i))\n",
    "        names += [('var%d(t-%d)' % (j+1, i)) for j in range(num)]\n",
    "\n",
    "    for i in range(0, 1):\n",
    "        cols.append(df.shift(-i))\n",
    "        if i == 0:\n",
    "            names += [('var%d(t)' % (j+1)) for j in range(num)]\n",
    "        else:\n",
    "            names += [('var%d(t+%d)' % (j+1, i)) for j in range(num)]\n",
    "\n",
    "    agg = pd.concat(cols, axis=1)\n",
    "    agg.columns = names\n",
    "    agg.dropna(inplace=True)\n",
    "    return agg\n",
    "\n",
    "from sklearn.model_selection import TimeSeriesSplit\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "df.ffill(axis=1, inplace=True)\n",
    "dataset = df.values\n",
    "dataset = dataset.astype('float')\n",
    "\n",
    "n_inputs = 24\n",
    "n_features = 7\n",
    "del_idx = n_inputs * n_features + 1\n",
    "del_cols = [i for i in range(del_idx, del_idx+n_features-1)]\n",
    "new_df = series_to_img(dataset, n_inputs)\n",
    "new_df.drop(new_df.columns[del_cols], axis=1, inplace=True)\n",
    "new_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7d146147-c5fb-42c5-a4b3-d1257fd2cf6b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "config : epochs, batch_size, learning_rate\n",
      "fold : 1/10\n",
      " == train [30, 64, 0.01] model ==  "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\lab\\anaconda3\\envs\\pytorch\\lib\\site-packages\\torch\\nn\\functional.py:718: UserWarning: Named tensors and all their associated APIs are an experimental feature and subject to change. Please do not use them for anything important until they are released as stable. (Triggered internally at  ..\\c10/core/TensorImpl.h:1156.)\n",
      "  return torch.max_pool2d(input, kernel_size, stride, padding, dilation, ceil_mode)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "error(rmse):1.56186\n",
      " == train [30, 64, 0.001] model ==  error(rmse):1.77024\n",
      "train-size:1314, val-size:328, test-size:831\n",
      "best_model => error(rmse) : 0.91392, param:[30, 64, 0.01], times: 30.182\n",
      "\n",
      "fold : 2/10\n",
      " == train [30, 64, 0.01] model ==  error(rmse):0.71313\n",
      " == train [30, 64, 0.001] model ==  error(rmse):0.93593\n",
      "train-size:1979, val-size:494, test-size:831\n",
      "best_model => error(rmse) : 0.55705, param:[30, 64, 0.01], times: 45.607\n",
      "\n",
      "fold : 3/10\n",
      " == train [30, 64, 0.01] model ==  error(rmse):0.96701\n",
      " == train [30, 64, 0.001] model ==  error(rmse):0.71920\n",
      "train-size:2644, val-size:660, test-size:831\n",
      "best_model => error(rmse) : 0.76079, param:[30, 64, 0.001], times: 61.259\n",
      "\n",
      "fold : 4/10\n",
      " == train [30, 64, 0.01] model ==  error(rmse):0.71179\n",
      " == train [30, 64, 0.001] model ==  error(rmse):0.81302\n",
      "train-size:3308, val-size:827, test-size:831\n",
      "best_model => error(rmse) : 1.45380, param:[30, 64, 0.01], times: 76.961\n",
      "\n",
      "fold : 5/10\n",
      " == train [30, 64, 0.01] model ==  error(rmse):0.95551\n",
      " == train [30, 64, 0.001] model ==  error(rmse):0.89850\n",
      "train-size:3973, val-size:993, test-size:831\n",
      "best_model => error(rmse) : 1.03995, param:[30, 64, 0.001], times: 92.419\n",
      "\n",
      "fold : 6/10\n",
      " == train [30, 64, 0.01] model ==  error(rmse):0.88113\n",
      " == train [30, 64, 0.001] model ==  error(rmse):0.91068\n",
      "train-size:4638, val-size:1159, test-size:831\n",
      "best_model => error(rmse) : 0.41202, param:[30, 64, 0.01], times: 108.266\n",
      "\n",
      "fold : 7/10\n",
      " == train [30, 64, 0.01] model ==  error(rmse):0.37308\n",
      " == train [30, 64, 0.001] model ==  error(rmse):0.38160\n",
      "train-size:5303, val-size:1325, test-size:831\n",
      "best_model => error(rmse) : 0.36245, param:[30, 64, 0.01], times: 124.138\n",
      "\n",
      "fold : 8/10\n",
      " == train [30, 64, 0.01] model ==  error(rmse):0.29585\n",
      " == train [30, 64, 0.001] model ==  error(rmse):0.39558\n",
      "train-size:5968, val-size:1491, test-size:831\n",
      "best_model => error(rmse) : 0.59299, param:[30, 64, 0.01], times: 139.302\n",
      "\n",
      "fold : 9/10\n",
      " == train [30, 64, 0.01] model ==  error(rmse):0.40203\n",
      " == train [30, 64, 0.001] model ==  error(rmse):0.48055\n",
      "train-size:6632, val-size:1658, test-size:831\n",
      "best_model => error(rmse) : 1.03475, param:[30, 64, 0.01], times: 155.079\n",
      "\n",
      "fold : 10/10\n",
      " == train [30, 64, 0.01] model ==  error(rmse):0.64138\n",
      " == train [30, 64, 0.001] model ==  error(rmse):0.72258\n",
      "train-size:7297, val-size:1824, test-size:831\n",
      "best_model => error(rmse) : 1.35293, param:[30, 64, 0.01], times: 170.699\n",
      "\n"
     ]
    }
   ],
   "source": [
    "n_splits = 10\n",
    "train_test_split = TimeSeriesSplit(n_splits=n_splits+1, gap=n_inputs).split(new_df)\n",
    "next(train_test_split)\n",
    "\n",
    "configs = model_config()\n",
    "history = []\n",
    "\n",
    "best_rmse, best_mse, best_mae = [], [], []\n",
    "learning_time = []\n",
    "\n",
    "i = 1\n",
    "\n",
    "print('config : epochs, batch_size, learning_rate')\n",
    "\n",
    "# nested cross validation for time series model\n",
    "for train_cv_indices, test_cv_indices in train_test_split:\n",
    "    print(f'fold : {i}/{n_splits}')\n",
    "    i+=1\n",
    "\n",
    "    # split x, y data\n",
    "    train_cv_X, train_cv_y = new_df.iloc[train_cv_indices, :-1].values, new_df.iloc[train_cv_indices,-1].values\n",
    "    test_cv_X, test_cv_y = new_df.iloc[test_cv_indices, :-1].values, new_df.iloc[test_cv_indices, -1].values\n",
    "\n",
    "    # length for validation set\n",
    "    test_length = int(len(train_cv_X)*0.2)\n",
    "\n",
    "    # scaling data\n",
    "    scaler_x = MinMaxScaler()\n",
    "    train_cv_X = scaler_x.fit_transform(train_cv_X)\n",
    "    test_cv_X = scaler_x.transform(test_cv_X)\n",
    "\n",
    "    train_X, val_X = train_cv_X[:-test_length, :], train_cv_X[-test_length:, :]\n",
    "    train_y, val_y = train_cv_y[:-test_length], train_cv_y[-test_length:]\n",
    "\n",
    "    # reshape\n",
    "    # inner loop\n",
    "    train_X = train_X.reshape(-1, 1, n_inputs, n_features)\n",
    "    val_X = val_X.reshape(-1, 1, n_inputs, n_features)\n",
    "    train_y = train_y.reshape(-1, 1)\n",
    "    val_y = val_y.reshape(-1, 1)\n",
    "\n",
    "    # outer loop\n",
    "    train_cv_X = train_cv_X.reshape(-1, 1, n_inputs, n_features)\n",
    "    test_cv_X = test_cv_X.reshape(-1, 1, n_inputs, n_features)\n",
    "    train_cv_y = train_cv_y.reshape(-1, 1)\n",
    "    test_cv_y = test_cv_y.reshape(-1, 1)\n",
    "\n",
    "    train_X = np_to_tensor(train_X)\n",
    "    train_y = np_to_tensor(train_y)\n",
    "    val_X = np_to_tensor(val_X)\n",
    "\n",
    "    train_cv_X = np_to_tensor(train_cv_X)\n",
    "    train_cv_y = np_to_tensor(train_cv_y)\n",
    "    test_cv_X = np_to_tensor(test_cv_X)\n",
    "\n",
    "    # model fit, inner\n",
    "    errors = []\n",
    "    for idx, cfg in enumerate(configs):\n",
    "        print(f' == train {cfg} model == ', end=' ')\n",
    "        model = model_fit(train_X, train_y, cfg)\n",
    "        output = model(val_X)\n",
    "        # for prevent cuda memory out\n",
    "        predicted = output.data.cpu().numpy()\n",
    "        error = MSE_metric(predicted, val_y)   # mse\n",
    "        print(f'error(rmse):{np.sqrt(error):.5f}')\n",
    "        if errors:\n",
    "            if error < min(errors):\n",
    "                param = idx\n",
    "        else:\n",
    "            param = idx\n",
    "        errors.append(error)\n",
    "    history.append(errors)\n",
    "\n",
    "    # outer\n",
    "    start_time = time.time()\n",
    "    # model fitting\n",
    "    selected_model = model_fit(train_cv_X,train_cv_y, configs[param])\n",
    "    # check time\n",
    "    duration = time.time() - start_time\n",
    "    output = selected_model(test_cv_X)\n",
    "    predicted = output.data.cpu().numpy()\n",
    "    \n",
    "    rmse = np.sqrt(MSE_metric(predicted, test_cv_y))\n",
    "    mse = MSE_metric(predicted, test_cv_y)\n",
    "    mae = MAE_metric(predicted, test_cv_y)\n",
    "    best_rmse.append(rmse)\n",
    "    best_mse.append(mse)\n",
    "    best_mae.append(mae)\n",
    "    learning_time.append(duration)\n",
    "\n",
    "    # model eval\n",
    "    print(f'train-size:{train_X.size(0)}, val-size:{val_X.size(0)}, test-size:{test_cv_X.size(0)}')\n",
    "    print(f'best_model => error(rmse) : {rmse:.5f}, param:{configs[param]}, times: {duration:.3f}')\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "84f684ea-3bdf-4ba5-9cbc-ef09c8ed2561",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE: mean=0.8473271799378759, std=0.6521144857327332\n",
      "RMSE: mean=0.8480642838949809, std=0.3579303707700272\n",
      "MAE: mean=0.6230885976372069, std=0.29470856035211435\n",
      "\n",
      "[training time]\n",
      "mean : 100.39110293388367, last:170.69850063323975\n"
     ]
    }
   ],
   "source": [
    "def model_evaluation(mse, rmse, mae):\n",
    "    mse = np.array(mse)\n",
    "    rmse = np.array(rmse)\n",
    "    mae = np.array(mae)\n",
    "    print(f'MSE: mean={np.mean(mse)}, std={np.std(mse)}')\n",
    "    print(f'RMSE: mean={np.mean(rmse)}, std={np.std(rmse)}')\n",
    "    print(f'MAE: mean={np.mean(mae)}, std={np.std(mae)}')\n",
    "\n",
    "model_evaluation(best_mse, best_rmse, best_mae)\n",
    "\n",
    "# check time\n",
    "print()\n",
    "print('[training time]')\n",
    "print(f'mean : {np.mean(np.array(learning_time))}, last:{learning_time[-1]}')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch",
   "language": "python",
   "name": "pytorch"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
