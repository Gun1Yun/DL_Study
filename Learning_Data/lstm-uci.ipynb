{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"lstm-uci.ipynb","provenance":[],"collapsed_sections":[],"authorship_tag":"ABX9TyOlNfe0TpOAkxxVLGmsmnGO"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU"},"cells":[{"cell_type":"markdown","metadata":{"id":"mvrJHYUF8PFK"},"source":["## For 'import ipynb files' - *Todo (convert .ipynb to .py)*\n","1. install import_ipynb, PyDrive\n","2. import ipynb files"]},{"cell_type":"code","metadata":{"id":"Wjy6Sy6iz6yB","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1621881912749,"user_tz":-540,"elapsed":6284,"user":{"displayName":"윤건일","photoUrl":"","userId":"05157393038207945770"}},"outputId":"ce1736c0-d448-483f-b611-3d189c51fd16"},"source":["!pip install -U -q PyDrive\n","!pip install import_ipynb\n","import import_ipynb\n","from pydrive.auth import GoogleAuth\n","from pydrive.drive import GoogleDrive\n","from google.colab import auth\n","from oauth2client.client import GoogleCredentials\n","\n","# Authenticate and create the PyDrive client.\n","# This only needs to be done once per notebook.\n","auth.authenticate_user()\n","gauth = GoogleAuth()\n","gauth.credentials = GoogleCredentials.get_application_default()\n","drive = GoogleDrive(gauth)\n","\n","# id for import files\n","'''\n","layers.ipynb : 1TE_v-Os9bcDepAWODmnDi5WuAz2tyfYn\n","optim.ipynb : 1kCLfroPeioTdHqogFoOkTVyFYsYe9RAh\n","'''\n","# test import\n","module = drive.CreateFile({'id':'1b1teolDFHMLhucgVFL_-2wjOyFoFzGmJ'})\n","module.GetContentFile('test_function.ipynb')\n","from test_function import print_test\n","print_test()\n","\n","# import require module\n","module = drive.CreateFile({'id':'1TE_v-Os9bcDepAWODmnDi5WuAz2tyfYn'})\n","module.GetContentFile('layers.ipynb')\n","module = drive.CreateFile({'id':'1kCLfroPeioTdHqogFoOkTVyFYsYe9RAh'})\n","module.GetContentFile('optim.ipynb')"],"execution_count":22,"outputs":[{"output_type":"stream","text":["Requirement already satisfied: import_ipynb in /usr/local/lib/python3.7/dist-packages (0.1.3)\n","test\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"SoYihFUO8sSa"},"source":["### GPU config\n","- **True** : use cupy\n","- **False** : use numpy"]},{"cell_type":"code","metadata":{"id":"u6gKRtRGB0bS","executionInfo":{"status":"ok","timestamp":1621881912765,"user_tz":-540,"elapsed":35,"user":{"displayName":"윤건일","photoUrl":"","userId":"05157393038207945770"}}},"source":["GPU = True\n","\n","if GPU:\n","    import cupy as np\n","    np.cuda.set_allocator(np.cuda.MemoryPool().malloc)\n","else:\n","    import numpy as np"],"execution_count":23,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"4AlvNeJ681y_"},"source":["### import requirements\n","- layer, optim\n","- upgrade version of scikit-learn for use ***TimeSeriesSplit()*** -gap parameter"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"yw9I-PcLB9OC","executionInfo":{"status":"ok","timestamp":1621881914946,"user_tz":-540,"elapsed":2214,"user":{"displayName":"윤건일","photoUrl":"","userId":"05157393038207945770"}},"outputId":"c287e647-9f40-4737-b5e8-fbc3e7aff494"},"source":["from layers import LSTM, TimeLSTM, FullyConnected\n","from optim import Adam\n","\n","# for time series split\n","!pip install scikit-learn==0.24.2"],"execution_count":24,"outputs":[{"output_type":"stream","text":["Requirement already satisfied: scikit-learn==0.24.2 in /usr/local/lib/python3.7/dist-packages (0.24.2)\n","Requirement already satisfied: scipy>=0.19.1 in /usr/local/lib/python3.7/dist-packages (from scikit-learn==0.24.2) (1.4.1)\n","Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from scikit-learn==0.24.2) (2.1.0)\n","Requirement already satisfied: numpy>=1.13.3 in /usr/local/lib/python3.7/dist-packages (from scikit-learn==0.24.2) (1.19.5)\n","Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.7/dist-packages (from scikit-learn==0.24.2) (1.0.1)\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"YPobU9tR9ttu"},"source":["### Define Custom Layer for data"]},{"cell_type":"code","metadata":{"id":"5Ux_k2aLCSSu","executionInfo":{"status":"ok","timestamp":1621881914950,"user_tz":-540,"elapsed":19,"user":{"displayName":"윤건일","photoUrl":"","userId":"05157393038207945770"}}},"source":["def sigmoid(x):\n","    return 1 / (1 + np.exp(-x))\n","\n","def MSE(y, t):\n","    return 0.5*np.mean((y-t)**2)\n","\n","class ReLU:\n","    def __init__(self):\n","        self.mask = None\n","\n","    def forward(self, x):\n","        self.mask = (x<=0)\n","        y = x.copy()\n","        y[self.mask] = 0\n","\n","        return y\n","    \n","    def backward(self, dy):\n","        dy[self.mask] = 0\n","        dx = dy\n","\n","        return dx\n","\n","\n","class TimeFC:\n","    def __init__(self, W, b):\n","        self.params = [W, b]\n","        self.grads = [np.zeros_like(W), np.zeros_like(b)]\n","        self.x = None\n","\n","    def forward(self, x):\n","        W, b = self.params\n","        N, D = x.shape\n","\n","        reshaped_x = x.reshape(N, -1)\n","        y = np.dot(reshaped_x, W) + b\n","        \n","        self.x = x\n","        y = y.reshape(N, -1)\n","        return y\n","\n","    def backward(self, dy):\n","        W, b = self.params\n","        x = self.x\n","        N, D = x.shape\n","\n","        dy = dy.reshape(N, -1)\n","        reshaped_x = x.reshape(N, -1)\n","\n","        db = np.sum(dy, axis=0)\n","        dx = np.matmul(dy, W.T)\n","        dW = np.matmul(reshaped_x.T, dy)\n","        \n","        dx = dx.reshape(*x.shape)\n","\n","        self.grads[0][...] = dW\n","        self.grads[1][...] = db\n","\n","        return dx\n","\n","class TimeMSE:\n","    def __init__(self):\n","        self.params, self.grads = [], []\n","        self.activation = ReLU()\n","        self.cache = None\n","\n","    def forward(self, xs, ts):\n","        N, V = xs.shape\n","        xs = xs.reshape(N, V)\n","        xs = self.activation.forward(xs)\n","        ts = ts.reshape(N, V)\n","\n","        loss = MSE(xs, ts)\n","        self.cache = (ts, xs, (N, V))\n","\n","        return loss\n","\n","    def backward(self, dy = 1):\n","\n","        ts, xs, (N,  V) = self.cache\n","        \n","        dx = dy * (xs - ts) / (N)\n","\n","        dx = self.activation.backward(dx)\n","        dx = dx.reshape(N , V)\n","        return dx"],"execution_count":25,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"S66S3tYs960N"},"source":["### Model Architecture for Time Series Data\n","- use **LSTM** Layer\n","- LSTM(100) - FC(100) - FC(64)\n","- Add ***fit()*** Method for validation"]},{"cell_type":"code","metadata":{"id":"FLrI4BBFC2JV","executionInfo":{"status":"ok","timestamp":1621881914953,"user_tz":-540,"elapsed":20,"user":{"displayName":"윤건일","photoUrl":"","userId":"05157393038207945770"}}},"source":["class LstmModelReg:\n","    def __init__(self, time_size, hidden_size, feature_size):\n","        T, H, F = time_size, hidden_size, feature_size\n","        H2 = 64\n","        rand = np.random.randn\n","\n","        # weights (Xavier)\n","        lstm_Wx = (rand(F, 4*H)/ np.sqrt(F)).astype('f')\n","        lstm_Wh = (rand(H, 4*H)/ np.sqrt(H)).astype('f')\n","        lstm_b = np.zeros(4*H).astype('f')\n","\n","        # He initialize\n","        fc_W1 = (rand(H, H2)/ np.sqrt(H/2)).astype('f')\n","        fc_b1 = np.zeros(H2).astype('f')\n","\n","        fc_W2 = (rand(H2, 1)/ np.sqrt(H2/2)).astype('f')\n","        fc_b2 = np.zeros(1).astype('f')\n","\n","        # layer\n","        self.layers = [\n","            TimeLSTM(lstm_Wx, lstm_Wh, lstm_b, stateful=True),\n","            TimeFC(fc_W1, fc_b1),\n","            TimeFC(fc_W2, fc_b2)\n","        ]\n","        self.loss_layer = TimeMSE()\n","\n","        self.params, self.grads = [], []\n","\n","        for layer in self.layers:\n","            self.params += layer.params\n","            self.grads += layer.grads\n","\n","\n","    def predict(self, xs):\n","        xs = np.array(xs)\n","        for layer in self.layers:\n","            xs = layer.forward(xs)\n","        return xs\n","\n","    def forward(self, xs, ts):\n","        xs = np.array(xs)\n","        ts = np.array(ts)\n","        for layer in self.layers:\n","            xs = layer.forward(xs)\n","        loss = self.loss_layer.forward(xs, ts)\n","        return loss\n","\n","    def backward(self, dy = 1):\n","        dy = self.loss_layer.backward(dy)\n","        for layer in reversed(self.layers):\n","            dy = layer.backward(dy)\n","        return dy\n","\n","    def fit(self, train_X=None, train_y=None,learning_rate=0.01, epochs=10, batch_size=32, verbose=0):\n","        optimizer = Adam(learning_rate)\n","\n","        data_size = train_X.shape[0]\n","        max_iters = data_size//batch_size\n","\n","        for epoch in range(1, epochs+1):\n","            idx = numpy.random.permutation(numpy.arange(data_size))\n","            train_X = train_X[idx]\n","            train_y = train_y[idx]\n","\n","            epoch_loss = 0\n","            start_time=time.time()\n","            \n","            for iter in range(max_iters):\n","                batch_x = train_X[iter*batch_size:(iter+1)*batch_size]\n","                batch_y = train_y[iter*batch_size:(iter+1)*batch_size]\n","\n","                loss = self.forward(batch_x, batch_y)\n","                self.backward()\n","                params, grads = self.params, self.grads\n","                optimizer.update(params, grads)\n","\n","                epoch_loss += loss\n","            avg_loss = epoch_loss/max_iters\n","\n","            if verbose:\n","                duration = start_time-time.time()\n","                print(f'epoch:{epoch}/{epochs}, 시간:{duration:.2f}[s], loss:{avg_loss:.5f}')\n","\n","\n","    def reset_state(self):\n","        self.layers[0].reset_state()"],"execution_count":26,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"XhCXX7-h-VIL"},"source":["### Functions for Data Preprocessing and Cross Validation"]},{"cell_type":"code","metadata":{"id":"e6Dk92kqFN_O","executionInfo":{"status":"ok","timestamp":1621881914955,"user_tz":-540,"elapsed":20,"user":{"displayName":"윤건일","photoUrl":"","userId":"05157393038207945770"}}},"source":["# series data to sequence function\n","def series_to_sequence(dataset, time_step=1):\n","    num = dataset.shape[1]      # features num\n","    df = pd.DataFrame(dataset)\n","    cols, names = list(), list()\n","    # sequence t-n to t-1\n","    for i in range(time_step, 0, -1):\n","        cols.append(df.shift(i))\n","        names += [('var%d(t-%d)' % (j+1, i)) for j in range(num)]\n","\n","    for i in range(0, 1):\n","        cols.append(df.shift(-i))\n","        if i == 0:\n","            names += [('var%d(t)' % (j+1)) for j in range(num)]\n","        else:\n","            names += [('var%d(t+%d)' % (j+1, i)) for j in range(num)]\n","\n","    agg = pd.concat(cols, axis=1)\n","    agg.columns = names\n","    agg.dropna(inplace=True)\n","    return agg\n","\n","# configuration setting\n","def model_config():\n","    # parameter for LSTM Model\n","    epochs = [10]\n","    batch_size = [64]\n","    learning_rate = [0.1, 0.01, 0.001]\n","    \n","    # create config data\n","    configs = []\n","    for i in epochs:\n","        for j in batch_size:\n","            for k in learning_rate:\n","                config = [i, j, k]\n","                configs.append(config)\n","    return configs\n","\n","# fucntion for fit cnn model using configs\n","def model_fit(train_X, train_y, config):\n","    # unpack config\n","    n_epochs, n_batch, learning_rate = config\n","    model = LstmModelReg(time_size=24, hidden_size=100, feature_size=8)\n","    # fit model and return\n","    model.fit(train_X=train_X, train_y=train_y, epochs=n_epochs, \n","              batch_size=n_batch, learning_rate=learning_rate)\n","    return model\n","\n","def MAE_metric(x, t):\n","    return np.mean(np.abs(x-t))\n","\n","def MSE_metric(x, t):\n","    return np.mean((x-t)**2)"],"execution_count":27,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"P-LxiZku-p53"},"source":["### Nested Cross Validation for Time Series Data\n","- Data : Beijing Air Pollution"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"UKWvsvhYFvJn","executionInfo":{"status":"ok","timestamp":1621883368549,"user_tz":-540,"elapsed":1071817,"user":{"displayName":"윤건일","photoUrl":"","userId":"05157393038207945770"}},"outputId":"10fb9681-9a25-4236-9782-4240a99a525f"},"source":["# dataset\n","import pandas as pd\n","import numpy\n","import time\n","from datetime import datetime\n","\n","df_parser = lambda x: datetime.strptime(x, '%Y %m %d %H')    # string to datetime\n","# data_url = 'https://archive.ics.uci.edu/ml/machine-learning-databases/00381/PRSA_data_2010.1.1-2014.12.31.csv'\n","data_url = 'https://raw.githubusercontent.com/jbrownlee/Datasets/master/pollution.csv'\n","df = pd.read_csv(data_url, sep=',', parse_dates=[['year', 'month', 'day', 'hour']], date_parser=df_parser, index_col=0)\n","\n","del df['No']\n","df.columns = ['pm2.5', 'dewp', 'temp', 'pres', 'cbwd','wind_speed', 'snow', 'rain']\n","df = df[24:]            # NaN values in first 24hours\n","\n","# sklearn library for time series split\n","from sklearn.model_selection import TimeSeriesSplit\n","from sklearn.preprocessing import LabelEncoder, MinMaxScaler\n","from sklearn.metrics import mean_squared_error\n","\n","dataset = df.values\n","label_encoder = LabelEncoder()\n","dataset[:, 4] = label_encoder.fit_transform(dataset[:, 4])  # for wind direction\n","dataset = dataset.astype('float')\n","\n","n_inputs = 24       # input time dim\n","n_features = 8      # input feature dim\n","del_idx = n_inputs * n_features + 1\n","del_cols = [i for i in range(del_idx, del_idx+n_features-1)]\n","new_df = series_to_img(dataset, n_inputs)       # time series to img data\n","new_df.drop(new_df.columns[del_cols], axis=1, inplace=True)\n","new_df.reset_index(drop=True, inplace=True)\n","\n","n_splits = 3\n","train_test_split = TimeSeriesSplit(n_splits=n_splits+1, gap=n_inputs).split(new_df)\n","next(train_test_split)\n","\n","configs = model_config()\n","history = []\n","i = 1\n","\n","print('config : epochs, batch_size, learning_rate')\n","\n","# nested cross validation for time series model\n","for train_cv_indices, test_cv_indices in train_test_split:\n","    print(f'fold : {i}/{n_splits}')\n","    i+=1\n","\n","    # split x, y data\n","    train_cv_X, train_cv_y = new_df.iloc[train_cv_indices, :-1].values, new_df.iloc[train_cv_indices,-1].values\n","    test_cv_X, test_cv_y = new_df.iloc[test_cv_indices, :-1].values, new_df.iloc[test_cv_indices, -1].values\n","\n","    # length for validation set\n","    test_length = len(test_cv_X)\n","\n","    # scaling data\n","    scaler_x = MinMaxScaler()\n","    train_cv_X = scaler_x.fit_transform(train_cv_X)\n","    test_cv_X = scaler_x.transform(test_cv_X)\n","\n","    train_X, val_X = train_cv_X[:-test_length, :], train_cv_X[-test_length:, :]\n","    train_y, val_y = train_cv_y[:-test_length], train_cv_y[-test_length:]\n","\n","    # reshape\n","    # inner loop\n","    train_X = train_X.reshape(-1, n_inputs, n_features)\n","    val_X = val_X.reshape(-1, n_inputs, n_features)\n","    train_y = train_y.reshape(-1, 1)\n","    val_y = val_y.reshape(-1, 1)\n","\n","    # outter loop\n","    train_cv_X = train_cv_X.reshape(-1, n_inputs, n_features)\n","    test_cv_X = test_cv_X.reshape(-1, n_inputs, n_features)\n","    train_cv_y = train_cv_y.reshape(-1, 1)\n","    test_cv_y = test_cv_y.reshape(-1, 1)\n","\n","    # model fit\n","    errors = []\n","    for idx, cfg in enumerate(configs):\n","        print(f' == train {cfg} model == ', end=' ')\n","        model = model_fit(train_X, train_y, cfg)\n","        model.reset_state()\n","        predicted = model.predict(val_X)\n","        if GPU:\n","            predicted = np.asnumpy(predicted)\n","        error = np.sqrt(MSE_metric(predicted, val_y))   # rmse\n","        print(f' error(RMSE):{error}')\n","        if errors:\n","            if error < min(errors):\n","                param = idx\n","        else:\n","            param = idx\n","        errors.append(error)\n","\n","    history.append(errors)\n","\n","    selected_model = model_fit(train_cv_X,train_cv_y, configs[param])\n","    selected_model.reset_state()\n","    predicted = selected_model.predict(test_cv_X)\n","    if GPU:\n","        predicted = np.asnumpy(predicted)\n","    error = np.sqrt(MSE_metric(predicted, test_cv_y))\n","\n","    # model eval\n","    print(f'best_model => error(rmse) : {error}, param:{param}')"],"execution_count":31,"outputs":[{"output_type":"stream","text":["config : epochs, batch_size, learning_rate\n","fold : 1/3\n"," == train [10, 64, 0.1] model ==   error(RMSE):99.0890638027906\n"," == train [10, 64, 0.01] model ==   error(RMSE):32.98655118835107\n"," == train [10, 64, 0.001] model ==   error(RMSE):35.29681060201724\n","best_model => error(rmse) : 23.323251892834353, param:1\n","fold : 2/3\n"," == train [10, 64, 0.1] model ==   error(RMSE):127.81696520407286\n"," == train [10, 64, 0.01] model ==   error(RMSE):38.541398905362605\n"," == train [10, 64, 0.001] model ==   error(RMSE):22.743030160214285\n","best_model => error(rmse) : 22.56849850186303, param:2\n","fold : 3/3\n"," == train [10, 64, 0.1] model ==   error(RMSE):87.76604012206721\n"," == train [10, 64, 0.01] model ==   error(RMSE):23.088664983422596\n"," == train [10, 64, 0.001] model ==   error(RMSE):22.514452675433873\n","best_model => error(rmse) : 21.473849720065555, param:2\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"pbhZs_u8Y6a9","executionInfo":{"status":"ok","timestamp":1621894968712,"user_tz":-540,"elapsed":307,"user":{"displayName":"윤건일","photoUrl":"","userId":"05157393038207945770"}},"outputId":"2b613cde-30df-43a6-8dd1-ef3f36b761b1"},"source":["model_evaluation = 23.32+22.56+21.47\n","model_evaluation /= 3\n","print(f'evaluation [Mean RMSE] : {model_evaluation}')"],"execution_count":2,"outputs":[{"output_type":"stream","text":["evaluation [Mean RMSE] : 22.45\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"yiR_kpK1-3kH","executionInfo":{"status":"ok","timestamp":1621887165740,"user_tz":-540,"elapsed":600,"user":{"displayName":"윤건일","photoUrl":"","userId":"05157393038207945770"}},"outputId":"f4046298-0d95-45c9-cf2e-c75862b7cd9a"},"source":["selected_model.reset_state()\n","predicted = selected_model.predict(test_cv_X)\n","if GPU:\n","    predicted = np.asnumpy(predicted)\n","print(f'MSE : {MSE_metric(predicted, test_cv_y)}')\n","print(f'RMSE : {np.sqrt(MSE_metric(predicted, test_cv_y))}')\n","\n","def MAE_metric(x, t):\n","    return np.mean(numpy.abs(x-t))\n","print(f'MAE : {MAE_metric(predicted, test_cv_y)}')"],"execution_count":36,"outputs":[{"output_type":"stream","text":["MSE : 461.1262217999595\n","RMSE : 21.473849720065555\n","MAE : 13.374773331339261\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"Uqlw5rrRARbl"},"source":[""],"execution_count":null,"outputs":[]}]}