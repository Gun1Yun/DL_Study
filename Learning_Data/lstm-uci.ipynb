{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"lstm-uci.ipynb","provenance":[],"authorship_tag":"ABX9TyPYtOvm9+mF4mkLSviBO0Pn"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":235},"id":"z_odbflkxaSo","executionInfo":{"status":"ok","timestamp":1621782581344,"user_tz":-540,"elapsed":1416,"user":{"displayName":"윤건일","photoUrl":"","userId":"05157393038207945770"}},"outputId":"c2c305dc-7dce-4875-98e7-a9844ad6a56b"},"source":["# data prepare\n","import pandas as pd\n","from datetime import datetime\n","\n","df_parser = lambda x: datetime.strptime(x, '%Y %m %d %H')    # string to datetime\n","# data_url = 'https://archive.ics.uci.edu/ml/machine-learning-databases/00381/PRSA_data_2010.1.1-2014.12.31.csv'\n","data_url = 'https://raw.githubusercontent.com/jbrownlee/Datasets/master/pollution.csv'\n","df = pd.read_csv(data_url, sep=',', parse_dates=[['year', 'month', 'day', 'hour']], date_parser=df_parser, index_col=0)\n","\n","del df['No']\n","df.columns = ['pm2.5', 'dewp', 'temp', 'pres', 'cbwd','wind_speed', 'snow', 'rain']\n","df = df[24:]            # NaN values in first 24hours\n","df.head()"],"execution_count":1,"outputs":[{"output_type":"execute_result","data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>pm2.5</th>\n","      <th>dewp</th>\n","      <th>temp</th>\n","      <th>pres</th>\n","      <th>cbwd</th>\n","      <th>wind_speed</th>\n","      <th>snow</th>\n","      <th>rain</th>\n","    </tr>\n","    <tr>\n","      <th>year_month_day_hour</th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>2010-01-02 00:00:00</th>\n","      <td>129.0</td>\n","      <td>-16</td>\n","      <td>-4.0</td>\n","      <td>1020.0</td>\n","      <td>SE</td>\n","      <td>1.79</td>\n","      <td>0</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>2010-01-02 01:00:00</th>\n","      <td>148.0</td>\n","      <td>-15</td>\n","      <td>-4.0</td>\n","      <td>1020.0</td>\n","      <td>SE</td>\n","      <td>2.68</td>\n","      <td>0</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>2010-01-02 02:00:00</th>\n","      <td>159.0</td>\n","      <td>-11</td>\n","      <td>-5.0</td>\n","      <td>1021.0</td>\n","      <td>SE</td>\n","      <td>3.57</td>\n","      <td>0</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>2010-01-02 03:00:00</th>\n","      <td>181.0</td>\n","      <td>-7</td>\n","      <td>-5.0</td>\n","      <td>1022.0</td>\n","      <td>SE</td>\n","      <td>5.36</td>\n","      <td>1</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>2010-01-02 04:00:00</th>\n","      <td>138.0</td>\n","      <td>-7</td>\n","      <td>-5.0</td>\n","      <td>1022.0</td>\n","      <td>SE</td>\n","      <td>6.25</td>\n","      <td>2</td>\n","      <td>0</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["                     pm2.5  dewp  temp    pres cbwd  wind_speed  snow  rain\n","year_month_day_hour                                                        \n","2010-01-02 00:00:00  129.0   -16  -4.0  1020.0   SE        1.79     0     0\n","2010-01-02 01:00:00  148.0   -15  -4.0  1020.0   SE        2.68     0     0\n","2010-01-02 02:00:00  159.0   -11  -5.0  1021.0   SE        3.57     0     0\n","2010-01-02 03:00:00  181.0    -7  -5.0  1022.0   SE        5.36     1     0\n","2010-01-02 04:00:00  138.0    -7  -5.0  1022.0   SE        6.25     2     0"]},"metadata":{"tags":[]},"execution_count":1}]},{"cell_type":"code","metadata":{"id":"F-_nLPdJxjEm"},"source":["def series_to_img(dataset, time_step=1):\n","    num = dataset.shape[1]      # features num\n","    df = pd.DataFrame(dataset)\n","    cols, names = list(), list()\n","    # sequence t-n to t-1\n","    for i in range(time_step, 0, -1):\n","        cols.append(df.shift(i))\n","        names += [('var%d(t-%d)' % (j+1, i)) for j in range(num)]\n","\n","    for i in range(0, 1):\n","        cols.append(df.shift(-i))\n","        if i == 0:\n","            names += [('var%d(t)' % (j+1)) for j in range(num)]\n","        else:\n","            names += [('var%d(t+%d)' % (j+1, i)) for j in range(num)]\n","\n","    agg = pd.concat(cols, axis=1)\n","    agg.columns = names\n","    agg.dropna(inplace=True)\n","    return agg\n","\n","from sklearn.preprocessing import LabelEncoder, MinMaxScaler\n","import numpy\n","\n","dataset = df.values\n","encoder = LabelEncoder()\n","dataset[:, 4] = encoder.fit_transform(dataset[:,4])\n","dataset = dataset.astype('f')\n","\n","last_hours = 24\n","features = 8\n","del_idx = last_hours*features + 1\n","del_cols = [i for i in range(del_idx, del_idx+features-1)]\n","reframed = series_to_img(dataset, last_hours)\n","reframed.drop(reframed.columns[del_cols], axis=1, inplace=True)\n","\n","dataset = reframed.values\n","train_hours = 365 * 24\n","train = dataset[:train_hours, :]\n","test = dataset[train_hours:, :]\n","# split\n","train_X, train_y = train[:, :-1], train[:, -1]\n","test_X, test_y = test[:, :-1], test[:, -1]\n","\n","# scaling\n","scaler_x = MinMaxScaler()\n","scaled_x = scaler_x.fit_transform(train_X)\n","\n","test_X = scaler_x.transform(test_X)\n","\n","# reshape\n","train_X = scaled_x.reshape(scaled_x.shape[0], last_hours, features)\n","test_X = test_X.reshape(test_X.shape[0], last_hours, features)\n","\n","train_X = train_X.reshape(-1, 1, last_hours, features)\n","test_X = test_X.reshape(-1, 1, last_hours, features)\n","\n","print(train_X.shape, train_y.shape, test_X.shape, test_y.shape)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":204},"id":"UyvyfTO6x-C7","executionInfo":{"status":"ok","timestamp":1621782786760,"user_tz":-540,"elapsed":235,"user":{"displayName":"윤건일","photoUrl":"","userId":"05157393038207945770"}},"outputId":"4dd66d5d-f173-4899-e234-55d937a4868a"},"source":["import numpy as np\n","\n","nRows = 365     #days\n","\n","df = pd.DataFrame(np.random.randint(0, 5, size=(nRows, 2)), columns=[\"X\", \"y\"], index = pd.date_range(\"20210101\", periods=nRows))\n","df.head()"],"execution_count":2,"outputs":[{"output_type":"execute_result","data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>X</th>\n","      <th>y</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>2021-01-01</th>\n","      <td>4</td>\n","      <td>3</td>\n","    </tr>\n","    <tr>\n","      <th>2021-01-02</th>\n","      <td>1</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>2021-01-03</th>\n","      <td>4</td>\n","      <td>4</td>\n","    </tr>\n","    <tr>\n","      <th>2021-01-04</th>\n","      <td>4</td>\n","      <td>3</td>\n","    </tr>\n","    <tr>\n","      <th>2021-01-05</th>\n","      <td>1</td>\n","      <td>2</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["            X  y\n","2021-01-01  4  3\n","2021-01-02  1  1\n","2021-01-03  4  4\n","2021-01-04  4  3\n","2021-01-05  1  2"]},"metadata":{"tags":[]},"execution_count":2}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Lyd9CAWZyXBZ","executionInfo":{"status":"ok","timestamp":1621783319896,"user_tz":-540,"elapsed":779,"user":{"displayName":"윤건일","photoUrl":"","userId":"05157393038207945770"}},"outputId":"f7fbdc90-eee7-49ed-b2ab-9067661341db"},"source":["from sklearn.model_selection import TimeSeriesSplit\n","\n","n_splits = 3\n","\n","trainTestSplit = TimeSeriesSplit(n_splits+1).split(df)\n","next(trainTestSplit) #Skip the first fold\n","\n","for trainCvIndices, testIndices in trainTestSplit:\n","    # split Train, Cv, Test\n","    XTrainCv, yTrainCv = df.iloc[trainCvIndices, 0], df.iloc[trainCvIndices, 1]\n","    XTest, yTest = df.iloc[testIndices, 0], df.iloc[testIndices, 1]\n","\n","    test_length = len(XTest)\n","    trainCvSplit = [(list(range(trainCvIndices[0], trainCvIndices[-test_length])),\n","                     list(range(trainCvIndices[-test_length], trainCvIndices[-1]+1)))]\n","\n","    print(f'Training : {XTrainCv.index[0].date()} -- {XTrainCv.index[-test_length-1].date()}\\\n","          , Cv : {XTrainCv.index[-test_length].date()} -- {XTrainCv.index[-1].date()}\\\n","          , Test : {XTest.index[0].date()} -- {XTest.index[-1].date()}')"],"execution_count":6,"outputs":[{"output_type":"stream","text":["Training : 2021-01-01 -- 2021-03-14          , Cv : 2021-03-15 -- 2021-05-26          , Test : 2021-05-27 -- 2021-08-07\n","Training : 2021-01-01 -- 2021-05-26          , Cv : 2021-05-27 -- 2021-08-07          , Test : 2021-08-08 -- 2021-10-19\n","Training : 2021-01-01 -- 2021-08-07          , Cv : 2021-08-08 -- 2021-10-19          , Test : 2021-10-20 -- 2021-12-31\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"Wjy6Sy6iz6yB"},"source":[""],"execution_count":null,"outputs":[]}]}