{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"ISE-LSTM-Regression(SP).ipynb","provenance":[],"mount_file_id":"1RA0ooIOUQGFHyLZoDm-OCVjnj3ZUq9qm","authorship_tag":"ABX9TyMOU1uYYaFv3teHZfMsEe3d"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU"},"cells":[{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"UzH47CqZ_M4h","executionInfo":{"status":"ok","timestamp":1623699737121,"user_tz":-540,"elapsed":396,"user":{"displayName":"윤건일","photoUrl":"","userId":"05157393038207945770"}},"outputId":"7bc42f48-e0d5-43ec-de7c-40cb2df3c890"},"source":["import os\n","import sys\n","\n","MODULE_PATH = '/content/drive/MyDrive/GitHub/DL_Study/Base'\n","\n","sys.path.insert(0, MODULE_PATH)\n","sys.path"],"execution_count":1,"outputs":[{"output_type":"execute_result","data":{"text/plain":["['/content/drive/MyDrive/GitHub/DL_Study/Base',\n"," '',\n"," '/content',\n"," '/env/python',\n"," '/usr/lib/python37.zip',\n"," '/usr/lib/python3.7',\n"," '/usr/lib/python3.7/lib-dynload',\n"," '/usr/local/lib/python3.7/dist-packages',\n"," '/usr/lib/python3/dist-packages',\n"," '/usr/local/lib/python3.7/dist-packages/IPython/extensions',\n"," '/root/.ipython']"]},"metadata":{"tags":[]},"execution_count":1}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"4o83Y4CR_QzN","executionInfo":{"status":"ok","timestamp":1623699740174,"user_tz":-540,"elapsed":3057,"user":{"displayName":"윤건일","photoUrl":"","userId":"05157393038207945770"}},"outputId":"7d851f43-f77a-425d-bb12-320f5630c870"},"source":["# import\n","import numpy\n","from config import *\n","from optim import Adam\n","from models import LstmModelReg\n","\n","# for time series split\n","!pip install scikit-learn==0.24.2"],"execution_count":2,"outputs":[{"output_type":"stream","text":["Requirement already satisfied: scikit-learn==0.24.2 in /usr/local/lib/python3.7/dist-packages (0.24.2)\n","Requirement already satisfied: scipy>=0.19.1 in /usr/local/lib/python3.7/dist-packages (from scikit-learn==0.24.2) (1.4.1)\n","Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.7/dist-packages (from scikit-learn==0.24.2) (1.0.1)\n","Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from scikit-learn==0.24.2) (2.1.0)\n","Requirement already satisfied: numpy>=1.13.3 in /usr/local/lib/python3.7/dist-packages (from scikit-learn==0.24.2) (1.19.5)\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"-2REeC4Y_Rtc","executionInfo":{"status":"ok","timestamp":1623699740175,"user_tz":-540,"elapsed":6,"user":{"displayName":"윤건일","photoUrl":"","userId":"05157393038207945770"}}},"source":["# configuration setting\n","def model_config():\n","    # parameter for LSTM Model\n","    epochs = [30]\n","    batch_size = [32, 64]\n","    learning_rate = [0.01, 0.001]\n","    \n","    # create config data\n","    configs = []\n","    for i in epochs:\n","        for j in batch_size:\n","            for k in learning_rate:\n","                config = [i, j, k]\n","                configs.append(config)\n","    return configs\n","\n","# fucntion for fit cnn model using configs\n","def model_fit(train_X, train_y, config):\n","    # unpack config\n","    n_epochs, n_batch, learning_rate = config\n","    model = LstmModelReg(time_size=24, hidden_size=100, feature_size=9)\n","    # fit model and return\n","    model.fit(train_X=train_X, train_y=train_y, epochs=n_epochs, \n","              batch_size=n_batch, learning_rate=learning_rate)\n","    return model\n","\n","def MAE_metric(x, t):\n","    return np.mean(np.abs(x-t))\n","\n","def MSE_metric(x, t):\n","    return np.mean((x-t)**2)"],"execution_count":3,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":204},"id":"Hq113BJ3_X0U","executionInfo":{"status":"ok","timestamp":1623699741202,"user_tz":-540,"elapsed":1031,"user":{"displayName":"윤건일","photoUrl":"","userId":"05157393038207945770"}},"outputId":"ab6b5ddc-d472-4178-a2a6-d2ba014f3997"},"source":["import pandas as pd\n","import numpy\n","import time\n","from datetime import datetime\n","\n","np.random.seed(42)\n","numpy.random.seed(42)\n","\n","data_url = 'https://archive.ics.uci.edu/ml/machine-learning-databases/00247/'\n","data_name = 'data_akbilgic.xlsx'\n","df = pd.read_excel(data_url+data_name, header=1)\n","df.drop(columns=df.columns[[0]], axis=1, inplace=True)\n","cols = df.columns.tolist()\n","cols = cols[2:]+cols[:2]\n","df = df[cols]\n","df.head()"],"execution_count":4,"outputs":[{"output_type":"execute_result","data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>SP</th>\n","      <th>DAX</th>\n","      <th>FTSE</th>\n","      <th>NIKKEI</th>\n","      <th>BOVESPA</th>\n","      <th>EU</th>\n","      <th>EM</th>\n","      <th>ISE</th>\n","      <th>ISE.1</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>-0.004679</td>\n","      <td>0.002193</td>\n","      <td>0.003894</td>\n","      <td>0.000000</td>\n","      <td>0.031190</td>\n","      <td>0.012698</td>\n","      <td>0.028524</td>\n","      <td>0.035754</td>\n","      <td>0.038376</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>0.007787</td>\n","      <td>0.008455</td>\n","      <td>0.012866</td>\n","      <td>0.004162</td>\n","      <td>0.018920</td>\n","      <td>0.011341</td>\n","      <td>0.008773</td>\n","      <td>0.025426</td>\n","      <td>0.031813</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>-0.030469</td>\n","      <td>-0.017833</td>\n","      <td>-0.028735</td>\n","      <td>0.017293</td>\n","      <td>-0.035899</td>\n","      <td>-0.017073</td>\n","      <td>-0.020015</td>\n","      <td>-0.028862</td>\n","      <td>-0.026353</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>0.003391</td>\n","      <td>-0.011726</td>\n","      <td>-0.000466</td>\n","      <td>-0.040061</td>\n","      <td>0.028283</td>\n","      <td>-0.005561</td>\n","      <td>-0.019424</td>\n","      <td>-0.062208</td>\n","      <td>-0.084716</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>-0.021533</td>\n","      <td>-0.019873</td>\n","      <td>-0.012710</td>\n","      <td>-0.004474</td>\n","      <td>-0.009764</td>\n","      <td>-0.010989</td>\n","      <td>-0.007802</td>\n","      <td>0.009860</td>\n","      <td>0.009658</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["         SP       DAX      FTSE  ...        EM       ISE     ISE.1\n","0 -0.004679  0.002193  0.003894  ...  0.028524  0.035754  0.038376\n","1  0.007787  0.008455  0.012866  ...  0.008773  0.025426  0.031813\n","2 -0.030469 -0.017833 -0.028735  ... -0.020015 -0.028862 -0.026353\n","3  0.003391 -0.011726 -0.000466  ... -0.019424 -0.062208 -0.084716\n","4 -0.021533 -0.019873 -0.012710  ... -0.007802  0.009860  0.009658\n","\n","[5 rows x 9 columns]"]},"metadata":{"tags":[]},"execution_count":4}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":270},"id":"7hSyB38a_Syx","executionInfo":{"status":"ok","timestamp":1623699741210,"user_tz":-540,"elapsed":18,"user":{"displayName":"윤건일","photoUrl":"","userId":"05157393038207945770"}},"outputId":"ebc064a5-0689-49c5-a7de-1740fcb11a7b"},"source":["# series data to img function\n","def series_to_img(dataset, time_step=1):\n","    num = dataset.shape[1]      # features num\n","    df = pd.DataFrame(dataset)\n","    cols, names = list(), list()\n","    # sequence t-n to t-1\n","    for i in range(time_step, 0, -1):\n","        cols.append(df.shift(i))\n","        names += [('var%d(t-%d)' % (j+1, i)) for j in range(num)]\n","\n","    for i in range(0, 1):\n","        cols.append(df.shift(-i))\n","        if i == 0:\n","            names += [('var%d(t)' % (j+1)) for j in range(num)]\n","        else:\n","            names += [('var%d(t+%d)' % (j+1, i)) for j in range(num)]\n","\n","    agg = pd.concat(cols, axis=1)\n","    agg.columns = names\n","    agg.dropna(inplace=True)\n","    return agg\n","\n","dataset = df.values\n","dataset = dataset.astype('float')\n","\n","n_inputs = 24\n","n_features = 9\n","del_idx = n_inputs * n_features + 1\n","del_cols = [i for i in range(del_idx, del_idx+n_features-1)]\n","new_df = series_to_img(dataset, n_inputs)\n","new_df.drop(new_df.columns[del_cols], axis=1, inplace=True)\n","new_df.head()"],"execution_count":5,"outputs":[{"output_type":"execute_result","data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>var1(t-24)</th>\n","      <th>var2(t-24)</th>\n","      <th>var3(t-24)</th>\n","      <th>var4(t-24)</th>\n","      <th>var5(t-24)</th>\n","      <th>var6(t-24)</th>\n","      <th>var7(t-24)</th>\n","      <th>var8(t-24)</th>\n","      <th>var9(t-24)</th>\n","      <th>var1(t-23)</th>\n","      <th>var2(t-23)</th>\n","      <th>var3(t-23)</th>\n","      <th>var4(t-23)</th>\n","      <th>var5(t-23)</th>\n","      <th>var6(t-23)</th>\n","      <th>var7(t-23)</th>\n","      <th>var8(t-23)</th>\n","      <th>var9(t-23)</th>\n","      <th>var1(t-22)</th>\n","      <th>var2(t-22)</th>\n","      <th>var3(t-22)</th>\n","      <th>var4(t-22)</th>\n","      <th>var5(t-22)</th>\n","      <th>var6(t-22)</th>\n","      <th>var7(t-22)</th>\n","      <th>var8(t-22)</th>\n","      <th>var9(t-22)</th>\n","      <th>var1(t-21)</th>\n","      <th>var2(t-21)</th>\n","      <th>var3(t-21)</th>\n","      <th>var4(t-21)</th>\n","      <th>var5(t-21)</th>\n","      <th>var6(t-21)</th>\n","      <th>var7(t-21)</th>\n","      <th>var8(t-21)</th>\n","      <th>var9(t-21)</th>\n","      <th>var1(t-20)</th>\n","      <th>var2(t-20)</th>\n","      <th>var3(t-20)</th>\n","      <th>var4(t-20)</th>\n","      <th>...</th>\n","      <th>var7(t-5)</th>\n","      <th>var8(t-5)</th>\n","      <th>var9(t-5)</th>\n","      <th>var1(t-4)</th>\n","      <th>var2(t-4)</th>\n","      <th>var3(t-4)</th>\n","      <th>var4(t-4)</th>\n","      <th>var5(t-4)</th>\n","      <th>var6(t-4)</th>\n","      <th>var7(t-4)</th>\n","      <th>var8(t-4)</th>\n","      <th>var9(t-4)</th>\n","      <th>var1(t-3)</th>\n","      <th>var2(t-3)</th>\n","      <th>var3(t-3)</th>\n","      <th>var4(t-3)</th>\n","      <th>var5(t-3)</th>\n","      <th>var6(t-3)</th>\n","      <th>var7(t-3)</th>\n","      <th>var8(t-3)</th>\n","      <th>var9(t-3)</th>\n","      <th>var1(t-2)</th>\n","      <th>var2(t-2)</th>\n","      <th>var3(t-2)</th>\n","      <th>var4(t-2)</th>\n","      <th>var5(t-2)</th>\n","      <th>var6(t-2)</th>\n","      <th>var7(t-2)</th>\n","      <th>var8(t-2)</th>\n","      <th>var9(t-2)</th>\n","      <th>var1(t-1)</th>\n","      <th>var2(t-1)</th>\n","      <th>var3(t-1)</th>\n","      <th>var4(t-1)</th>\n","      <th>var5(t-1)</th>\n","      <th>var6(t-1)</th>\n","      <th>var7(t-1)</th>\n","      <th>var8(t-1)</th>\n","      <th>var9(t-1)</th>\n","      <th>var1(t)</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>24</th>\n","      <td>-0.004679</td>\n","      <td>0.002193</td>\n","      <td>0.003894</td>\n","      <td>0.000000</td>\n","      <td>0.031190</td>\n","      <td>0.012698</td>\n","      <td>0.028524</td>\n","      <td>0.035754</td>\n","      <td>0.038376</td>\n","      <td>0.007787</td>\n","      <td>0.008455</td>\n","      <td>0.012866</td>\n","      <td>0.004162</td>\n","      <td>0.018920</td>\n","      <td>0.011341</td>\n","      <td>0.008773</td>\n","      <td>0.025426</td>\n","      <td>0.031813</td>\n","      <td>-0.030469</td>\n","      <td>-0.017833</td>\n","      <td>-0.028735</td>\n","      <td>0.017293</td>\n","      <td>-0.035899</td>\n","      <td>-0.017073</td>\n","      <td>-0.020015</td>\n","      <td>-0.028862</td>\n","      <td>-0.026353</td>\n","      <td>0.003391</td>\n","      <td>-0.011726</td>\n","      <td>-0.000466</td>\n","      <td>-0.040061</td>\n","      <td>0.028283</td>\n","      <td>-0.005561</td>\n","      <td>-0.019424</td>\n","      <td>-0.062208</td>\n","      <td>-0.084716</td>\n","      <td>-0.021533</td>\n","      <td>-0.019873</td>\n","      <td>-0.012710</td>\n","      <td>-0.004474</td>\n","      <td>...</td>\n","      <td>0.002243</td>\n","      <td>-0.008777</td>\n","      <td>-0.023458</td>\n","      <td>-0.000533</td>\n","      <td>-0.015637</td>\n","      <td>-0.017454</td>\n","      <td>-0.015134</td>\n","      <td>-0.016289</td>\n","      <td>-0.019739</td>\n","      <td>-0.019091</td>\n","      <td>-0.025919</td>\n","      <td>-0.035607</td>\n","      <td>0.015710</td>\n","      <td>0.024040</td>\n","      <td>0.021039</td>\n","      <td>-0.006175</td>\n","      <td>0.027574</td>\n","      <td>0.017862</td>\n","      <td>0.012719</td>\n","      <td>0.015279</td>\n","      <td>0.022403</td>\n","      <td>-0.007518</td>\n","      <td>0.026577</td>\n","      <td>0.015275</td>\n","      <td>0.026908</td>\n","      <td>0.009565</td>\n","      <td>0.018770</td>\n","      <td>0.015166</td>\n","      <td>0.018578</td>\n","      <td>0.023231</td>\n","      <td>0.016233</td>\n","      <td>0.003932</td>\n","      <td>0.000071</td>\n","      <td>-0.011169</td>\n","      <td>0.024128</td>\n","      <td>-0.004139</td>\n","      <td>0.002073</td>\n","      <td>-0.014133</td>\n","      <td>-0.014571</td>\n","      <td>0.026541</td>\n","    </tr>\n","    <tr>\n","      <th>25</th>\n","      <td>0.007787</td>\n","      <td>0.008455</td>\n","      <td>0.012866</td>\n","      <td>0.004162</td>\n","      <td>0.018920</td>\n","      <td>0.011341</td>\n","      <td>0.008773</td>\n","      <td>0.025426</td>\n","      <td>0.031813</td>\n","      <td>-0.030469</td>\n","      <td>-0.017833</td>\n","      <td>-0.028735</td>\n","      <td>0.017293</td>\n","      <td>-0.035899</td>\n","      <td>-0.017073</td>\n","      <td>-0.020015</td>\n","      <td>-0.028862</td>\n","      <td>-0.026353</td>\n","      <td>0.003391</td>\n","      <td>-0.011726</td>\n","      <td>-0.000466</td>\n","      <td>-0.040061</td>\n","      <td>0.028283</td>\n","      <td>-0.005561</td>\n","      <td>-0.019424</td>\n","      <td>-0.062208</td>\n","      <td>-0.084716</td>\n","      <td>-0.021533</td>\n","      <td>-0.019873</td>\n","      <td>-0.012710</td>\n","      <td>-0.004474</td>\n","      <td>-0.009764</td>\n","      <td>-0.010989</td>\n","      <td>-0.007802</td>\n","      <td>0.009860</td>\n","      <td>0.009658</td>\n","      <td>-0.022823</td>\n","      <td>-0.013526</td>\n","      <td>-0.005026</td>\n","      <td>-0.049039</td>\n","      <td>...</td>\n","      <td>-0.019091</td>\n","      <td>-0.025919</td>\n","      <td>-0.035607</td>\n","      <td>0.015710</td>\n","      <td>0.024040</td>\n","      <td>0.021039</td>\n","      <td>-0.006175</td>\n","      <td>0.027574</td>\n","      <td>0.017862</td>\n","      <td>0.012719</td>\n","      <td>0.015279</td>\n","      <td>0.022403</td>\n","      <td>-0.007518</td>\n","      <td>0.026577</td>\n","      <td>0.015275</td>\n","      <td>0.026908</td>\n","      <td>0.009565</td>\n","      <td>0.018770</td>\n","      <td>0.015166</td>\n","      <td>0.018578</td>\n","      <td>0.023231</td>\n","      <td>0.016233</td>\n","      <td>0.003932</td>\n","      <td>0.000071</td>\n","      <td>-0.011169</td>\n","      <td>0.024128</td>\n","      <td>-0.004139</td>\n","      <td>0.002073</td>\n","      <td>-0.014133</td>\n","      <td>-0.014571</td>\n","      <td>0.026541</td>\n","      <td>0.029306</td>\n","      <td>0.014788</td>\n","      <td>0.015846</td>\n","      <td>0.039282</td>\n","      <td>0.019127</td>\n","      <td>0.032338</td>\n","      <td>0.036607</td>\n","      <td>0.042759</td>\n","      <td>0.001484</td>\n","    </tr>\n","    <tr>\n","      <th>26</th>\n","      <td>-0.030469</td>\n","      <td>-0.017833</td>\n","      <td>-0.028735</td>\n","      <td>0.017293</td>\n","      <td>-0.035899</td>\n","      <td>-0.017073</td>\n","      <td>-0.020015</td>\n","      <td>-0.028862</td>\n","      <td>-0.026353</td>\n","      <td>0.003391</td>\n","      <td>-0.011726</td>\n","      <td>-0.000466</td>\n","      <td>-0.040061</td>\n","      <td>0.028283</td>\n","      <td>-0.005561</td>\n","      <td>-0.019424</td>\n","      <td>-0.062208</td>\n","      <td>-0.084716</td>\n","      <td>-0.021533</td>\n","      <td>-0.019873</td>\n","      <td>-0.012710</td>\n","      <td>-0.004474</td>\n","      <td>-0.009764</td>\n","      <td>-0.010989</td>\n","      <td>-0.007802</td>\n","      <td>0.009860</td>\n","      <td>0.009658</td>\n","      <td>-0.022823</td>\n","      <td>-0.013526</td>\n","      <td>-0.005026</td>\n","      <td>-0.049039</td>\n","      <td>-0.053849</td>\n","      <td>-0.012451</td>\n","      <td>-0.022630</td>\n","      <td>-0.029191</td>\n","      <td>-0.042361</td>\n","      <td>0.001757</td>\n","      <td>-0.017674</td>\n","      <td>-0.006141</td>\n","      <td>0.000000</td>\n","      <td>...</td>\n","      <td>0.012719</td>\n","      <td>0.015279</td>\n","      <td>0.022403</td>\n","      <td>-0.007518</td>\n","      <td>0.026577</td>\n","      <td>0.015275</td>\n","      <td>0.026908</td>\n","      <td>0.009565</td>\n","      <td>0.018770</td>\n","      <td>0.015166</td>\n","      <td>0.018578</td>\n","      <td>0.023231</td>\n","      <td>0.016233</td>\n","      <td>0.003932</td>\n","      <td>0.000071</td>\n","      <td>-0.011169</td>\n","      <td>0.024128</td>\n","      <td>-0.004139</td>\n","      <td>0.002073</td>\n","      <td>-0.014133</td>\n","      <td>-0.014571</td>\n","      <td>0.026541</td>\n","      <td>0.029306</td>\n","      <td>0.014788</td>\n","      <td>0.015846</td>\n","      <td>0.039282</td>\n","      <td>0.019127</td>\n","      <td>0.032338</td>\n","      <td>0.036607</td>\n","      <td>0.042759</td>\n","      <td>0.001484</td>\n","      <td>0.004766</td>\n","      <td>0.003651</td>\n","      <td>-0.013411</td>\n","      <td>-0.015462</td>\n","      <td>0.005627</td>\n","      <td>0.007895</td>\n","      <td>0.011353</td>\n","      <td>0.021468</td>\n","      <td>-0.050369</td>\n","    </tr>\n","    <tr>\n","      <th>27</th>\n","      <td>0.003391</td>\n","      <td>-0.011726</td>\n","      <td>-0.000466</td>\n","      <td>-0.040061</td>\n","      <td>0.028283</td>\n","      <td>-0.005561</td>\n","      <td>-0.019424</td>\n","      <td>-0.062208</td>\n","      <td>-0.084716</td>\n","      <td>-0.021533</td>\n","      <td>-0.019873</td>\n","      <td>-0.012710</td>\n","      <td>-0.004474</td>\n","      <td>-0.009764</td>\n","      <td>-0.010989</td>\n","      <td>-0.007802</td>\n","      <td>0.009860</td>\n","      <td>0.009658</td>\n","      <td>-0.022823</td>\n","      <td>-0.013526</td>\n","      <td>-0.005026</td>\n","      <td>-0.049039</td>\n","      <td>-0.053849</td>\n","      <td>-0.012451</td>\n","      <td>-0.022630</td>\n","      <td>-0.029191</td>\n","      <td>-0.042361</td>\n","      <td>0.001757</td>\n","      <td>-0.017674</td>\n","      <td>-0.006141</td>\n","      <td>0.000000</td>\n","      <td>0.003572</td>\n","      <td>-0.012220</td>\n","      <td>-0.004827</td>\n","      <td>0.015445</td>\n","      <td>-0.000272</td>\n","      <td>-0.034032</td>\n","      <td>-0.047383</td>\n","      <td>-0.050945</td>\n","      <td>0.002912</td>\n","      <td>...</td>\n","      <td>0.015166</td>\n","      <td>0.018578</td>\n","      <td>0.023231</td>\n","      <td>0.016233</td>\n","      <td>0.003932</td>\n","      <td>0.000071</td>\n","      <td>-0.011169</td>\n","      <td>0.024128</td>\n","      <td>-0.004139</td>\n","      <td>0.002073</td>\n","      <td>-0.014133</td>\n","      <td>-0.014571</td>\n","      <td>0.026541</td>\n","      <td>0.029306</td>\n","      <td>0.014788</td>\n","      <td>0.015846</td>\n","      <td>0.039282</td>\n","      <td>0.019127</td>\n","      <td>0.032338</td>\n","      <td>0.036607</td>\n","      <td>0.042759</td>\n","      <td>0.001484</td>\n","      <td>0.004766</td>\n","      <td>0.003651</td>\n","      <td>-0.013411</td>\n","      <td>-0.015462</td>\n","      <td>0.005627</td>\n","      <td>0.007895</td>\n","      <td>0.011353</td>\n","      <td>0.021468</td>\n","      <td>-0.050369</td>\n","      <td>-0.035170</td>\n","      <td>-0.022182</td>\n","      <td>-0.002902</td>\n","      <td>-0.021440</td>\n","      <td>-0.024388</td>\n","      <td>-0.002139</td>\n","      <td>-0.040542</td>\n","      <td>-0.043907</td>\n","      <td>0.007923</td>\n","    </tr>\n","    <tr>\n","      <th>28</th>\n","      <td>-0.021533</td>\n","      <td>-0.019873</td>\n","      <td>-0.012710</td>\n","      <td>-0.004474</td>\n","      <td>-0.009764</td>\n","      <td>-0.010989</td>\n","      <td>-0.007802</td>\n","      <td>0.009860</td>\n","      <td>0.009658</td>\n","      <td>-0.022823</td>\n","      <td>-0.013526</td>\n","      <td>-0.005026</td>\n","      <td>-0.049039</td>\n","      <td>-0.053849</td>\n","      <td>-0.012451</td>\n","      <td>-0.022630</td>\n","      <td>-0.029191</td>\n","      <td>-0.042361</td>\n","      <td>0.001757</td>\n","      <td>-0.017674</td>\n","      <td>-0.006141</td>\n","      <td>0.000000</td>\n","      <td>0.003572</td>\n","      <td>-0.012220</td>\n","      <td>-0.004827</td>\n","      <td>0.015445</td>\n","      <td>-0.000272</td>\n","      <td>-0.034032</td>\n","      <td>-0.047383</td>\n","      <td>-0.050945</td>\n","      <td>0.002912</td>\n","      <td>-0.040302</td>\n","      <td>-0.045220</td>\n","      <td>-0.008677</td>\n","      <td>-0.041168</td>\n","      <td>-0.035552</td>\n","      <td>0.001328</td>\n","      <td>-0.019551</td>\n","      <td>-0.014335</td>\n","      <td>-0.050448</td>\n","      <td>...</td>\n","      <td>0.002073</td>\n","      <td>-0.014133</td>\n","      <td>-0.014571</td>\n","      <td>0.026541</td>\n","      <td>0.029306</td>\n","      <td>0.014788</td>\n","      <td>0.015846</td>\n","      <td>0.039282</td>\n","      <td>0.019127</td>\n","      <td>0.032338</td>\n","      <td>0.036607</td>\n","      <td>0.042759</td>\n","      <td>0.001484</td>\n","      <td>0.004766</td>\n","      <td>0.003651</td>\n","      <td>-0.013411</td>\n","      <td>-0.015462</td>\n","      <td>0.005627</td>\n","      <td>0.007895</td>\n","      <td>0.011353</td>\n","      <td>0.021468</td>\n","      <td>-0.050369</td>\n","      <td>-0.035170</td>\n","      <td>-0.022182</td>\n","      <td>-0.002902</td>\n","      <td>-0.021440</td>\n","      <td>-0.024388</td>\n","      <td>-0.002139</td>\n","      <td>-0.040542</td>\n","      <td>-0.043907</td>\n","      <td>0.007923</td>\n","      <td>0.005434</td>\n","      <td>0.005019</td>\n","      <td>-0.030745</td>\n","      <td>-0.008799</td>\n","      <td>0.001097</td>\n","      <td>-0.007926</td>\n","      <td>-0.022106</td>\n","      <td>-0.033893</td>\n","      <td>0.001738</td>\n","    </tr>\n","  </tbody>\n","</table>\n","<p>5 rows × 217 columns</p>\n","</div>"],"text/plain":["    var1(t-24)  var2(t-24)  var3(t-24)  ...  var8(t-1)  var9(t-1)   var1(t)\n","24   -0.004679    0.002193    0.003894  ...  -0.014133  -0.014571  0.026541\n","25    0.007787    0.008455    0.012866  ...   0.036607   0.042759  0.001484\n","26   -0.030469   -0.017833   -0.028735  ...   0.011353   0.021468 -0.050369\n","27    0.003391   -0.011726   -0.000466  ...  -0.040542  -0.043907  0.007923\n","28   -0.021533   -0.019873   -0.012710  ...  -0.022106  -0.033893  0.001738\n","\n","[5 rows x 217 columns]"]},"metadata":{"tags":[]},"execution_count":5}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"PwJwyFfi_Tla","executionInfo":{"status":"ok","timestamp":1623699840292,"user_tz":-540,"elapsed":99097,"user":{"displayName":"윤건일","photoUrl":"","userId":"05157393038207945770"}},"outputId":"5682cd1a-fce9-4e5d-80d6-4ad0c4db8248"},"source":["from sklearn.model_selection import TimeSeriesSplit\n","from sklearn.preprocessing import MinMaxScaler\n","\n","n_splits = 3\n","test_size = (int)(len(new_df)*0.2)\n","train_test_split = TimeSeriesSplit(n_splits=n_splits+1, gap=n_inputs, test_size=test_size).split(new_df)\n","next(train_test_split)\n","\n","configs = model_config()\n","history = []\n","best_error = []\n","i = 1\n","\n","print('config : epochs, batch_size, learning_rate')\n","\n","# neted cross validation\n","for train_cv_indices, test_cv_indices in train_test_split:\n","    print(f'fold : {i}/{n_splits}')\n","    i+=1\n","\n","    # split x, y data\n","    train_cv_X, train_cv_y = new_df.iloc[train_cv_indices, :-1].values, new_df.iloc[train_cv_indices,-1].values\n","    test_cv_X, test_cv_y = new_df.iloc[test_cv_indices, :-1].values, new_df.iloc[test_cv_indices, -1].values\n","\n","    # length for validation set\n","    test_length = len(test_cv_X)\n","\n","    # scaling data\n","    scaler_x = MinMaxScaler()\n","    train_cv_X = scaler_x.fit_transform(train_cv_X)\n","    test_cv_X = scaler_x.transform(test_cv_X)\n","\n","    train_X, val_X = train_cv_X[:-test_length, :], train_cv_X[-test_length:, :]\n","    train_y, val_y = train_cv_y[:-test_length], train_cv_y[-test_length:]\n","\n","    # reshape\n","    # inner loop\n","    train_X = train_X.reshape(-1,  n_inputs, n_features)\n","    val_X = val_X.reshape(-1, n_inputs, n_features)\n","    train_y = train_y.reshape(-1, 1)\n","    val_y = val_y.reshape(-1, 1)\n","\n","    # outer loop\n","    train_cv_X = train_cv_X.reshape(-1,  n_inputs, n_features)\n","    test_cv_X = test_cv_X.reshape(-1, n_inputs, n_features)\n","    train_cv_y = train_cv_y.reshape(-1, 1)\n","    test_cv_y = test_cv_y.reshape(-1, 1)\n","\n","    # model fit, inner\n","    errors = []\n","    for idx, cfg in enumerate(configs):\n","        print(f' == train {cfg} model == ', end=' ')\n","        model = model_fit(train_X, train_y, cfg)\n","        model.reset_state()\n","        predicted = model.predict(val_X)\n","        if GPU:\n","            predicted = np.asnumpy(predicted)\n","        error = np.sqrt(MSE_metric(predicted, val_y))   # rmse\n","        print(f' error(RMSE):{error}')\n","        if errors:\n","            if error < min(errors):\n","                param = idx\n","        else:\n","            param = idx\n","        errors.append(error)\n","\n","    history.append(errors)\n","\n","    selected_model = model_fit(train_cv_X,train_cv_y, configs[param])\n","    selected_model.reset_state()\n","    predicted = selected_model.predict(test_cv_X)\n","    if GPU:\n","        predicted = np.asnumpy(predicted)\n","    error = np.sqrt(MSE_metric(predicted, test_cv_y))\n","    best_error.append(error)\n","\n","    # model eval\n","    print(f'train-size:{train_X.shape[0]}, val-size:{val_X.shape[0]}, test-size:{test_cv_X.shape[0]}')\n","    print(f'best_model => error(rmse) : {error}, param:{configs[param]}')\n","    print()"],"execution_count":6,"outputs":[{"output_type":"stream","text":["config : epochs, batch_size, learning_rate\n","fold : 1/3\n"," == train [30, 32, 0.01] model ==   error(RMSE):33.79165057554351\n"," == train [30, 32, 0.001] model ==   error(RMSE):2.0148279949444663\n"," == train [30, 64, 0.01] model ==   error(RMSE):28.048165052468228\n"," == train [30, 64, 0.001] model ==   error(RMSE):1.9316286215400762\n","train-size:80, val-size:102, test-size:102\n","best_model => error(rmse) : 2.4876631821712945, param:[30, 64, 0.001]\n","\n","fold : 2/3\n"," == train [30, 32, 0.01] model ==   error(RMSE):0.6178486529203194\n"," == train [30, 32, 0.001] model ==   error(RMSE):0.44641865295644456\n"," == train [30, 64, 0.01] model ==   error(RMSE):29.585626083716495\n"," == train [30, 64, 0.001] model ==   error(RMSE):0.8786802965057463\n","train-size:182, val-size:102, test-size:102\n","best_model => error(rmse) : 0.6358523182490049, param:[30, 32, 0.001]\n","\n","fold : 3/3\n"," == train [30, 32, 0.01] model ==   error(RMSE):28.708894105334817\n"," == train [30, 32, 0.001] model ==   error(RMSE):0.8363687461030129\n"," == train [30, 64, 0.01] model ==   error(RMSE):19.617621756813968\n"," == train [30, 64, 0.001] model ==   error(RMSE):2.0579946989275153\n","train-size:284, val-size:102, test-size:102\n","best_model => error(rmse) : 2.2585596729129396, param:[30, 32, 0.001]\n","\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"--o8k0Wd_oOY","executionInfo":{"status":"ok","timestamp":1623699840294,"user_tz":-540,"elapsed":21,"user":{"displayName":"윤건일","photoUrl":"","userId":"05157393038207945770"}},"outputId":"5c53b67c-ff2a-40b2-da92-5bd0d26f53d3"},"source":["model_evaluation = sum(best_error)\n","model_evaluation /= n_splits\n","print(f'evaluation [Mean RMSE] : {model_evaluation}')\n","\n","selected_model.reset_state()\n","predicted = selected_model.predict(test_cv_X)\n","if GPU:\n","    predicted = np.asnumpy(predicted)\n","print(f'MSE : {MSE_metric(predicted, test_cv_y)}')\n","print(f'RMSE : {np.sqrt(MSE_metric(predicted, test_cv_y))}')\n","\n","def MAE_metric(x, t):\n","    return np.mean(numpy.abs(x-t))\n","print(f'MAE : {MAE_metric(predicted, test_cv_y)}')\n","\n","print(f'Standard Deviation : {np.std(predicted)}')"],"execution_count":7,"outputs":[{"output_type":"stream","text":["evaluation [Mean RMSE] : 1.7940250577777463\n","MSE : 5.101091796108605\n","RMSE : 2.2585596729129396\n","MAE : 2.25635587565282\n","Standard Deviation : 0.1013544574379921\n"],"name":"stdout"}]}]}