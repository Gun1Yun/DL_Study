{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f1cb2b89-63e1-40e6-814d-a47bd62cdbe1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "\n",
    "MODULE_PATH = 'C:\\Github\\DL_Study\\CNN'\n",
    "\n",
    "sys.path.insert(0, MODULE_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4d1c2508-3f01-4816-95c4-f4189becd43a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch._C.Generator at 0x1db22f0a410>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# import\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import numpy\n",
    "import time\n",
    "\n",
    "from ShuffleNet import *\n",
    "\n",
    "# set random seed\n",
    "torch.manual_seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f56f7e81-317f-45dd-834c-f8c7e5e1e64f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_device():\n",
    "    if torch.cuda.is_available():\n",
    "        device = torch.device('cuda:0')\n",
    "    else:\n",
    "        device = torch.device('cpu')\n",
    "    return device\n",
    "\n",
    "def df_to_tensor(df):\n",
    "    device = get_device()\n",
    "    return torch.from_numpy(df.values).float().to(device)\n",
    "\n",
    "def np_to_tensor(data):\n",
    "    device = get_device()\n",
    "    return torch.tensor(data).float().to(device)\n",
    "\n",
    "# configuration setting\n",
    "def model_config():\n",
    "    # parameter for CNN Model\n",
    "    epochs = [30]\n",
    "    batch_size = [64]\n",
    "    learning_rate = [0.01, 0.001]\n",
    "    \n",
    "    # create config data\n",
    "    configs = []\n",
    "    for i in epochs:\n",
    "        for j in batch_size:\n",
    "            for k in learning_rate:\n",
    "                config = [i, j, k]\n",
    "                configs.append(config)\n",
    "    return configs\n",
    "\n",
    "# fucntion for fit cnn model using configs\n",
    "def model_fit(train_X, train_y, config, verbose=0):\n",
    "\n",
    "    # unpack config\n",
    "    n_epochs, n_batch, learning_rate = config\n",
    "    # use ShuffleNet for CNN\n",
    "    model = ShuffleNet(groups=3, in_channels=1)\n",
    "    if torch.cuda.is_available():\n",
    "        model.cuda()\n",
    "\n",
    "    # define Loss and Optimizer\n",
    "    criterion = nn.MSELoss()\n",
    "    optimizer = optim.Adam(model.parameters(), lr=learning_rate)\n",
    "\n",
    "    data_size = train_X.size(0)\n",
    "    max_iters = data_size//n_batch\n",
    "\n",
    "    for epoch in range(1, n_epochs+1):\n",
    "        #shuffle data\n",
    "        idx = numpy.random.permutation(numpy.arange(data_size))\n",
    "        x_data = train_X[idx]\n",
    "        y_data = train_y[idx]\n",
    "\n",
    "        epoch_loss = 0\n",
    "        start_time = time.time()\n",
    "        for it in range(max_iters):\n",
    "            batch_x = x_data[it*n_batch:(it+1)*n_batch]\n",
    "            batch_y = y_data[it*n_batch:(it+1)*n_batch]\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            predict = model(batch_x)\n",
    "            loss = criterion(predict, batch_y)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            epoch_loss+= loss.item()\n",
    "        avg_loss = epoch_loss/max_iters\n",
    "\n",
    "        if verbose:\n",
    "            duration = start_time-time.time()\n",
    "            print(f'epoch:{epoch}/{epochs}, ì‹œê°„:{duration:.2f}[s], loss:{avg_loss:.5f}')\n",
    "\n",
    "\n",
    "    return model\n",
    "\n",
    "def MAE_metric(x, t):\n",
    "    t = np.array(t)\n",
    "    return np.mean(numpy.abs(x-t))\n",
    "\n",
    "def MSE_metric(x, t):\n",
    "    t = np.array(t)\n",
    "    return np.mean((x-t)**2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6af1c22b-75c0-418f-89f4-bac6dbe7de65",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>CO(GT)</th>\n",
       "      <th>PT08.S1(CO)</th>\n",
       "      <th>C6H6(GT)</th>\n",
       "      <th>PT08.S2(NMHC)</th>\n",
       "      <th>NOx(GT)</th>\n",
       "      <th>PT08.S3(NOx)</th>\n",
       "      <th>NO2(GT)</th>\n",
       "      <th>PT08.S4(NO2)</th>\n",
       "      <th>PT08.S5(O3)</th>\n",
       "      <th>T</th>\n",
       "      <th>RH</th>\n",
       "      <th>AH</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2.6</td>\n",
       "      <td>1360.0</td>\n",
       "      <td>11.9</td>\n",
       "      <td>1046.0</td>\n",
       "      <td>166.0</td>\n",
       "      <td>1056.0</td>\n",
       "      <td>113.0</td>\n",
       "      <td>1692.0</td>\n",
       "      <td>1268.0</td>\n",
       "      <td>13.6</td>\n",
       "      <td>48.9</td>\n",
       "      <td>0.7578</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2.0</td>\n",
       "      <td>1292.0</td>\n",
       "      <td>9.4</td>\n",
       "      <td>955.0</td>\n",
       "      <td>103.0</td>\n",
       "      <td>1174.0</td>\n",
       "      <td>92.0</td>\n",
       "      <td>1559.0</td>\n",
       "      <td>972.0</td>\n",
       "      <td>13.3</td>\n",
       "      <td>47.7</td>\n",
       "      <td>0.7255</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2.2</td>\n",
       "      <td>1402.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>939.0</td>\n",
       "      <td>131.0</td>\n",
       "      <td>1140.0</td>\n",
       "      <td>114.0</td>\n",
       "      <td>1555.0</td>\n",
       "      <td>1074.0</td>\n",
       "      <td>11.9</td>\n",
       "      <td>54.0</td>\n",
       "      <td>0.7502</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2.2</td>\n",
       "      <td>1376.0</td>\n",
       "      <td>9.2</td>\n",
       "      <td>948.0</td>\n",
       "      <td>172.0</td>\n",
       "      <td>1092.0</td>\n",
       "      <td>122.0</td>\n",
       "      <td>1584.0</td>\n",
       "      <td>1203.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>60.0</td>\n",
       "      <td>0.7867</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.6</td>\n",
       "      <td>1272.0</td>\n",
       "      <td>6.5</td>\n",
       "      <td>836.0</td>\n",
       "      <td>131.0</td>\n",
       "      <td>1205.0</td>\n",
       "      <td>116.0</td>\n",
       "      <td>1490.0</td>\n",
       "      <td>1110.0</td>\n",
       "      <td>11.2</td>\n",
       "      <td>59.6</td>\n",
       "      <td>0.7888</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   CO(GT)  PT08.S1(CO)  C6H6(GT)  PT08.S2(NMHC)  NOx(GT)  PT08.S3(NOx)  \\\n",
       "0     2.6       1360.0      11.9         1046.0    166.0        1056.0   \n",
       "1     2.0       1292.0       9.4          955.0    103.0        1174.0   \n",
       "2     2.2       1402.0       9.0          939.0    131.0        1140.0   \n",
       "3     2.2       1376.0       9.2          948.0    172.0        1092.0   \n",
       "4     1.6       1272.0       6.5          836.0    131.0        1205.0   \n",
       "\n",
       "   NO2(GT)  PT08.S4(NO2)  PT08.S5(O3)     T    RH      AH  \n",
       "0    113.0        1692.0       1268.0  13.6  48.9  0.7578  \n",
       "1     92.0        1559.0        972.0  13.3  47.7  0.7255  \n",
       "2    114.0        1555.0       1074.0  11.9  54.0  0.7502  \n",
       "3    122.0        1584.0       1203.0  11.0  60.0  0.7867  \n",
       "4    116.0        1490.0       1110.0  11.2  59.6  0.7888  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# dataset\n",
    "import zipfile, requests, io\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import numpy\n",
    "import time\n",
    "\n",
    "numpy.random.seed(42)\n",
    "np.random.seed(42)\n",
    "\n",
    "data_url = 'https://archive.ics.uci.edu/ml/machine-learning-databases/00360/AirQualityUCI.zip'\n",
    "r = requests.get(data_url)\n",
    "with zipfile.ZipFile(io.BytesIO(r.content)) as z:\n",
    "    with z.open('AirQualityUCI.csv') as f:\n",
    "        df = pd.read_csv(f, sep=';')\n",
    "\n",
    "df = df.iloc[:9357]\n",
    "df.drop(['Date', 'Time', 'Unnamed: 15', 'Unnamed: 16'], axis=1, inplace=True)\n",
    "df = df.astype(str)\n",
    "df.replace('(.*),(.*)', r'\\1.\\2', regex=True, inplace=True)\n",
    "df = df.astype('float')\n",
    "df.replace(-200, numpy.nan, inplace=True)       # -200 is missing value\n",
    "df.drop(['NMHC(GT)'], axis=1, inplace=True)     # almost NaN value\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f9de9caf-3247-4713-baf1-15c8970c7275",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "skewness : 0.7557812558451819\n",
      "kurtosis : 0.33427505050353723\n",
      "jarque bera : 897.8116781627575\n",
      "ADF : -9.823043865717219\n"
     ]
    }
   ],
   "source": [
    "from scipy.stats import skew, kurtosis\n",
    "from statsmodels.tsa.stattools import adfuller\n",
    "\n",
    "# jb = (n/6)*(skewness**2 + (kurtosis**2/4))\n",
    "\n",
    "def data_statistics(df):\n",
    "    df = df.dropna()\n",
    "    data = df.values\n",
    "    num = len(df)\n",
    "    skewness_ = skew(data)\n",
    "    kurtosis_ = kurtosis(data)\n",
    "    jarque_bera_ = (num/6)*(skewness_**2 + (kurtosis_**2/4))\n",
    "    result = adfuller(data)\n",
    "    adf_ = result[0]\n",
    "    print(f'skewness : {skewness_}')\n",
    "    print(f'kurtosis : {kurtosis_}')\n",
    "    print(f'jarque bera : {jarque_bera_}')\n",
    "    print(f'ADF : {adf_}')\n",
    "\n",
    "data_statistics(df['PT08.S1(CO)'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "cb3c939a-5bf9-40fc-968c-779ebf28ca18",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>CO(GT)</th>\n",
       "      <th>PT08.S1(CO)</th>\n",
       "      <th>C6H6(GT)</th>\n",
       "      <th>PT08.S2(NMHC)</th>\n",
       "      <th>NOx(GT)</th>\n",
       "      <th>PT08.S3(NOx)</th>\n",
       "      <th>NO2(GT)</th>\n",
       "      <th>PT08.S4(NO2)</th>\n",
       "      <th>PT08.S5(O3)</th>\n",
       "      <th>T</th>\n",
       "      <th>RH</th>\n",
       "      <th>AH</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>7674.000000</td>\n",
       "      <td>8991.000000</td>\n",
       "      <td>8991.000000</td>\n",
       "      <td>8991.000000</td>\n",
       "      <td>7718.000000</td>\n",
       "      <td>8991.000000</td>\n",
       "      <td>7715.000000</td>\n",
       "      <td>8991.000000</td>\n",
       "      <td>8991.000000</td>\n",
       "      <td>8991.000000</td>\n",
       "      <td>8991.000000</td>\n",
       "      <td>8991.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>2.152750</td>\n",
       "      <td>1099.833166</td>\n",
       "      <td>10.083105</td>\n",
       "      <td>939.153376</td>\n",
       "      <td>246.896735</td>\n",
       "      <td>835.493605</td>\n",
       "      <td>113.091251</td>\n",
       "      <td>1456.264598</td>\n",
       "      <td>1022.906128</td>\n",
       "      <td>18.317829</td>\n",
       "      <td>49.234201</td>\n",
       "      <td>1.025530</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>1.453252</td>\n",
       "      <td>217.080037</td>\n",
       "      <td>7.449820</td>\n",
       "      <td>266.831429</td>\n",
       "      <td>212.979168</td>\n",
       "      <td>256.817320</td>\n",
       "      <td>48.370108</td>\n",
       "      <td>346.206794</td>\n",
       "      <td>398.484288</td>\n",
       "      <td>8.832116</td>\n",
       "      <td>17.316892</td>\n",
       "      <td>0.403813</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.100000</td>\n",
       "      <td>647.000000</td>\n",
       "      <td>0.100000</td>\n",
       "      <td>383.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>322.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>551.000000</td>\n",
       "      <td>221.000000</td>\n",
       "      <td>-1.900000</td>\n",
       "      <td>9.200000</td>\n",
       "      <td>0.184700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>1.100000</td>\n",
       "      <td>937.000000</td>\n",
       "      <td>4.400000</td>\n",
       "      <td>734.500000</td>\n",
       "      <td>98.000000</td>\n",
       "      <td>658.000000</td>\n",
       "      <td>78.000000</td>\n",
       "      <td>1227.000000</td>\n",
       "      <td>731.500000</td>\n",
       "      <td>11.800000</td>\n",
       "      <td>35.800000</td>\n",
       "      <td>0.736800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>1.800000</td>\n",
       "      <td>1063.000000</td>\n",
       "      <td>8.200000</td>\n",
       "      <td>909.000000</td>\n",
       "      <td>180.000000</td>\n",
       "      <td>806.000000</td>\n",
       "      <td>109.000000</td>\n",
       "      <td>1463.000000</td>\n",
       "      <td>963.000000</td>\n",
       "      <td>17.800000</td>\n",
       "      <td>49.600000</td>\n",
       "      <td>0.995400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>2.900000</td>\n",
       "      <td>1231.000000</td>\n",
       "      <td>14.000000</td>\n",
       "      <td>1116.000000</td>\n",
       "      <td>326.000000</td>\n",
       "      <td>969.500000</td>\n",
       "      <td>142.000000</td>\n",
       "      <td>1674.000000</td>\n",
       "      <td>1273.500000</td>\n",
       "      <td>24.400000</td>\n",
       "      <td>62.500000</td>\n",
       "      <td>1.313700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>11.900000</td>\n",
       "      <td>2040.000000</td>\n",
       "      <td>63.700000</td>\n",
       "      <td>2214.000000</td>\n",
       "      <td>1479.000000</td>\n",
       "      <td>2683.000000</td>\n",
       "      <td>340.000000</td>\n",
       "      <td>2775.000000</td>\n",
       "      <td>2523.000000</td>\n",
       "      <td>44.600000</td>\n",
       "      <td>88.700000</td>\n",
       "      <td>2.231000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            CO(GT)  PT08.S1(CO)     C6H6(GT)  PT08.S2(NMHC)      NOx(GT)  \\\n",
       "count  7674.000000  8991.000000  8991.000000    8991.000000  7718.000000   \n",
       "mean      2.152750  1099.833166    10.083105     939.153376   246.896735   \n",
       "std       1.453252   217.080037     7.449820     266.831429   212.979168   \n",
       "min       0.100000   647.000000     0.100000     383.000000     2.000000   \n",
       "25%       1.100000   937.000000     4.400000     734.500000    98.000000   \n",
       "50%       1.800000  1063.000000     8.200000     909.000000   180.000000   \n",
       "75%       2.900000  1231.000000    14.000000    1116.000000   326.000000   \n",
       "max      11.900000  2040.000000    63.700000    2214.000000  1479.000000   \n",
       "\n",
       "       PT08.S3(NOx)      NO2(GT)  PT08.S4(NO2)  PT08.S5(O3)            T  \\\n",
       "count   8991.000000  7715.000000   8991.000000  8991.000000  8991.000000   \n",
       "mean     835.493605   113.091251   1456.264598  1022.906128    18.317829   \n",
       "std      256.817320    48.370108    346.206794   398.484288     8.832116   \n",
       "min      322.000000     2.000000    551.000000   221.000000    -1.900000   \n",
       "25%      658.000000    78.000000   1227.000000   731.500000    11.800000   \n",
       "50%      806.000000   109.000000   1463.000000   963.000000    17.800000   \n",
       "75%      969.500000   142.000000   1674.000000  1273.500000    24.400000   \n",
       "max     2683.000000   340.000000   2775.000000  2523.000000    44.600000   \n",
       "\n",
       "                RH           AH  \n",
       "count  8991.000000  8991.000000  \n",
       "mean     49.234201     1.025530  \n",
       "std      17.316892     0.403813  \n",
       "min       9.200000     0.184700  \n",
       "25%      35.800000     0.736800  \n",
       "50%      49.600000     0.995400  \n",
       "75%      62.500000     1.313700  \n",
       "max      88.700000     2.231000  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6b0167de-fe53-4d16-bfcb-02a92d1079d7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "CO(GT)           1683\n",
       "PT08.S1(CO)       366\n",
       "C6H6(GT)          366\n",
       "PT08.S2(NMHC)     366\n",
       "NOx(GT)          1639\n",
       "PT08.S3(NOx)      366\n",
       "NO2(GT)          1642\n",
       "PT08.S4(NO2)      366\n",
       "PT08.S5(O3)       366\n",
       "T                 366\n",
       "RH                366\n",
       "AH                366\n",
       "dtype: int64"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "cb8e5d17-4d6c-440e-9a3d-9021b486b58f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# series data to img function\n",
    "def series_to_img(dataset, time_step=1):\n",
    "    num = dataset.shape[1]      # features num\n",
    "    df = pd.DataFrame(dataset)\n",
    "    cols, names = list(), list()\n",
    "    # sequence t-n to t-1\n",
    "    for i in range(time_step, 0, -1):\n",
    "        cols.append(df.shift(i))\n",
    "        names += [('var%d(t-%d)' % (j+1, i)) for j in range(num)]\n",
    "\n",
    "    for i in range(0, 1):\n",
    "        cols.append(df.shift(-i))\n",
    "        if i == 0:\n",
    "            names += [('var%d(t)' % (j+1)) for j in range(num)]\n",
    "        else:\n",
    "            names += [('var%d(t+%d)' % (j+1, i)) for j in range(num)]\n",
    "\n",
    "    agg = pd.concat(cols, axis=1)\n",
    "    agg.columns = names\n",
    "    agg.dropna(inplace=True)\n",
    "    return agg\n",
    "\n",
    "from sklearn.model_selection import TimeSeriesSplit\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "cols = df.columns.tolist()\n",
    "cols = cols[1:2]+cols[0:1]+cols[2:]\n",
    "dataset = df[cols]\n",
    "dataset.ffill(axis=1, inplace=True)                  # forward fill for missing value\n",
    "dataset = dataset.values\n",
    "dataset = dataset.astype('float')\n",
    "\n",
    "n_inputs = 24\n",
    "n_features = 12\n",
    "del_idx = n_inputs * n_features + 1\n",
    "del_cols = [i for i in range(del_idx, del_idx+n_features-1)]\n",
    "new_df = series_to_img(dataset, n_inputs)\n",
    "new_df.drop(new_df.columns[del_cols], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "291268a0-cc51-4c7f-b9fb-6ee9874f1bb9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "config : epochs, batch_size, learning_rate\n",
      "fold : 1/10\n",
      " == train [30, 64, 0.01] model ==  "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\lab\\anaconda3\\envs\\pytorch\\lib\\site-packages\\torch\\nn\\functional.py:718: UserWarning: Named tensors and all their associated APIs are an experimental feature and subject to change. Please do not use them for anything important until they are released as stable. (Triggered internally at  ..\\c10/core/TensorImpl.h:1156.)\n",
      "  return torch.max_pool2d(input, kernel_size, stride, padding, dilation, ceil_mode)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "error(rmse):190.3350\n",
      " == train [30, 64, 0.001] model ==  error(rmse):195.8149\n",
      "train-size:1130, val-size:282, test-size:717\n",
      "best_model => error(rmse) : 215.37, param:[30, 64, 0.01], times: 26.324\n",
      "\n",
      "fold : 2/10\n",
      " == train [30, 64, 0.01] model ==  error(rmse):232.1035\n",
      " == train [30, 64, 0.001] model ==  error(rmse):212.5361\n",
      "train-size:1704, val-size:425, test-size:717\n",
      "best_model => error(rmse) : 174.87, param:[30, 64, 0.001], times: 39.446\n",
      "\n",
      "fold : 3/10\n",
      " == train [30, 64, 0.01] model ==  error(rmse):134.8446\n",
      " == train [30, 64, 0.001] model ==  error(rmse):165.2034\n",
      "train-size:2277, val-size:569, test-size:717\n",
      "best_model => error(rmse) : 156.88, param:[30, 64, 0.01], times: 52.684\n",
      "\n",
      "fold : 4/10\n",
      " == train [30, 64, 0.01] model ==  error(rmse):186.6190\n",
      " == train [30, 64, 0.001] model ==  error(rmse):172.8347\n",
      "train-size:2851, val-size:712, test-size:717\n",
      "best_model => error(rmse) : 165.49, param:[30, 64, 0.001], times: 65.660\n",
      "\n",
      "fold : 5/10\n",
      " == train [30, 64, 0.01] model ==  error(rmse):145.5573\n",
      " == train [30, 64, 0.001] model ==  error(rmse):164.1876\n",
      "train-size:3424, val-size:856, test-size:717\n",
      "best_model => error(rmse) : 159.33, param:[30, 64, 0.01], times: 78.772\n",
      "\n",
      "fold : 6/10\n",
      " == train [30, 64, 0.01] model ==  error(rmse):133.3357\n",
      " == train [30, 64, 0.001] model ==  error(rmse):160.5752\n",
      "train-size:3998, val-size:999, test-size:717\n",
      "best_model => error(rmse) : 142.25, param:[30, 64, 0.01], times: 93.057\n",
      "\n",
      "fold : 7/10\n",
      " == train [30, 64, 0.01] model ==  error(rmse):158.3471\n",
      " == train [30, 64, 0.001] model ==  error(rmse):166.9852\n",
      "train-size:4572, val-size:1142, test-size:717\n",
      "best_model => error(rmse) : 136.34, param:[30, 64, 0.01], times: 106.043\n",
      "\n",
      "fold : 8/10\n",
      " == train [30, 64, 0.01] model ==  error(rmse):145.1599\n",
      " == train [30, 64, 0.001] model ==  error(rmse):164.1603\n",
      "train-size:5145, val-size:1286, test-size:717\n",
      "best_model => error(rmse) : 124.06, param:[30, 64, 0.01], times: 119.116\n",
      "\n",
      "fold : 9/10\n",
      " == train [30, 64, 0.01] model ==  error(rmse):142.5371\n",
      " == train [30, 64, 0.001] model ==  error(rmse):166.7465\n",
      "train-size:5719, val-size:1429, test-size:717\n",
      "best_model => error(rmse) : 105.25, param:[30, 64, 0.01], times: 132.492\n",
      "\n",
      "fold : 10/10\n",
      " == train [30, 64, 0.01] model ==  error(rmse):119.1465\n",
      " == train [30, 64, 0.001] model ==  error(rmse):145.3686\n",
      "train-size:6292, val-size:1573, test-size:717\n",
      "best_model => error(rmse) : 95.05, param:[30, 64, 0.01], times: 145.862\n",
      "\n"
     ]
    }
   ],
   "source": [
    "n_splits = 10\n",
    "train_test_split = TimeSeriesSplit(n_splits=n_splits+1, gap=n_inputs).split(new_df)\n",
    "next(train_test_split)\n",
    "\n",
    "configs = model_config()\n",
    "history = []\n",
    "\n",
    "best_rmse, best_mse, best_mae = [], [], []\n",
    "learning_time = []\n",
    "\n",
    "i = 1\n",
    "\n",
    "print('config : epochs, batch_size, learning_rate')\n",
    "\n",
    "# nested cross validation for time series model\n",
    "for train_cv_indices, test_cv_indices in train_test_split:\n",
    "    print(f'fold : {i}/{n_splits}')\n",
    "    i+=1\n",
    "\n",
    "    # split x, y data\n",
    "    train_cv_X, train_cv_y = new_df.iloc[train_cv_indices, :-1].values, new_df.iloc[train_cv_indices,-1].values\n",
    "    test_cv_X, test_cv_y = new_df.iloc[test_cv_indices, :-1].values, new_df.iloc[test_cv_indices, -1].values\n",
    "\n",
    "    # length for validation set\n",
    "    test_length = int(len(train_cv_X)*0.2)\n",
    "\n",
    "    # scaling data\n",
    "    scaler_x = MinMaxScaler()\n",
    "    train_cv_X = scaler_x.fit_transform(train_cv_X)\n",
    "    test_cv_X = scaler_x.transform(test_cv_X)\n",
    "\n",
    "    train_X, val_X = train_cv_X[:-test_length, :], train_cv_X[-test_length:, :]\n",
    "    train_y, val_y = train_cv_y[:-test_length], train_cv_y[-test_length:]\n",
    "\n",
    "    # reshape\n",
    "    # inner loop\n",
    "    train_X = train_X.reshape(-1, 1, n_inputs, n_features)\n",
    "    val_X = val_X.reshape(-1, 1, n_inputs, n_features)\n",
    "    train_y = train_y.reshape(-1, 1)\n",
    "    val_y = val_y.reshape(-1, 1)\n",
    "\n",
    "    # outer loop\n",
    "    train_cv_X = train_cv_X.reshape(-1, 1, n_inputs, n_features)\n",
    "    test_cv_X = test_cv_X.reshape(-1, 1, n_inputs, n_features)\n",
    "    train_cv_y = train_cv_y.reshape(-1, 1)\n",
    "    test_cv_y = test_cv_y.reshape(-1, 1)\n",
    "\n",
    "    train_X = np_to_tensor(train_X)\n",
    "    train_y = np_to_tensor(train_y)\n",
    "    val_X = np_to_tensor(val_X)\n",
    "    val_y = np_to_tensor(val_y)\n",
    "    train_cv_X = np_to_tensor(train_cv_X)\n",
    "    train_cv_y = np_to_tensor(train_cv_y)\n",
    "    test_cv_X = np_to_tensor(test_cv_X)\n",
    "    test_cv_y = np_to_tensor(test_cv_y)\n",
    "\n",
    "    # model fit, inner\n",
    "    errors = []\n",
    "    for idx, cfg in enumerate(configs):\n",
    "        print(f' == train {cfg} model == ', end=' ')\n",
    "        model = model_fit(train_X, train_y, cfg)\n",
    "        predicted = model(val_X)\n",
    "        error = F.mse_loss(predicted, val_y)   # mse\n",
    "        print(f'error(rmse):{np.sqrt(error.item()):.4f}')\n",
    "        if errors:\n",
    "            if error.item() < min(errors):\n",
    "                param = idx\n",
    "        else:\n",
    "            param = idx\n",
    "        errors.append(error.item())\n",
    "\n",
    "    history.append(errors)\n",
    "\n",
    "    # outer\n",
    "    start_time = time.time()\n",
    "    # model fitting\n",
    "    selected_model = model_fit(train_cv_X,train_cv_y, configs[param])\n",
    "    # check time\n",
    "    duration = time.time() - start_time\n",
    "    predicted = selected_model(test_cv_X)\n",
    "    rmse = np.sqrt(F.mse_loss(predicted, test_cv_y).item())\n",
    "    mse = F.mse_loss(predicted, test_cv_y)\n",
    "    mae = F.l1_loss(predicted, test_cv_y)\n",
    "    best_rmse.append(rmse)\n",
    "    best_mse.append(mse.item())\n",
    "    best_mae.append(mae.item())\n",
    "    learning_time.append(duration)\n",
    "\n",
    "    # model eval\n",
    "    print(f'train-size:{train_X.size(0)}, val-size:{val_X.size(0)}, test-size:{test_cv_X.size(0)}')\n",
    "    print(f'best_model => error(rmse) : {rmse:.2f}, param:{configs[param]}, times: {duration:.3f}')\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c2e1f8d1-6675-4ba6-a4a0-3c67a4669af6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE: mean=22867.64931640625, std=10265.813312401671\n",
      "RMSE: mean=147.48958529290812, std=33.3837018098987\n",
      "MAE: mean=112.99891357421875, std=25.41284193223544\n",
      "\n",
      "[training time]\n",
      "mean : 85.94544966220856, last:145.86179089546204\n"
     ]
    }
   ],
   "source": [
    "predicted = selected_model(test_cv_X)\n",
    "\n",
    "def model_evaluation(mse, rmse, mae):\n",
    "    mse = np.array(mse)\n",
    "    rmse = np.array(rmse)\n",
    "    mae = np.array(mae)\n",
    "    print(f'MSE: mean={np.mean(mse)}, std={np.std(mse)}')\n",
    "    print(f'RMSE: mean={np.mean(rmse)}, std={np.std(rmse)}')\n",
    "    print(f'MAE: mean={np.mean(mae)}, std={np.std(mae)}')\n",
    "\n",
    "model_evaluation(best_mse, best_rmse, best_mae)\n",
    "\n",
    "# check time\n",
    "print()\n",
    "print('[training time]')\n",
    "print(f'mean : {np.mean(np.array(learning_time))}, last:{learning_time[-1]}')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch",
   "language": "python",
   "name": "pytorch"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
