{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"Chickenpox-LSTM-Regression.ipynb","provenance":[],"authorship_tag":"ABX9TyNfvWWEq4qmNeXynNlshv3h"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","metadata":{"id":"OGZDJ-AjRsEd"},"source":["import os\n","import sys\n","\n","MODULE_PATH = '/content/drive/MyDrive/GitHub/DL_Study/Base'\n","\n","sys.path.insert(0, MODULE_PATH)\n","sys.path"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"WIRpK35FSqC1"},"source":["# import\n","import numpy\n","from config import *\n","from optim import Adam\n","from models import LstmModelReg\n","\n","# for time series split\n","!pip install scikit-learn==0.24.2"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"I2lwT7QxSsgM"},"source":["# configuration setting\n","def model_config():\n","    # parameter for LSTM Model\n","    epochs = [30]\n","    batch_size = [64]\n","    learning_rate = [0.01, 0.001]\n","    \n","    # create config data\n","    configs = []\n","    for i in epochs:\n","        for j in batch_size:\n","            for k in learning_rate:\n","                config = [i, j, k]\n","                configs.append(config)\n","    return configs\n","\n","# fucntion for fit cnn model using configs\n","def model_fit(train_X, train_y, config):\n","    # unpack config\n","    n_epochs, n_batch, learning_rate = config\n","    model = LstmModelReg(time_size=24, hidden_size=64, feature_size=20)\n","    # fit model and return\n","    model.fit(train_X=train_X, train_y=train_y, epochs=n_epochs, \n","              batch_size=n_batch, learning_rate=learning_rate)\n","    return model\n","\n","def MAE_metric(x, t):\n","    return np.mean(numpy.abs(x-t))\n","\n","def MSE_metric(x, t):\n","    return np.mean((x-t)**2)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"1qyAbXzISvfy"},"source":["import zipfile, requests, io\n","import pandas as pd\n","import numpy\n","import time\n","from datetime import datetime\n","\n","data_url = 'https://archive.ics.uci.edu/ml/machine-learning-databases/00580/hungary_chickenpox.zip'\n","r = requests.get(data_url)\n","files = zipfile.ZipFile(io.BytesIO(r.content))\n","df = pd.read_csv(files.open('hungary_chickenpox.csv'), sep=',')\n","df.drop('Date', axis=1, inplace=True)\n","df.head()"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"lhkxq_G5SwnL"},"source":["from scipy.stats import skew, kurtosis\n","from statsmodels.tsa.stattools import adfuller\n","\n","# jb = (n/6)*(skewness**2 + (kurtosis**2/4))\n","\n","def data_statistics(df):\n","    df = df.dropna()\n","    data = df.values\n","    num = len(df)\n","    skewness_ = skew(data)\n","    kurtosis_ = kurtosis(data)\n","    jarque_bera_ = (num/6)*(skewness_**2 + (kurtosis_**2/4))\n","    result = adfuller(data)\n","    adf_ = result[0]\n","    print(f'skewness : {skewness_}')\n","    print(f'kurtosis : {kurtosis_}')\n","    print(f'jarque bera : {jarque_bera_}')\n","    print(f'ADF : {adf_}')\n","\n","data_statistics(df['BUDAPEST'])"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"Ghcn6fdxSxnW"},"source":["df.describe()"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"LyDd22oiSyv9"},"source":["df.isnull().sum()"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"lyuIgCS9Sznm"},"source":["# series data to img function\n","def series_to_img(dataset, time_step=1):\n","    num = dataset.shape[1]      # features num\n","    df = pd.DataFrame(dataset)\n","    cols, names = list(), list()\n","    # sequence t-n to t-1\n","    for i in range(time_step, 0, -1):\n","        cols.append(df.shift(i))\n","        names += [('var%d(t-%d)' % (j+1, i)) for j in range(num)]\n","\n","    for i in range(0, 1):\n","        cols.append(df.shift(-i))\n","        if i == 0:\n","            names += [('var%d(t)' % (j+1)) for j in range(num)]\n","        else:\n","            names += [('var%d(t+%d)' % (j+1, i)) for j in range(num)]\n","\n","    agg = pd.concat(cols, axis=1)\n","    agg.columns = names\n","    agg.dropna(inplace=True)\n","    return agg\n","\n","from sklearn.model_selection import TimeSeriesSplit\n","from sklearn.preprocessing import MinMaxScaler\n","\n","dataset = df.values\n","dataset = dataset.astype('float')\n","\n","n_inputs = 24\n","n_features = 20\n","del_idx = n_inputs * n_features + 1\n","del_cols = [i for i in range(del_idx, del_idx+n_features-1)]\n","new_df = series_to_img(dataset, n_inputs)\n","new_df.drop(new_df.columns[del_cols], axis=1, inplace=True)\n","new_df.head()"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"tZW8U6sjS068"},"source":["n_splits = 3\n","test_size = (int)(len(new_df)*0.2)\n","train_test_split = TimeSeriesSplit(n_splits=n_splits+1, gap=n_inputs, test_size=test_size).split(new_df)\n","next(train_test_split)\n","\n","configs = model_config()\n","history = []\n","\n","best_rmse, best_mse, best_mae = [], [], []\n","i = 1\n","\n","print('config : epochs, batch_size, learning_rate')\n","\n","# neted cross validation\n","for train_cv_indices, test_cv_indices in train_test_split:\n","    print(f'fold : {i}/{n_splits}')\n","    i+=1\n","\n","    # split x, y data\n","    train_cv_X, train_cv_y = new_df.iloc[train_cv_indices, :-1].values, new_df.iloc[train_cv_indices,-1].values\n","    test_cv_X, test_cv_y = new_df.iloc[test_cv_indices, :-1].values, new_df.iloc[test_cv_indices, -1].values\n","\n","    # length for validation set\n","    test_length = len(test_cv_X)\n","\n","    # scaling data\n","    scaler_x = MinMaxScaler()\n","    train_cv_X = scaler_x.fit_transform(train_cv_X)\n","    test_cv_X = scaler_x.transform(test_cv_X)\n","\n","    train_X, val_X = train_cv_X[:-test_length, :], train_cv_X[-test_length:, :]\n","    train_y, val_y = train_cv_y[:-test_length], train_cv_y[-test_length:]\n","\n","    # reshape\n","    # inner loop\n","    train_X = train_X.reshape(-1,  n_inputs, n_features)\n","    val_X = val_X.reshape(-1, n_inputs, n_features)\n","    train_y = train_y.reshape(-1, 1)\n","    val_y = val_y.reshape(-1, 1)\n","\n","    # outer loop\n","    train_cv_X = train_cv_X.reshape(-1,  n_inputs, n_features)\n","    test_cv_X = test_cv_X.reshape(-1, n_inputs, n_features)\n","    train_cv_y = train_cv_y.reshape(-1, 1)\n","    test_cv_y = test_cv_y.reshape(-1, 1)\n","\n","    # model fit, inner\n","    errors = []\n","    for idx, cfg in enumerate(configs):\n","        print(f' == train {cfg} model == ', end=' ')\n","        model = model_fit(train_X, train_y, cfg)\n","        model.reset_state()\n","        predicted = model.predict(val_X)\n","        if GPU:\n","            predicted = np.asnumpy(predicted)\n","        error = np.sqrt(MSE_metric(predicted, val_y))   # rmse\n","        print(f' error(RMSE):{error}')\n","        if errors:\n","            if error < min(errors):\n","                param = idx\n","        else:\n","            param = idx\n","        errors.append(error)\n","\n","    history.append(errors)\n","\n","    selected_model = model_fit(train_cv_X,train_cv_y, configs[param])\n","    selected_model.reset_state()\n","    predicted = selected_model.predict(test_cv_X)\n","    if GPU:\n","        predicted = np.asnumpy(predicted)\n","\n","    rmse = np.sqrt(MSE_metric(predicted, test_cv_y))\n","    mse = MSE_metric(predicted, test_cv_y)\n","    mae = MAE_metric(predicted, test_cv_y)\n","    best_rmse.append(rmse)\n","    best_mse.append(mse)\n","    best_mae.append(mae)   \n","\n","    # model eval\n","    print(f'train-size:{train_X.shape[0]}, val-size:{val_X.shape[0]}, test-size:{test_cv_X.shape[0]}')\n","    print(f'best_model => error(rmse) : {rmse.item():.2f}, param:{configs[param]}')\n","    print()"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"pVXLMcEwS467"},"source":["selected_model.reset_state()\n","predicted = selected_model.predict(test_cv_X)\n","if GPU:\n","    predicted = np.asnumpy(predicted)\n","\n","def model_evaluation(mse, rmse, mae):\n","    mse = np.array(mse)\n","    rmse = np.array(rmse)\n","    mae = np.array(mae)\n","    print(f'MSE: mean={np.mean(mse)}, std={np.std(mse)}')\n","    print(f'RMSE: mean={np.mean(rmse)}, std={np.std(rmse)}')\n","    print(f'MAE: mean={np.mean(mae)}, std={np.std(mae)}')\n","\n","model_evaluation(best_mse, best_rmse, best_mae)"],"execution_count":null,"outputs":[]}]}