{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"Chickenpox-CNN-ShuffleNet-Regression.ipynb","provenance":[],"collapsed_sections":[],"mount_file_id":"1c_787SchxTa211GbFb8CGPQepejs9ZBG","authorship_tag":"ABX9TyNa/Heh7FX+Vv0T718qtiaG"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU"},"cells":[{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"KmgKY-V_HfbK","executionInfo":{"status":"ok","timestamp":1624896711467,"user_tz":-540,"elapsed":282,"user":{"displayName":"윤건일","photoUrl":"","userId":"05157393038207945770"}},"outputId":"5834fb31-5913-4ce5-ad39-0e6fc86225fc"},"source":["import os\n","import sys\n","\n","MODULE_PATH = '/content/drive/MyDrive/GitHub/DL_Study/CNN'\n","\n","sys.path.insert(0, MODULE_PATH)\n","sys.path"],"execution_count":1,"outputs":[{"output_type":"execute_result","data":{"text/plain":["['/content/drive/MyDrive/GitHub/DL_Study/CNN',\n"," '',\n"," '/content',\n"," '/env/python',\n"," '/usr/lib/python37.zip',\n"," '/usr/lib/python3.7',\n"," '/usr/lib/python3.7/lib-dynload',\n"," '/usr/local/lib/python3.7/dist-packages',\n"," '/usr/lib/python3/dist-packages',\n"," '/usr/local/lib/python3.7/dist-packages/IPython/extensions',\n"," '/root/.ipython']"]},"metadata":{"tags":[]},"execution_count":1}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"ZaxlYM59Hx25","executionInfo":{"status":"ok","timestamp":1624896724915,"user_tz":-540,"elapsed":13088,"user":{"displayName":"윤건일","photoUrl":"","userId":"05157393038207945770"}},"outputId":"b817fd3d-9797-4006-aa65-97df89a99382"},"source":["# import\n","import torch\n","import torch.nn as nn\n","import torch.nn.functional as F\n","import torch.optim as optim\n","import time\n","import numpy\n","\n","from ShuffleNet import *\n","\n","torch.manual_seed(42)\n","\n","# for time series split\n","!pip install scikit-learn==0.24.2"],"execution_count":2,"outputs":[{"output_type":"stream","text":["Collecting scikit-learn==0.24.2\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/a8/eb/a48f25c967526b66d5f1fa7a984594f0bf0a5afafa94a8c4dbc317744620/scikit_learn-0.24.2-cp37-cp37m-manylinux2010_x86_64.whl (22.3MB)\n","\u001b[K     |████████████████████████████████| 22.3MB 1.2MB/s \n","\u001b[?25hRequirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.7/dist-packages (from scikit-learn==0.24.2) (1.0.1)\n","Requirement already satisfied: numpy>=1.13.3 in /usr/local/lib/python3.7/dist-packages (from scikit-learn==0.24.2) (1.19.5)\n","Collecting threadpoolctl>=2.0.0\n","  Downloading https://files.pythonhosted.org/packages/f7/12/ec3f2e203afa394a149911729357aa48affc59c20e2c1c8297a60f33f133/threadpoolctl-2.1.0-py3-none-any.whl\n","Requirement already satisfied: scipy>=0.19.1 in /usr/local/lib/python3.7/dist-packages (from scikit-learn==0.24.2) (1.4.1)\n","Installing collected packages: threadpoolctl, scikit-learn\n","  Found existing installation: scikit-learn 0.22.2.post1\n","    Uninstalling scikit-learn-0.22.2.post1:\n","      Successfully uninstalled scikit-learn-0.22.2.post1\n","Successfully installed scikit-learn-0.24.2 threadpoolctl-2.1.0\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"BVO20xiRHywd","executionInfo":{"status":"ok","timestamp":1624896724918,"user_tz":-540,"elapsed":13,"user":{"displayName":"윤건일","photoUrl":"","userId":"05157393038207945770"}}},"source":["def get_device():\n","    if torch.cuda.is_available():\n","        device = torch.device('cuda:0')\n","    else:\n","        device = torch.device('cpu')\n","    return device\n","\n","def df_to_tensor(df):\n","    device = get_device()\n","    return torch.from_numpy(df.values).float().to(device)\n","\n","def np_to_tensor(data):\n","    device = get_device()\n","    return torch.tensor(data).float().to(device)\n","\n","# configuration setting\n","def model_config():\n","    # parameter for CNN Model\n","    epochs = [30]\n","    batch_size = [32]\n","    learning_rate = [0.01, 0.001]\n","    \n","    # create config data\n","    configs = []\n","    for i in epochs:\n","        for j in batch_size:\n","            for k in learning_rate:\n","                config = [i, j, k]\n","                configs.append(config)\n","    return configs\n","\n","# fucntion for fit cnn model using configs\n","def model_fit(train_X, train_y, config, verbose=0):\n","\n","    # unpack config\n","    n_epochs, n_batch, learning_rate = config\n","    # use ShuffleNet for CNN\n","    model = ShuffleNet(groups=3, in_channels=1)\n","    if torch.cuda.is_available():\n","        model.cuda()\n","\n","    # define Loss and Optimizer\n","    criterion = nn.MSELoss()\n","    optimizer = optim.Adam(model.parameters(), lr=learning_rate)\n","\n","    data_size = train_X.size(0)\n","    max_iters = data_size//n_batch\n","\n","    for epoch in range(1, n_epochs+1):\n","        #shuffle data\n","        idx = numpy.random.permutation(numpy.arange(data_size))\n","        x_data = train_X[idx]\n","        y_data = train_y[idx]\n","\n","        epoch_loss = 0\n","        start_time = time.time()\n","        for it in range(max_iters):\n","            batch_x = x_data[it*n_batch:(it+1)*n_batch]\n","            batch_y = y_data[it*n_batch:(it+1)*n_batch]\n","\n","            optimizer.zero_grad()\n","            predict = model(batch_x)\n","            loss = criterion(predict, batch_y)\n","            loss.backward()\n","            optimizer.step()\n","\n","            epoch_loss+= loss.item()\n","        avg_loss = epoch_loss/max_iters\n","\n","        if verbose:\n","            duration = start_time-time.time()\n","            print(f'epoch:{epoch}/{epochs}, ì‹œê°„:{duration:.2f}[s], loss:{avg_loss:.5f}')\n","\n","\n","    return model\n","\n","def MAE_metric(x, t):\n","    t = np.array(t)\n","    return np.mean(numpy.abs(x-t))\n","\n","def MSE_metric(x, t):\n","    t = np.array(t)\n","    return np.mean((x-t)**2)"],"execution_count":3,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":204},"id":"bPb9PdRIIKPY","executionInfo":{"status":"ok","timestamp":1624896724920,"user_tz":-540,"elapsed":14,"user":{"displayName":"윤건일","photoUrl":"","userId":"05157393038207945770"}},"outputId":"bb5d1a3c-ea4a-4cdf-9b2f-1ada17d6b021"},"source":["import zipfile, requests, io\n","import pandas as pd\n","import numpy as np\n","import numpy\n","import time\n","from datetime import datetime\n","\n","np.random.seed(42)\n","numpy.random.seed(42)\n","\n","data_url = 'https://archive.ics.uci.edu/ml/machine-learning-databases/00580/hungary_chickenpox.zip'\n","r = requests.get(data_url)\n","files = zipfile.ZipFile(io.BytesIO(r.content))\n","df = pd.read_csv(files.open('hungary_chickenpox.csv'), sep=',')\n","df.drop('Date', axis=1, inplace=True)\n","df.head()"],"execution_count":4,"outputs":[{"output_type":"execute_result","data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>BUDAPEST</th>\n","      <th>BARANYA</th>\n","      <th>BACS</th>\n","      <th>BEKES</th>\n","      <th>BORSOD</th>\n","      <th>CSONGRAD</th>\n","      <th>FEJER</th>\n","      <th>GYOR</th>\n","      <th>HAJDU</th>\n","      <th>HEVES</th>\n","      <th>JASZ</th>\n","      <th>KOMAROM</th>\n","      <th>NOGRAD</th>\n","      <th>PEST</th>\n","      <th>SOMOGY</th>\n","      <th>SZABOLCS</th>\n","      <th>TOLNA</th>\n","      <th>VAS</th>\n","      <th>VESZPREM</th>\n","      <th>ZALA</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>168</td>\n","      <td>79</td>\n","      <td>30</td>\n","      <td>173</td>\n","      <td>169</td>\n","      <td>42</td>\n","      <td>136</td>\n","      <td>120</td>\n","      <td>162</td>\n","      <td>36</td>\n","      <td>130</td>\n","      <td>57</td>\n","      <td>2</td>\n","      <td>178</td>\n","      <td>66</td>\n","      <td>64</td>\n","      <td>11</td>\n","      <td>29</td>\n","      <td>87</td>\n","      <td>68</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>157</td>\n","      <td>60</td>\n","      <td>30</td>\n","      <td>92</td>\n","      <td>200</td>\n","      <td>53</td>\n","      <td>51</td>\n","      <td>70</td>\n","      <td>84</td>\n","      <td>28</td>\n","      <td>80</td>\n","      <td>50</td>\n","      <td>29</td>\n","      <td>141</td>\n","      <td>48</td>\n","      <td>29</td>\n","      <td>58</td>\n","      <td>53</td>\n","      <td>68</td>\n","      <td>26</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>96</td>\n","      <td>44</td>\n","      <td>31</td>\n","      <td>86</td>\n","      <td>93</td>\n","      <td>30</td>\n","      <td>93</td>\n","      <td>84</td>\n","      <td>191</td>\n","      <td>51</td>\n","      <td>64</td>\n","      <td>46</td>\n","      <td>4</td>\n","      <td>157</td>\n","      <td>33</td>\n","      <td>33</td>\n","      <td>24</td>\n","      <td>18</td>\n","      <td>62</td>\n","      <td>44</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>163</td>\n","      <td>49</td>\n","      <td>43</td>\n","      <td>126</td>\n","      <td>46</td>\n","      <td>39</td>\n","      <td>52</td>\n","      <td>114</td>\n","      <td>107</td>\n","      <td>42</td>\n","      <td>63</td>\n","      <td>54</td>\n","      <td>14</td>\n","      <td>107</td>\n","      <td>66</td>\n","      <td>50</td>\n","      <td>25</td>\n","      <td>21</td>\n","      <td>43</td>\n","      <td>31</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>122</td>\n","      <td>78</td>\n","      <td>53</td>\n","      <td>87</td>\n","      <td>103</td>\n","      <td>34</td>\n","      <td>95</td>\n","      <td>131</td>\n","      <td>172</td>\n","      <td>40</td>\n","      <td>61</td>\n","      <td>49</td>\n","      <td>11</td>\n","      <td>124</td>\n","      <td>63</td>\n","      <td>56</td>\n","      <td>7</td>\n","      <td>47</td>\n","      <td>85</td>\n","      <td>60</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["   BUDAPEST  BARANYA  BACS  BEKES  BORSOD  ...  SZABOLCS  TOLNA  VAS  VESZPREM  ZALA\n","0       168       79    30    173     169  ...        64     11   29        87    68\n","1       157       60    30     92     200  ...        29     58   53        68    26\n","2        96       44    31     86      93  ...        33     24   18        62    44\n","3       163       49    43    126      46  ...        50     25   21        43    31\n","4       122       78    53     87     103  ...        56      7   47        85    60\n","\n","[5 rows x 20 columns]"]},"metadata":{"tags":[]},"execution_count":4}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"ndyZ8bVdIRSO","executionInfo":{"status":"ok","timestamp":1624896725811,"user_tz":-540,"elapsed":901,"user":{"displayName":"윤건일","photoUrl":"","userId":"05157393038207945770"}},"outputId":"a12db27e-481d-4396-90ab-838b727b4fca"},"source":["from scipy.stats import skew, kurtosis\n","from statsmodels.tsa.stattools import adfuller\n","\n","# jb = (n/6)*(skewness**2 + (kurtosis**2/4))\n","\n","def data_statistics(df):\n","    df = df.dropna()\n","    data = df.values\n","    num = len(df)\n","    skewness_ = skew(data)\n","    kurtosis_ = kurtosis(data)\n","    jarque_bera_ = (num/6)*(skewness_**2 + (kurtosis_**2/4))\n","    result = adfuller(data)\n","    adf_ = result[0]\n","    print(f'skewness : {skewness_}')\n","    print(f'kurtosis : {kurtosis_}')\n","    print(f'jarque bera : {jarque_bera_}')\n","    print(f'ADF : {adf_}')\n","\n","data_statistics(df['BUDAPEST'])"],"execution_count":5,"outputs":[{"output_type":"stream","text":["skewness : 0.9489236649041097\n","kurtosis : 1.4006683128498736\n","jarque bera : 121.01039256493132\n","ADF : -6.933218014746713\n"],"name":"stdout"},{"output_type":"stream","text":["/usr/local/lib/python3.7/dist-packages/statsmodels/tools/_testing.py:19: FutureWarning: pandas.util.testing is deprecated. Use the functions in the public API at pandas.testing instead.\n","  import pandas.util.testing as tm\n"],"name":"stderr"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":317},"id":"c5gT9AEEIueO","executionInfo":{"status":"ok","timestamp":1624896725819,"user_tz":-540,"elapsed":43,"user":{"displayName":"윤건일","photoUrl":"","userId":"05157393038207945770"}},"outputId":"87bf9fae-40a8-437e-e740-565cbdff6bae"},"source":["df.describe()"],"execution_count":6,"outputs":[{"output_type":"execute_result","data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>BUDAPEST</th>\n","      <th>BARANYA</th>\n","      <th>BACS</th>\n","      <th>BEKES</th>\n","      <th>BORSOD</th>\n","      <th>CSONGRAD</th>\n","      <th>FEJER</th>\n","      <th>GYOR</th>\n","      <th>HAJDU</th>\n","      <th>HEVES</th>\n","      <th>JASZ</th>\n","      <th>KOMAROM</th>\n","      <th>NOGRAD</th>\n","      <th>PEST</th>\n","      <th>SOMOGY</th>\n","      <th>SZABOLCS</th>\n","      <th>TOLNA</th>\n","      <th>VAS</th>\n","      <th>VESZPREM</th>\n","      <th>ZALA</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>count</th>\n","      <td>522.000000</td>\n","      <td>522.000000</td>\n","      <td>522.000000</td>\n","      <td>522.000000</td>\n","      <td>522.000000</td>\n","      <td>522.000000</td>\n","      <td>522.000000</td>\n","      <td>522.000000</td>\n","      <td>522.000000</td>\n","      <td>522.000000</td>\n","      <td>522.000000</td>\n","      <td>522.000000</td>\n","      <td>522.000000</td>\n","      <td>522.000000</td>\n","      <td>522.000000</td>\n","      <td>522.000000</td>\n","      <td>522.000000</td>\n","      <td>522.000000</td>\n","      <td>522.000000</td>\n","      <td>522.000000</td>\n","    </tr>\n","    <tr>\n","      <th>mean</th>\n","      <td>101.245211</td>\n","      <td>34.204981</td>\n","      <td>37.166667</td>\n","      <td>28.911877</td>\n","      <td>57.082375</td>\n","      <td>31.488506</td>\n","      <td>33.272031</td>\n","      <td>41.436782</td>\n","      <td>47.097701</td>\n","      <td>29.691571</td>\n","      <td>40.869732</td>\n","      <td>25.643678</td>\n","      <td>21.850575</td>\n","      <td>86.101533</td>\n","      <td>27.609195</td>\n","      <td>29.854406</td>\n","      <td>20.352490</td>\n","      <td>22.467433</td>\n","      <td>40.636015</td>\n","      <td>19.873563</td>\n","    </tr>\n","    <tr>\n","      <th>std</th>\n","      <td>76.354872</td>\n","      <td>32.567222</td>\n","      <td>36.843095</td>\n","      <td>37.618092</td>\n","      <td>50.725437</td>\n","      <td>33.790208</td>\n","      <td>31.397989</td>\n","      <td>36.014297</td>\n","      <td>44.610836</td>\n","      <td>31.857750</td>\n","      <td>37.283299</td>\n","      <td>24.467995</td>\n","      <td>22.025999</td>\n","      <td>66.773741</td>\n","      <td>26.724236</td>\n","      <td>31.814630</td>\n","      <td>23.273025</td>\n","      <td>25.006638</td>\n","      <td>40.699471</td>\n","      <td>21.999636</td>\n","    </tr>\n","    <tr>\n","      <th>min</th>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","    </tr>\n","    <tr>\n","      <th>25%</th>\n","      <td>34.250000</td>\n","      <td>8.000000</td>\n","      <td>8.000000</td>\n","      <td>4.000000</td>\n","      <td>14.250000</td>\n","      <td>6.000000</td>\n","      <td>7.000000</td>\n","      <td>9.000000</td>\n","      <td>11.000000</td>\n","      <td>6.250000</td>\n","      <td>10.000000</td>\n","      <td>6.000000</td>\n","      <td>4.000000</td>\n","      <td>28.250000</td>\n","      <td>6.000000</td>\n","      <td>6.000000</td>\n","      <td>4.000000</td>\n","      <td>3.000000</td>\n","      <td>7.250000</td>\n","      <td>4.000000</td>\n","    </tr>\n","    <tr>\n","      <th>50%</th>\n","      <td>93.000000</td>\n","      <td>25.000000</td>\n","      <td>29.500000</td>\n","      <td>14.000000</td>\n","      <td>46.500000</td>\n","      <td>20.500000</td>\n","      <td>24.000000</td>\n","      <td>35.000000</td>\n","      <td>37.000000</td>\n","      <td>21.000000</td>\n","      <td>31.000000</td>\n","      <td>19.000000</td>\n","      <td>15.000000</td>\n","      <td>81.000000</td>\n","      <td>20.500000</td>\n","      <td>18.500000</td>\n","      <td>12.000000</td>\n","      <td>13.000000</td>\n","      <td>32.000000</td>\n","      <td>13.000000</td>\n","    </tr>\n","    <tr>\n","      <th>75%</th>\n","      <td>149.000000</td>\n","      <td>51.000000</td>\n","      <td>53.000000</td>\n","      <td>38.750000</td>\n","      <td>83.750000</td>\n","      <td>47.000000</td>\n","      <td>51.750000</td>\n","      <td>63.000000</td>\n","      <td>68.000000</td>\n","      <td>41.000000</td>\n","      <td>61.750000</td>\n","      <td>39.000000</td>\n","      <td>32.750000</td>\n","      <td>129.750000</td>\n","      <td>41.000000</td>\n","      <td>45.000000</td>\n","      <td>29.000000</td>\n","      <td>34.000000</td>\n","      <td>59.000000</td>\n","      <td>31.000000</td>\n","    </tr>\n","    <tr>\n","      <th>max</th>\n","      <td>479.000000</td>\n","      <td>194.000000</td>\n","      <td>274.000000</td>\n","      <td>271.000000</td>\n","      <td>355.000000</td>\n","      <td>199.000000</td>\n","      <td>164.000000</td>\n","      <td>181.000000</td>\n","      <td>262.000000</td>\n","      <td>210.000000</td>\n","      <td>224.000000</td>\n","      <td>160.000000</td>\n","      <td>112.000000</td>\n","      <td>431.000000</td>\n","      <td>155.000000</td>\n","      <td>203.000000</td>\n","      <td>131.000000</td>\n","      <td>141.000000</td>\n","      <td>230.000000</td>\n","      <td>216.000000</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["         BUDAPEST     BARANYA        BACS  ...         VAS    VESZPREM        ZALA\n","count  522.000000  522.000000  522.000000  ...  522.000000  522.000000  522.000000\n","mean   101.245211   34.204981   37.166667  ...   22.467433   40.636015   19.873563\n","std     76.354872   32.567222   36.843095  ...   25.006638   40.699471   21.999636\n","min      0.000000    0.000000    0.000000  ...    0.000000    0.000000    0.000000\n","25%     34.250000    8.000000    8.000000  ...    3.000000    7.250000    4.000000\n","50%     93.000000   25.000000   29.500000  ...   13.000000   32.000000   13.000000\n","75%    149.000000   51.000000   53.000000  ...   34.000000   59.000000   31.000000\n","max    479.000000  194.000000  274.000000  ...  141.000000  230.000000  216.000000\n","\n","[8 rows x 20 columns]"]},"metadata":{"tags":[]},"execution_count":6}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"pqayTNbLIvfe","executionInfo":{"status":"ok","timestamp":1624896725821,"user_tz":-540,"elapsed":35,"user":{"displayName":"윤건일","photoUrl":"","userId":"05157393038207945770"}},"outputId":"8190d367-8463-429c-d01d-d9549355987c"},"source":["df.isnull().sum()"],"execution_count":7,"outputs":[{"output_type":"execute_result","data":{"text/plain":["BUDAPEST    0\n","BARANYA     0\n","BACS        0\n","BEKES       0\n","BORSOD      0\n","CSONGRAD    0\n","FEJER       0\n","GYOR        0\n","HAJDU       0\n","HEVES       0\n","JASZ        0\n","KOMAROM     0\n","NOGRAD      0\n","PEST        0\n","SOMOGY      0\n","SZABOLCS    0\n","TOLNA       0\n","VAS         0\n","VESZPREM    0\n","ZALA        0\n","dtype: int64"]},"metadata":{"tags":[]},"execution_count":7}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":270},"id":"xM3E8tFRIwOv","executionInfo":{"status":"ok","timestamp":1624896726569,"user_tz":-540,"elapsed":775,"user":{"displayName":"윤건일","photoUrl":"","userId":"05157393038207945770"}},"outputId":"76285cda-d5fa-40b9-dd8a-14557e9087b7"},"source":["# series data to img function\n","def series_to_img(dataset, time_step=1):\n","    num = dataset.shape[1]      # features num\n","    df = pd.DataFrame(dataset)\n","    cols, names = list(), list()\n","    # sequence t-n to t-1\n","    for i in range(time_step, 0, -1):\n","        cols.append(df.shift(i))\n","        names += [('var%d(t-%d)' % (j+1, i)) for j in range(num)]\n","\n","    for i in range(0, 1):\n","        cols.append(df.shift(-i))\n","        if i == 0:\n","            names += [('var%d(t)' % (j+1)) for j in range(num)]\n","        else:\n","            names += [('var%d(t+%d)' % (j+1, i)) for j in range(num)]\n","\n","    agg = pd.concat(cols, axis=1)\n","    agg.columns = names\n","    agg.dropna(inplace=True)\n","    return agg\n","\n","from sklearn.model_selection import TimeSeriesSplit\n","from sklearn.preprocessing import MinMaxScaler\n","\n","dataset = df.values\n","dataset = dataset.astype('float')\n","\n","n_inputs = 24\n","n_features = 20\n","del_idx = n_inputs * n_features + 1\n","del_cols = [i for i in range(del_idx, del_idx+n_features-1)]\n","new_df = series_to_img(dataset, n_inputs)\n","new_df.drop(new_df.columns[del_cols], axis=1, inplace=True)\n","new_df.head()"],"execution_count":8,"outputs":[{"output_type":"execute_result","data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>var1(t-24)</th>\n","      <th>var2(t-24)</th>\n","      <th>var3(t-24)</th>\n","      <th>var4(t-24)</th>\n","      <th>var5(t-24)</th>\n","      <th>var6(t-24)</th>\n","      <th>var7(t-24)</th>\n","      <th>var8(t-24)</th>\n","      <th>var9(t-24)</th>\n","      <th>var10(t-24)</th>\n","      <th>var11(t-24)</th>\n","      <th>var12(t-24)</th>\n","      <th>var13(t-24)</th>\n","      <th>var14(t-24)</th>\n","      <th>var15(t-24)</th>\n","      <th>var16(t-24)</th>\n","      <th>var17(t-24)</th>\n","      <th>var18(t-24)</th>\n","      <th>var19(t-24)</th>\n","      <th>var20(t-24)</th>\n","      <th>var1(t-23)</th>\n","      <th>var2(t-23)</th>\n","      <th>var3(t-23)</th>\n","      <th>var4(t-23)</th>\n","      <th>var5(t-23)</th>\n","      <th>var6(t-23)</th>\n","      <th>var7(t-23)</th>\n","      <th>var8(t-23)</th>\n","      <th>var9(t-23)</th>\n","      <th>var10(t-23)</th>\n","      <th>var11(t-23)</th>\n","      <th>var12(t-23)</th>\n","      <th>var13(t-23)</th>\n","      <th>var14(t-23)</th>\n","      <th>var15(t-23)</th>\n","      <th>var16(t-23)</th>\n","      <th>var17(t-23)</th>\n","      <th>var18(t-23)</th>\n","      <th>var19(t-23)</th>\n","      <th>var20(t-23)</th>\n","      <th>...</th>\n","      <th>var2(t-2)</th>\n","      <th>var3(t-2)</th>\n","      <th>var4(t-2)</th>\n","      <th>var5(t-2)</th>\n","      <th>var6(t-2)</th>\n","      <th>var7(t-2)</th>\n","      <th>var8(t-2)</th>\n","      <th>var9(t-2)</th>\n","      <th>var10(t-2)</th>\n","      <th>var11(t-2)</th>\n","      <th>var12(t-2)</th>\n","      <th>var13(t-2)</th>\n","      <th>var14(t-2)</th>\n","      <th>var15(t-2)</th>\n","      <th>var16(t-2)</th>\n","      <th>var17(t-2)</th>\n","      <th>var18(t-2)</th>\n","      <th>var19(t-2)</th>\n","      <th>var20(t-2)</th>\n","      <th>var1(t-1)</th>\n","      <th>var2(t-1)</th>\n","      <th>var3(t-1)</th>\n","      <th>var4(t-1)</th>\n","      <th>var5(t-1)</th>\n","      <th>var6(t-1)</th>\n","      <th>var7(t-1)</th>\n","      <th>var8(t-1)</th>\n","      <th>var9(t-1)</th>\n","      <th>var10(t-1)</th>\n","      <th>var11(t-1)</th>\n","      <th>var12(t-1)</th>\n","      <th>var13(t-1)</th>\n","      <th>var14(t-1)</th>\n","      <th>var15(t-1)</th>\n","      <th>var16(t-1)</th>\n","      <th>var17(t-1)</th>\n","      <th>var18(t-1)</th>\n","      <th>var19(t-1)</th>\n","      <th>var20(t-1)</th>\n","      <th>var1(t)</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>24</th>\n","      <td>168.0</td>\n","      <td>79.0</td>\n","      <td>30.0</td>\n","      <td>173.0</td>\n","      <td>169.0</td>\n","      <td>42.0</td>\n","      <td>136.0</td>\n","      <td>120.0</td>\n","      <td>162.0</td>\n","      <td>36.0</td>\n","      <td>130.0</td>\n","      <td>57.0</td>\n","      <td>2.0</td>\n","      <td>178.0</td>\n","      <td>66.0</td>\n","      <td>64.0</td>\n","      <td>11.0</td>\n","      <td>29.0</td>\n","      <td>87.0</td>\n","      <td>68.0</td>\n","      <td>157.0</td>\n","      <td>60.0</td>\n","      <td>30.0</td>\n","      <td>92.0</td>\n","      <td>200.0</td>\n","      <td>53.0</td>\n","      <td>51.0</td>\n","      <td>70.0</td>\n","      <td>84.0</td>\n","      <td>28.0</td>\n","      <td>80.0</td>\n","      <td>50.0</td>\n","      <td>29.0</td>\n","      <td>141.0</td>\n","      <td>48.0</td>\n","      <td>29.0</td>\n","      <td>58.0</td>\n","      <td>53.0</td>\n","      <td>68.0</td>\n","      <td>26.0</td>\n","      <td>...</td>\n","      <td>98.0</td>\n","      <td>129.0</td>\n","      <td>100.0</td>\n","      <td>104.0</td>\n","      <td>48.0</td>\n","      <td>73.0</td>\n","      <td>128.0</td>\n","      <td>95.0</td>\n","      <td>62.0</td>\n","      <td>163.0</td>\n","      <td>146.0</td>\n","      <td>39.0</td>\n","      <td>145.0</td>\n","      <td>23.0</td>\n","      <td>84.0</td>\n","      <td>46.0</td>\n","      <td>39.0</td>\n","      <td>87.0</td>\n","      <td>37.0</td>\n","      <td>139.0</td>\n","      <td>30.0</td>\n","      <td>94.0</td>\n","      <td>54.0</td>\n","      <td>61.0</td>\n","      <td>30.0</td>\n","      <td>56.0</td>\n","      <td>79.0</td>\n","      <td>161.0</td>\n","      <td>83.0</td>\n","      <td>99.0</td>\n","      <td>82.0</td>\n","      <td>29.0</td>\n","      <td>66.0</td>\n","      <td>13.0</td>\n","      <td>14.0</td>\n","      <td>23.0</td>\n","      <td>29.0</td>\n","      <td>69.0</td>\n","      <td>47.0</td>\n","      <td>155.0</td>\n","    </tr>\n","    <tr>\n","      <th>25</th>\n","      <td>157.0</td>\n","      <td>60.0</td>\n","      <td>30.0</td>\n","      <td>92.0</td>\n","      <td>200.0</td>\n","      <td>53.0</td>\n","      <td>51.0</td>\n","      <td>70.0</td>\n","      <td>84.0</td>\n","      <td>28.0</td>\n","      <td>80.0</td>\n","      <td>50.0</td>\n","      <td>29.0</td>\n","      <td>141.0</td>\n","      <td>48.0</td>\n","      <td>29.0</td>\n","      <td>58.0</td>\n","      <td>53.0</td>\n","      <td>68.0</td>\n","      <td>26.0</td>\n","      <td>96.0</td>\n","      <td>44.0</td>\n","      <td>31.0</td>\n","      <td>86.0</td>\n","      <td>93.0</td>\n","      <td>30.0</td>\n","      <td>93.0</td>\n","      <td>84.0</td>\n","      <td>191.0</td>\n","      <td>51.0</td>\n","      <td>64.0</td>\n","      <td>46.0</td>\n","      <td>4.0</td>\n","      <td>157.0</td>\n","      <td>33.0</td>\n","      <td>33.0</td>\n","      <td>24.0</td>\n","      <td>18.0</td>\n","      <td>62.0</td>\n","      <td>44.0</td>\n","      <td>...</td>\n","      <td>30.0</td>\n","      <td>94.0</td>\n","      <td>54.0</td>\n","      <td>61.0</td>\n","      <td>30.0</td>\n","      <td>56.0</td>\n","      <td>79.0</td>\n","      <td>161.0</td>\n","      <td>83.0</td>\n","      <td>99.0</td>\n","      <td>82.0</td>\n","      <td>29.0</td>\n","      <td>66.0</td>\n","      <td>13.0</td>\n","      <td>14.0</td>\n","      <td>23.0</td>\n","      <td>29.0</td>\n","      <td>69.0</td>\n","      <td>47.0</td>\n","      <td>155.0</td>\n","      <td>56.0</td>\n","      <td>94.0</td>\n","      <td>56.0</td>\n","      <td>147.0</td>\n","      <td>24.0</td>\n","      <td>77.0</td>\n","      <td>93.0</td>\n","      <td>150.0</td>\n","      <td>47.0</td>\n","      <td>123.0</td>\n","      <td>83.0</td>\n","      <td>30.0</td>\n","      <td>117.0</td>\n","      <td>36.0</td>\n","      <td>73.0</td>\n","      <td>21.0</td>\n","      <td>53.0</td>\n","      <td>66.0</td>\n","      <td>70.0</td>\n","      <td>98.0</td>\n","    </tr>\n","    <tr>\n","      <th>26</th>\n","      <td>96.0</td>\n","      <td>44.0</td>\n","      <td>31.0</td>\n","      <td>86.0</td>\n","      <td>93.0</td>\n","      <td>30.0</td>\n","      <td>93.0</td>\n","      <td>84.0</td>\n","      <td>191.0</td>\n","      <td>51.0</td>\n","      <td>64.0</td>\n","      <td>46.0</td>\n","      <td>4.0</td>\n","      <td>157.0</td>\n","      <td>33.0</td>\n","      <td>33.0</td>\n","      <td>24.0</td>\n","      <td>18.0</td>\n","      <td>62.0</td>\n","      <td>44.0</td>\n","      <td>163.0</td>\n","      <td>49.0</td>\n","      <td>43.0</td>\n","      <td>126.0</td>\n","      <td>46.0</td>\n","      <td>39.0</td>\n","      <td>52.0</td>\n","      <td>114.0</td>\n","      <td>107.0</td>\n","      <td>42.0</td>\n","      <td>63.0</td>\n","      <td>54.0</td>\n","      <td>14.0</td>\n","      <td>107.0</td>\n","      <td>66.0</td>\n","      <td>50.0</td>\n","      <td>25.0</td>\n","      <td>21.0</td>\n","      <td>43.0</td>\n","      <td>31.0</td>\n","      <td>...</td>\n","      <td>56.0</td>\n","      <td>94.0</td>\n","      <td>56.0</td>\n","      <td>147.0</td>\n","      <td>24.0</td>\n","      <td>77.0</td>\n","      <td>93.0</td>\n","      <td>150.0</td>\n","      <td>47.0</td>\n","      <td>123.0</td>\n","      <td>83.0</td>\n","      <td>30.0</td>\n","      <td>117.0</td>\n","      <td>36.0</td>\n","      <td>73.0</td>\n","      <td>21.0</td>\n","      <td>53.0</td>\n","      <td>66.0</td>\n","      <td>70.0</td>\n","      <td>98.0</td>\n","      <td>40.0</td>\n","      <td>153.0</td>\n","      <td>32.0</td>\n","      <td>85.0</td>\n","      <td>13.0</td>\n","      <td>31.0</td>\n","      <td>62.0</td>\n","      <td>40.0</td>\n","      <td>42.0</td>\n","      <td>82.0</td>\n","      <td>81.0</td>\n","      <td>10.0</td>\n","      <td>89.0</td>\n","      <td>12.0</td>\n","      <td>60.0</td>\n","      <td>22.0</td>\n","      <td>25.0</td>\n","      <td>49.0</td>\n","      <td>18.0</td>\n","      <td>87.0</td>\n","    </tr>\n","    <tr>\n","      <th>27</th>\n","      <td>163.0</td>\n","      <td>49.0</td>\n","      <td>43.0</td>\n","      <td>126.0</td>\n","      <td>46.0</td>\n","      <td>39.0</td>\n","      <td>52.0</td>\n","      <td>114.0</td>\n","      <td>107.0</td>\n","      <td>42.0</td>\n","      <td>63.0</td>\n","      <td>54.0</td>\n","      <td>14.0</td>\n","      <td>107.0</td>\n","      <td>66.0</td>\n","      <td>50.0</td>\n","      <td>25.0</td>\n","      <td>21.0</td>\n","      <td>43.0</td>\n","      <td>31.0</td>\n","      <td>122.0</td>\n","      <td>78.0</td>\n","      <td>53.0</td>\n","      <td>87.0</td>\n","      <td>103.0</td>\n","      <td>34.0</td>\n","      <td>95.0</td>\n","      <td>131.0</td>\n","      <td>172.0</td>\n","      <td>40.0</td>\n","      <td>61.0</td>\n","      <td>49.0</td>\n","      <td>11.0</td>\n","      <td>124.0</td>\n","      <td>63.0</td>\n","      <td>56.0</td>\n","      <td>7.0</td>\n","      <td>47.0</td>\n","      <td>85.0</td>\n","      <td>60.0</td>\n","      <td>...</td>\n","      <td>40.0</td>\n","      <td>153.0</td>\n","      <td>32.0</td>\n","      <td>85.0</td>\n","      <td>13.0</td>\n","      <td>31.0</td>\n","      <td>62.0</td>\n","      <td>40.0</td>\n","      <td>42.0</td>\n","      <td>82.0</td>\n","      <td>81.0</td>\n","      <td>10.0</td>\n","      <td>89.0</td>\n","      <td>12.0</td>\n","      <td>60.0</td>\n","      <td>22.0</td>\n","      <td>25.0</td>\n","      <td>49.0</td>\n","      <td>18.0</td>\n","      <td>87.0</td>\n","      <td>18.0</td>\n","      <td>38.0</td>\n","      <td>26.0</td>\n","      <td>69.0</td>\n","      <td>32.0</td>\n","      <td>33.0</td>\n","      <td>66.0</td>\n","      <td>106.0</td>\n","      <td>40.0</td>\n","      <td>84.0</td>\n","      <td>72.0</td>\n","      <td>10.0</td>\n","      <td>91.0</td>\n","      <td>11.0</td>\n","      <td>86.0</td>\n","      <td>12.0</td>\n","      <td>54.0</td>\n","      <td>51.0</td>\n","      <td>34.0</td>\n","      <td>110.0</td>\n","    </tr>\n","    <tr>\n","      <th>28</th>\n","      <td>122.0</td>\n","      <td>78.0</td>\n","      <td>53.0</td>\n","      <td>87.0</td>\n","      <td>103.0</td>\n","      <td>34.0</td>\n","      <td>95.0</td>\n","      <td>131.0</td>\n","      <td>172.0</td>\n","      <td>40.0</td>\n","      <td>61.0</td>\n","      <td>49.0</td>\n","      <td>11.0</td>\n","      <td>124.0</td>\n","      <td>63.0</td>\n","      <td>56.0</td>\n","      <td>7.0</td>\n","      <td>47.0</td>\n","      <td>85.0</td>\n","      <td>60.0</td>\n","      <td>174.0</td>\n","      <td>76.0</td>\n","      <td>77.0</td>\n","      <td>152.0</td>\n","      <td>189.0</td>\n","      <td>26.0</td>\n","      <td>74.0</td>\n","      <td>181.0</td>\n","      <td>157.0</td>\n","      <td>44.0</td>\n","      <td>95.0</td>\n","      <td>97.0</td>\n","      <td>26.0</td>\n","      <td>146.0</td>\n","      <td>59.0</td>\n","      <td>54.0</td>\n","      <td>27.0</td>\n","      <td>54.0</td>\n","      <td>48.0</td>\n","      <td>60.0</td>\n","      <td>...</td>\n","      <td>18.0</td>\n","      <td>38.0</td>\n","      <td>26.0</td>\n","      <td>69.0</td>\n","      <td>32.0</td>\n","      <td>33.0</td>\n","      <td>66.0</td>\n","      <td>106.0</td>\n","      <td>40.0</td>\n","      <td>84.0</td>\n","      <td>72.0</td>\n","      <td>10.0</td>\n","      <td>91.0</td>\n","      <td>11.0</td>\n","      <td>86.0</td>\n","      <td>12.0</td>\n","      <td>54.0</td>\n","      <td>51.0</td>\n","      <td>34.0</td>\n","      <td>110.0</td>\n","      <td>15.0</td>\n","      <td>67.0</td>\n","      <td>13.0</td>\n","      <td>36.0</td>\n","      <td>20.0</td>\n","      <td>24.0</td>\n","      <td>41.0</td>\n","      <td>49.0</td>\n","      <td>18.0</td>\n","      <td>58.0</td>\n","      <td>43.0</td>\n","      <td>12.0</td>\n","      <td>31.0</td>\n","      <td>11.0</td>\n","      <td>35.0</td>\n","      <td>8.0</td>\n","      <td>18.0</td>\n","      <td>39.0</td>\n","      <td>14.0</td>\n","      <td>70.0</td>\n","    </tr>\n","  </tbody>\n","</table>\n","<p>5 rows × 481 columns</p>\n","</div>"],"text/plain":["    var1(t-24)  var2(t-24)  var3(t-24)  ...  var19(t-1)  var20(t-1)  var1(t)\n","24       168.0        79.0        30.0  ...        69.0        47.0    155.0\n","25       157.0        60.0        30.0  ...        66.0        70.0     98.0\n","26        96.0        44.0        31.0  ...        49.0        18.0     87.0\n","27       163.0        49.0        43.0  ...        51.0        34.0    110.0\n","28       122.0        78.0        53.0  ...        39.0        14.0     70.0\n","\n","[5 rows x 481 columns]"]},"metadata":{"tags":[]},"execution_count":8}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"8vsBFiK8I2D0","executionInfo":{"status":"ok","timestamp":1624896916089,"user_tz":-540,"elapsed":189526,"user":{"displayName":"윤건일","photoUrl":"","userId":"05157393038207945770"}},"outputId":"91935b10-d44a-4ef8-cd9a-497e1f14147c"},"source":["n_splits = 10\n","train_test_split = TimeSeriesSplit(n_splits=n_splits+1, gap=n_inputs).split(new_df)\n","next(train_test_split)\n","\n","configs = model_config()\n","history = []\n","\n","best_rmse, best_mse, best_mae = [], [], []\n","\n","i = 1\n","\n","print('config : epochs, batch_size, learning_rate')\n","\n","# nested cross validation for time series model\n","for train_cv_indices, test_cv_indices in train_test_split:\n","    print(f'fold : {i}/{n_splits}')\n","    i+=1\n","\n","    # split x, y data\n","    train_cv_X, train_cv_y = new_df.iloc[train_cv_indices, :-1].values, new_df.iloc[train_cv_indices,-1].values\n","    test_cv_X, test_cv_y = new_df.iloc[test_cv_indices, :-1].values, new_df.iloc[test_cv_indices, -1].values\n","\n","    # length for validation set\n","    test_length = int(len(train_cv_X)*0.2)\n","\n","    # scaling data\n","    scaler_x = MinMaxScaler()\n","    train_cv_X = scaler_x.fit_transform(train_cv_X)\n","    test_cv_X = scaler_x.transform(test_cv_X)\n","\n","    train_X, val_X = train_cv_X[:-test_length, :], train_cv_X[-test_length:, :]\n","    train_y, val_y = train_cv_y[:-test_length], train_cv_y[-test_length:]\n","\n","    # reshape\n","    # inner loop\n","    train_X = train_X.reshape(-1, 1, n_inputs, n_features)\n","    val_X = val_X.reshape(-1, 1, n_inputs, n_features)\n","    train_y = train_y.reshape(-1, 1)\n","    val_y = val_y.reshape(-1, 1)\n","\n","    # outer loop\n","    train_cv_X = train_cv_X.reshape(-1, 1, n_inputs, n_features)\n","    test_cv_X = test_cv_X.reshape(-1, 1, n_inputs, n_features)\n","    train_cv_y = train_cv_y.reshape(-1, 1)\n","    test_cv_y = test_cv_y.reshape(-1, 1)\n","\n","    train_X = np_to_tensor(train_X)\n","    train_y = np_to_tensor(train_y)\n","    val_X = np_to_tensor(val_X)\n","    val_y = np_to_tensor(val_y)\n","    train_cv_X = np_to_tensor(train_cv_X)\n","    train_cv_y = np_to_tensor(train_cv_y)\n","    test_cv_X = np_to_tensor(test_cv_X)\n","    test_cv_y = np_to_tensor(test_cv_y)\n","\n","    # model fit, inner\n","    errors = []\n","    for idx, cfg in enumerate(configs):\n","        print(f' == train {cfg} model == ', end=' ')\n","        model = model_fit(train_X, train_y, cfg)\n","        predicted = model(val_X)\n","        error = F.mse_loss(predicted, val_y)   # rmse\n","        print(f'error(rmse):{error.item():.2f}')\n","        if errors:\n","            if error.item() < min(errors):\n","                param = idx\n","        else:\n","            param = idx\n","        errors.append(error.item())\n","\n","    history.append(errors)\n","\n","    # outer\n","    selected_model = model_fit(train_cv_X,train_cv_y, configs[param])\n","    predicted = selected_model(test_cv_X)\n","    rmse = np.sqrt(F.mse_loss(predicted, test_cv_y).item())\n","    mse = F.mse_loss(predicted, test_cv_y)\n","    mae = F.l1_loss(predicted, test_cv_y)\n","    best_rmse.append(rmse)\n","    best_mse.append(mse.item())\n","    best_mae.append(mae.item())\n","\n","    # model eval\n","    print(f'train-size:{train_X.size(0)}, val-size:{val_X.size(0)}, test-size:{test_cv_X.size(0)}')\n","    print(f'best_model => error(rmse) : {rmse:.2f}, param:{configs[param]}')\n","    print()"],"execution_count":9,"outputs":[{"output_type":"stream","text":["config : epochs, batch_size, learning_rate\n","fold : 1/10\n"," == train [30, 32, 0.01] model ==  "],"name":"stdout"},{"output_type":"stream","text":["/usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:718: UserWarning: Named tensors and all their associated APIs are an experimental feature and subject to change. Please do not use them for anything important until they are released as stable. (Triggered internally at  /pytorch/c10/core/TensorImpl.h:1156.)\n","  return torch.max_pool2d(input, kernel_size, stride, padding, dilation, ceil_mode)\n"],"name":"stderr"},{"output_type":"stream","text":["error(rmse):2800.82\n"," == train [30, 32, 0.001] model ==  error(rmse):5277.20\n","train-size:52, val-size:12, test-size:41\n","best_model => error(rmse) : 56.90, param:[30, 32, 0.01]\n","\n","fold : 2/10\n"," == train [30, 32, 0.01] model ==  error(rmse):15811.77\n"," == train [30, 32, 0.001] model ==  error(rmse):28573.99\n","train-size:84, val-size:21, test-size:41\n","best_model => error(rmse) : 107.30, param:[30, 32, 0.01]\n","\n","fold : 3/10\n"," == train [30, 32, 0.01] model ==  error(rmse):10120.88\n"," == train [30, 32, 0.001] model ==  error(rmse):7534.97\n","train-size:117, val-size:29, test-size:41\n","best_model => error(rmse) : 74.68, param:[30, 32, 0.001]\n","\n","fold : 4/10\n"," == train [30, 32, 0.01] model ==  error(rmse):7089.15\n"," == train [30, 32, 0.001] model ==  error(rmse):6251.32\n","train-size:150, val-size:37, test-size:41\n","best_model => error(rmse) : 64.12, param:[30, 32, 0.001]\n","\n","fold : 5/10\n"," == train [30, 32, 0.01] model ==  error(rmse):2762.48\n"," == train [30, 32, 0.001] model ==  error(rmse):3326.95\n","train-size:183, val-size:45, test-size:41\n","best_model => error(rmse) : 54.04, param:[30, 32, 0.01]\n","\n","fold : 6/10\n"," == train [30, 32, 0.01] model ==  error(rmse):5389.32\n"," == train [30, 32, 0.001] model ==  error(rmse):3190.20\n","train-size:216, val-size:53, test-size:41\n","best_model => error(rmse) : 36.81, param:[30, 32, 0.001]\n","\n","fold : 7/10\n"," == train [30, 32, 0.01] model ==  error(rmse):4702.97\n"," == train [30, 32, 0.001] model ==  error(rmse):2852.81\n","train-size:248, val-size:62, test-size:41\n","best_model => error(rmse) : 69.94, param:[30, 32, 0.001]\n","\n","fold : 8/10\n"," == train [30, 32, 0.01] model ==  error(rmse):3069.24\n"," == train [30, 32, 0.001] model ==  error(rmse):3986.74\n","train-size:281, val-size:70, test-size:41\n","best_model => error(rmse) : 60.41, param:[30, 32, 0.01]\n","\n","fold : 9/10\n"," == train [30, 32, 0.01] model ==  error(rmse):3383.57\n"," == train [30, 32, 0.001] model ==  error(rmse):4550.33\n","train-size:314, val-size:78, test-size:41\n","best_model => error(rmse) : 62.85, param:[30, 32, 0.01]\n","\n","fold : 10/10\n"," == train [30, 32, 0.01] model ==  error(rmse):3340.01\n"," == train [30, 32, 0.001] model ==  error(rmse):3894.20\n","train-size:347, val-size:86, test-size:41\n","best_model => error(rmse) : 77.42, param:[30, 32, 0.01]\n","\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"vbY7fwOCI33U","executionInfo":{"status":"ok","timestamp":1624896916090,"user_tz":-540,"elapsed":19,"user":{"displayName":"윤건일","photoUrl":"","userId":"05157393038207945770"}},"outputId":"2d3c9329-e7f5-457c-da54-03462defa967"},"source":["predicted = selected_model(test_cv_X)\n","\n","def model_evaluation(mse, rmse, mae):\n","    mse = np.array(mse)\n","    rmse = np.array(rmse)\n","    mae = np.array(mae)\n","    print(f'MSE: mean={np.mean(mse)}, std={np.std(mse)}')\n","    print(f'RMSE: mean={np.mean(rmse)}, std={np.std(rmse)}')\n","    print(f'MAE: mean={np.mean(mae)}, std={np.std(mae)}')\n","\n","model_evaluation(best_mse, best_rmse, best_mae)"],"execution_count":10,"outputs":[{"output_type":"stream","text":["MSE: mean=4719.942248535156, std=2596.4394523626847\n","RMSE: mean=66.44664584708063, std=17.458107119839728\n","MAE: mean=48.71797752380371, std=11.758798160969683\n"],"name":"stdout"}]}]}